[{"content":"並行複製 (Multi-Thread Slave, MTS) 在 MySQL 8.0.27 之前，Replica 預設只有一個 IO_THREAD 和一個 SQL_THREAD：\nIO_THREAD 負責從 Source 接收 binlog 並寫入 Replica 的 relaylog SQL_THREAD 負責解析和重放 relaylog 中的 event 當 Source 有併發大量寫入時，Replica 的 IO_THREAD 因為是順序寫入一般不會導致 replication delay，但是只有單線程 SQL_THREAD 回放速度是跟不上有多線程寫入的 Source，因此會造成 replication delay 不斷變大，相應也導致 Replica 的 relaylog 大量堆積占滿 disk 空間。\n因此從 MySQL 5.6 開始提供了 Multi-Tread Slave (MTS)，透過多線程的 SQL_THREAD 來緩解這種問題，並且在後續的大版本中不斷進行優化。\n各個版本的 MTS 基於 database 級別的 MTS (5.6) 在 MySQL 5.6 只有基於 Database 級別的 MTS，只有在不同 Database 的語句才可以並行執行，因此這無法解決單表高寫入所造成的同步延遲。\n基於 Group Commit 的 MTS (5.7) Group Commit 簡述 Group Commit 是 MySQL 5.6 版本引入用來優化 BinLog、RedoLog 在 2PC 時寫入的瓶頸，簡單來說原本每個 Transaction 都需要獨自 fsync 操作來寫入 Disk 持久化，經過 Group Commit 的優化後會將多個 Transaction 組成一個對列一起進行 fsync 操作，大幅減少 fsync 操作解決在雙 1 時造成的性能急速下降的問題。\n關於 Group Commit 的具體描述，可參考 MySQL Group Commit 演進。\nslave_parallel_type 在 MySQL 5.7 引入了 slave_parallel_type 這個新參數，可使用的值有以下 2 個：\nDATABASE：也就是 5.6 版本，不同 DATABASE 的才能並行回放。 LOGICAL_CLOCK：5.7 版本基於 Group Commit 的並行回放。 LOGICAL_CLOCK - Commit Parent Based 模式 在 Source 中能夠在同一個對列一起進行 Group commit，表示這個對列中的所有 Transaction 都沒有鎖衝突，因此也可在 Replica 內並行回放。\n為了讓 Replica 能基於 Group Commit 實現 MTS，在 Binlog 中為每個 Transaction 添加了 LOGICAL CLOCK 也就是以下 2 個值：\nsequence_number：每個 Transaction 的唯一序列號，具體在 Transaction 進入 flush 階段的對列之前分配。 last_commited：紀錄上次 Group commit 時最大的 sequence_number，也就是說 last_committed 相同表示同屬一個 Group。 透過 mysqlbinlog 可以看到 binlog 中每個 Transaction 都有這 2 個變量\n備註：sequence_number、last_commited 只在同一個 BinLog 文件不重複，每當換到新的 BinLog 文件時會重新從 0 開始計數。\n不過 Commit Parent Based 有一個缺陷，讓我們看一下例子：\n1 2 3 4 5 6 7 8 9 10 11 Trx1 ------------P----------C--------------------------------\u0026gt; | Trx2 ----------------P------+---C----------------------------\u0026gt; | | Trx3 -------------------P---+---+-----C----------------------\u0026gt; | | | Trx4 -----------------------+-P-+-----+----C-----------------\u0026gt; | | | | Trx5 -----------------------+---+-P---+----+---C-------------\u0026gt; | | | | | Trx6 -----------------------+---+---P-+----+---+---C----------\u0026gt; 每一個水平線代表一個 Transaction 由左到右的時間點，其中 P 表示 prepare 階段取得上一個 Group 更新 last_committed 的時間點，C 表示 commit 前更新 last_committed 的時間點。\n其中可以觀察到：\nTrx4 的 P 時間點取得的是 Trx1 commit 產生的 last_committed Trx5 和 Trx6 的 P 時間點取得的是 Trx2 commit 產生的 last_committed 依照 Commit Parent 模式下 Trx5、Trx6 可以一起在 Replica 回放，但是 Trx4 不可以和 Trx5、Trx6 一起在 Replica 回放。\n然而，實際上依照時間線我們可以看到 Trx4 在 prepare 到 commit 的過程中，Trx5、Trx6 有在這個過程中 prepare，也就是說實際上他們並沒有鎖衝突 (如果衝突 Trx5、Trx6 會卡在 lock wait)，所以理論上他們在 Replica 是可以並行回放到。\nLOGICAL_CLOCK - Lock Based 模式 為了進一步優化 Commit Parent Based 的缺陷，MySQL 5.7 馬上實現了 MySQL :: WL#7165: MTS: Optimizing MTS scheduling by increasing the parallelization window on master 的優化，也就是基於 Lock Based 模式的 LOGICAL_CLOCK，只要 Transaction 在各自持有的鎖沒有衝突時就可以並行執行。\n在此模式下 binlog 中的 sequence_number、last_commited 涵義如下：\nsequence_number：每個 Transaction 的唯一序列號，具體在 Transaction 進入 flush 階段的對列之前分配， last_commited：當 Transaction 開始加鎖時，將全局變量 max_committed_transaction 當下的值作為 last_commited。 全局變量 max_committed_transaction：已經結束 Lock interval 的最大 sequence_number，每個 Transaction 在 InnoDB commit 階段時，如果自己的 sequence_number \u0026gt; max_committed_transaction 時會將其更新為自己的 sequence_number 。 因為無法預先知道哪一個鎖是最後一個，因此 Transaction 內每一個 DML 都會不斷更新該 Transaction 的 last_commited。 在 Source 寫入 sequence_number、last_commited 之後，接下來就是看 Replica 如何依據這 2 個直來實現 Lock Based 的 MTS。\n首先複習一下，只有當 Transaction 和 Transaction 在 Lock ~ Commit (也就是釋放鎖) 之間有交集才能在 Replica 並行回放：\n1 2 3 4 5 6 7 - Can execute in parallel: Trx1 -----L---------C------------\u0026gt; Trx2 ----------L---------C-------\u0026gt; - Can not execute in parallel: Trx1 -----L----C-----------------\u0026gt; Trx2 ---------------L----C-------\u0026gt; 讓我們首先為上圖中的 L~C 的期間定義一個新的名詞 Lock interval：\nLock interval 的起始點(上圖L)：在 Binlog Prepare 階段取得最後一把鎖的時間點。 Lock interval 的結束點(上圖C)：在 InnoDB Commit 階段釋放第一把鎖的時間點。 也就是說對於 Replica 在讀取 BinLog 時：\nlast_commited 作為 Lock interval 的起始點：因為 Transaction 開始加鎖的邏輯時間是目前最後一個已結束 lock interval 的最後一個 sequence_number，就是全局變量 max_committed_transaction。 sequence_number 作為 Lock interval 的結束點：因為當該 Transaction 結束 lock interval 時會將自己的 sequence_number 更新到 max_committed_transaction，也就是說對於下個 Transaction 而言的 last_commited。 在 Replica 回放時只有 Transaction 之間如果 last_commited~sequence_number 之間有重疊就可以並行回放。\n實現方式如下：\n定義一個變量 last_lwm_timestamp：為一個已經完成回放 Transaction 的 sequence_number ，該 Transaction 其 sequence_number 之前的所有 Transaction 都已經 commit。 當 coordinator 線程讀取一個 Transaction 的 last_committed： 當 last_committed \u0026lt; last_lwm_timestamp 表示 Lock interval 有交集，因此可以丟給 work 線程並行回放。\n1 2 Trx1 -----L---------C------------\u0026gt; Trx2 ----------L---------C-------\u0026gt; 當 last_committed = last_lwm_timestamp 雖然 Lock interval 沒有交集，但是該情況表示前一個 Transaction 完成，所以當前 Transaction 才會拿到前一個的 sequence_number 作為自己的 last_commited，而 last_lwm_timestamp 是已經 commit 的 Transaction，因此可以丟給 work 線程回放了。\n1 2 Trx1 -----L----C-----------------\u0026gt; Trx2 ----------L---------C-------\u0026gt; 當 last_committed \u0026gt; last_lwm_timestamp 表示 Lock interval 沒有交集，因此不能丟給 work 線程並行回放。\n1 2 Trx1 -----L----C-----------------\u0026gt; Trx2 ---------------L----C-------\u0026gt; Commit Parent Based VS Lock Based 舉例 假設有以下 binlog：\n在 Commit Parent Based 下：\nsequence_number 1~7 的 Transaction 其 last_committed 都是 0，所以可在 replica 並行回放。 sequence_number 8 的 Transaction 其 last_committed 是 1，所以不能和 sequence_number 1~7一起在 replica 並行回放。 *備註：在 Commit Parent Based 下，正確的 last_committed 應該要是 7，此處僅方便舉例使用 Lock Based 舉例。 sequence_number 914 的 Transaction 其 last_committed 都是 7，不能和 sequence_number 18 一起在 replica 並行回放。 在 Lock Based 下：\nsequence_number 17 的 Transaction 其 last_committed 都是 0 表示為同一個 Group，所以 17 可在 replica 並行回放。 sequence_number 8 的 last_committed = 1，表示 8 和 17 的鎖不衝突，因此 18 可在 replica 並行回放。 sequence_number 914 的 Transaction 其 last_committed 都是 7 表示為同一個 Group，同時 814 的鎖不衝突，因次 8~14 可在 replica 並行回放 缺陷 基於 Group Commit 的 MTS 不論是 Commit Parent Based 還是 Lock Based 都一樣，都是只有在 Source 上每個 Group 的 Transaction 足夠多，也就是併發度夠高的情況下才能在 Replica 上有較好的並行回放效率。\n雖然在 5.7 新增 binlog_group_commit_sync_delay、binlog_group_commit_sync_no_delay_count這 2 個設定，可以讓一個 Group 有更多的 Transaction，然而效果仍然十分有限。\n基於 WriteSet 的 MTS (5.7.22、8.0) MySQL 5.7 雖然透過 Group Commit 優化了 MTS，但這主要是優化在 Master 上有高並行度的情況下，如果 Master 並行度不高則同一個 Group 的 Event 相對少，因此 Slave 回放速度無法有效加快。\n在 8.0 為了解決上述問題，即使在 Source 上是串行 commit 的 Transaction，只要互相不衝突那麼在 Replica 上就能並行回放。\n在 8.0 新增了 binlog_transaction_dependency_tracking 這個參數來控制 binlog 寫入相關資訊，讓 Replica 據此進行並行回放，有以下三個值：\nCOMMIT_ORDER：使用 5.7 Group commit 的方式判斷。 WRITESET：使用 WriteSet 的方式判斷 Transaction 是否有衝突。 WRITESET_SESSION：WRITESET 的基礎上保證同一個 session 內的 Transaction 不可並行。 WriteSet 簡述 WriteSet 在 MySQL Group Replication(MGR) 中就已經實現了：\nMySQL Group Replication Protocol\n使用的地方是 certify 階段用來判斷 Transaction 是否允許 commit，這個時候就會透過 WriteSet 來判斷是否和其他 member 上的 Transaction 有衝突。\n💡 因為 MGR 可以在多個 member 上寫入，因此不像單機模式可以透過 Lock 衝突來避免 Transaction 之間的衝突，同時為了提高效能 MGR 採用樂觀的方式不透過其他方式額外加鎖，只有準備 commit 的時候透過 WriteSet 判斷 member 之間的 Transaction 是否衝突。\nWriteSet 應用到 MTS 簡述 假設在 Source 上 Transaction commit 時間軸如下，同一個時間只有 1~2 個 Transaction：\n上途中方塊對應 Transaction 修改的資料範圍，如果沒有重疊表示 Transaction 之間修改的數據不衝突，那麼透過 WriteSet 判斷 Transaction 之間是否衝突後，就可以在 Replica上如下並行：\n不過上圖有個小問題是可能發生 T3 比 T2 早執行的狀況，導致 Source 和 Replica 中同一個 session 產生有不同的執行紀錄，如果評估後覺得不可接受有以下 2 個方式可以解決：\nslave_preserve_commit_order = ON binlog_transaction_dependency_tracking = WRITESET_SESSION 如上圖調整後可以發現同一個 session 的都不能並行回放。\n實現方式 WriteSet 是什麼？ WriteSet 是一個 hash 數組，大小由 binlog_transaction_dependency_history_size 來決定。\n在 InooDB 修改數據後，會將修改的 row 數據以下內容進行 hash 後寫入 WriteSet：\nWriteSet 產出細節\n💡 產生的 Hash 值的方式可以參考 sql/rpl_write_set_handler.cc 中的 add_pke function mysql-server/rpl_write_set_handler.cc at 8.0 · mysql/mysql-server · GitHub\n範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mysql\u0026gt; use db_name Database changed mysql\u0026gt; show create table table_name \\G *************************** 1. row *************************** Table: table_name Create Table: CREATE TABLE `table_name` ( `pk_column` int(11) NOT NULL, `uk_column` int(11) NOT NULL, `idx_column` int(11) NOT NULL, PRIMARY KEY (`pk_column`), UNIQUE KEY `uk_column` (`uk_column`), KEY `idx_column` (`idx_column`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 mysql\u0026gt; INSERT INTO db_name.table_name VALUES(6, 7, 8) 1 2 3 4 5 6 7 8 9 10 11 12 # 透過編譯 mysqld debug 執行查看 ~ -\u0026gt; tail -f /tmp/mysqld.trace T@6: | | | | | | | | \u0026lt;generate_hash_pke 441 T@6: | | | | | | | | \u0026gt;generate_hash_pke T@6: | | | | | | | | | \u0026gt;Rpl_transaction_write_set_ctx::add_write_set T@6: | | | | | | | | | \u0026lt;Rpl_transaction_write_set_ctx::add_write_set 51 T@6: | | | | | | | | | info: pke: PRIMARY½db_name½7table_name½106½1; hash: 10113078337023140702 T@6: | | | | | | | | \u0026lt;generate_hash_pke 441 T@6: | | | | | | | | \u0026gt;generate_hash_pke T@6: | | | | | | | | | \u0026gt;Rpl_transaction_write_set_ctx::add_write_set T@6: | | | | | | | | | \u0026lt;Rpl_transaction_write_set_ctx::add_write_set 51 T@6: | | | | | | | | | info: pke: uk_column½db_name½7table_name½107½1; hash: 406567197175550244 偽代碼如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 如果表中存在索引： 将数据库名，表名信息写入临时变量 循环扫描表中每个索引： 如果不是唯一索引： 退出本次循环继续循环。 循环两种生成数据的方式(二进制格式和字符串格式)： 将索引名字写入到pke中。 将临时变量信息写入到pke中。 循环扫描索引中的每一个字段： 将每一个字段的信息写入到pke中。 如果字段扫描完成： 将pke生成hash值并且写入到写集合中。 如果没有找到主键或者唯一键记录一个标记，后面通过这个标记来 判定是否使用Writeset的并行复制方式 基於 WriteSet 的 MTS 怎麼實現？ 該模式下 Replica 同樣是基於 Source 產生的 binlog 中的 last_commited 和 sequenct_number 來決定是否可以並行回放，也就是說如果要進一步增加並行回放的效率，就需要盡可能為每個 Transaction 找出更小的 last_commited。\n基於 WriteSet 的 MTS 能找出更小的 last_commited 的方式就是維護一個先前 Transaction 所組成的 WriteSet 的歷史紀錄，之後新進來的 Transaction 計算 WriteSet 後和這個歷史紀錄進行衝突比對，以此來嘗試找出更小的 last_commited。\nbinlog_transaction_dependency_tracking 不同對 last_commit 的處理 基於 WriteSet 的 MTS 實際上是基於 ORDER_COMMIT (Group Commit) 進一步處理而已。\n根據 binlog_transaction_dependency_tracking 的設定不同，在 Source code 有如下內容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 case DEPENDENCY_TRACKING_COMMIT_ORDER: m_commit_order.get_dependency(thd, sequence_number, commit_parent); break; case DEPENDENCY_TRACKING_WRITESET: m_commit_order.get_dependency(thd, sequence_number, commit_parent); m_writeset.get_dependency(thd, sequence_number, commit_parent); break; case DEPENDENCY_TRACKING_WRITESET_SESSION: m_commit_order.get_dependency(thd, sequence_number, commit_parent); m_writeset.get_dependency(thd, sequence_number, commit_parent); m_writeset_session.get_dependency(thd, sequence_number, commit_parent); break; 可以看到從 COMMIT_ORDER 到 WRITESET 再到 WRITESET_SESSION 其實都是以上一個設定的為基礎進一步透過一個新的 function 進行修改而已，這些 function 修改的是 last_commited 值。\nWriteSet 歷史紀錄詳解 WriteSet 的歷史紀錄包含了 2 個元素：\nWriteSet 的 Hash 值 最後一次修改該行的 Transaction 其 sequence_number 1 2 3 4 5 6 /* Track the last transaction sequence number that changed each row in the database, using row hashes from the writeset as the index. */ typedef std::map\u0026lt;uint64,int64\u0026gt; Writeset_history; //map实现 Writeset_history m_writeset_history; 另外 binlog_transaction_dependency_history_size 決定了可以儲存幾組紀錄，內部會依照 WriteSet Hash 值進行排序。\n如果 WriteSet 的歷史紀錄達到 binlog_transaction_dependency_history_size 設定的值就會將歷史紀錄清空，並且本次的 Transaction 會成為清空後歷史紀錄的第一筆紀錄。\n另外除了歷史紀錄還有有一個 m_writeset_history_start 的值，用來儲存這個歷史紀錄中的最小 sequence_number。\n1 2 3 4 5 6 7 8 if (exceeds_capacity || !can_use_writesets) //Writeset的历史MAP已满 { m_writeset_history_start= sequence_number; //如果超过最大设置，清空writeset history。从当前seq number 重新记录， 也就是最小的那个事务seq number m_writeset_history.clear(); //清空历史MAP } WriteSet MTS 對 last_commit 的處理流程 這裡透過一個例子解釋，假設如下：\n當前的 Transaction 基於 ORDER_COMMIT (Group Commit) 的方式產生了結果： last_commit = 125 sequence_number = 130 該 Transaction 修改的表只有 PK 沒有 UK。 該 Transaction 修改了 4 行資料，分別為 ROW1、ROW7、ROW6、ROW10。 下圖展示了該 Transaction 和 WriteSet 歷史紀錄：\n接下來就會透過 WriteSet 方式找到更小的 last_commit：\n將 last_commit 由 125 調整為 100 (歷史紀錄中最小的 sequence_number m_writeset_history_start)。\n備註：因為該 Transaction 比歷史紀錄中的 Transaction 晚執行，因此 last_commit 一定都比他們的 sequence_number 大。\n將 ROW1 的 Hash 值在 WriteSet 歷史紀錄中確認，發現有修改相同紀錄的 Transaction：\n將歷史紀錄中該行的 sequence_number 由 120 (歷史紀錄值) 調整為 130(該 Transaction)。 將該 Transaction 的 last_commit 由 100 調整為 120。 將 ROW7 的 Hash 值在 WriteSet 歷史紀錄中確認，發現有修改相同紀錄的 Transaction：\n將歷史紀錄中該行的 sequence_number 由 114 (歷史紀錄值) 調整為 130(該 Transaction)。 當前 Transaction 當前 last_commit 為 120 比歷史紀錄中的 114 大，因為在 120 就衝突了，所以不能改成更小的 114，因此 last_commit 不變依舊是 120。 將 ROW6 的 Hash 值在 WriteSet 歷史紀錄中確認，發現有修改相同紀錄的 Transaction：\n將歷史紀錄中該行的 sequence_number 由 105 (歷史紀錄值) 調整為 130(該 Transaction)。 當前 Transaction 當前 last_commit 為 120 比歷史紀錄中的 105 大，因為在 120 就衝突了，所以不能改成更小的 105，因此 last_commit 不變依舊是 120。 將 ROW10 的 Hash 值在 WriteSet 歷史紀錄中確認，發現並沒有修改相同紀錄的 Transaction：\n因為沒有找到相同的 WriteSet，因此需要把該 Transaction ROW10 的 Hast 值和 sequence_number 寫入 WriteSet 歷史紀錄。 如果歷史紀錄大小超過 binlog_transaction_dependency_history_size，則清空當前歷史紀錄，隨後將 Transaction ROW10 的 Hast 值和 sequence_number(130) 寫入 WriteSet 新的歷史紀錄，並將 m_writeset_history_start 改為 130。 如果歷史紀錄大小沒有超過 binlog_transaction_dependency_history_size，將 Transaction ROW10 的 Hast 值和 sequence_number(130) 寫入 WriteSet 當前歷史紀錄。 整個過程結束，該 Transaction 的 last_commit 由原本的 125 降低為 120，最後結果如下圖：\n該過程在 Function Writeset_trx_dependency_tracker::get_dependency 中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 if (can_use_writesets) //如果能够使用writeset 方式 { /* Check if adding this transaction exceeds the capacity of the writeset history. If that happens, m_writeset_history will be cleared only after 而 add_pke using its information for current transaction. */ exceeds_capacity= m_writeset_history.size() + writeset-\u0026gt;size() \u0026gt; m_opt_max_history_size; //如果大于参数binlog_transaction_dependency_history_size设置清理标记 /* Compute the greatest sequence_number among all conflicts and add the transaction\u0026#39;s row hashes to the history. */ int64 last_parent= m_writeset_history_start; //临时变量，首先设置为最小的一个seq number for (std::set\u0026lt;uint64\u0026gt;::iterator it= writeset-\u0026gt;begin(); it != writeset-\u0026gt;end(); ++it) //循环每一个Writeset中的每一个元素 { Writeset_history::iterator hst= m_writeset_history.find(*it); //是否在writeset history中 已经存在了。 map中的元素是 key是writeset 值是sequence number if (hst != m_writeset_history.end()) //如果存在 { if (hst-\u0026gt;second \u0026gt; last_parent \u0026amp;\u0026amp; hst-\u0026gt;second \u0026lt; sequence_number) last_parent= hst-\u0026gt;second; //如果已经大于了不需要设置 hst-\u0026gt;second= sequence_number; //更改这行记录的sequence_number } else { if (!exceeds_capacity) m_writeset_history.insert(std::pair\u0026lt;uint64, int64\u0026gt;(*it, sequence_number)); //没有冲突则插入。 } } ...... if (!write_set_ctx-\u0026gt;get_has_missing_keys()) //如果没有主键和唯一键那么不更改last commit { /* The WRITESET commit_parent then becomes the minimum of largest parent found using the hashes of the row touched by the transaction and the commit parent calculated with COMMIT_ORDER. */； commit_parent= std::min(last_parent, commit_parent); //这里对last commit做更改了。降低他的last commit } } } } if (exceeds_capacity || !can_use_writesets) { m_writeset_history_start= sequence_number; //如果超过最大设置 清空writeset history。从当前sequence 重新记录 也就是最小的那个事务seqnuce number m_writeset_history.clear();//清空真个MAP } WRITESET_SESSION 怎麼做? 前面有提到過 WRITESET_SESSION 是基於 WRITESET 的基礎上繼續處理的，WRITESET_SESSION 要做到的是同一個 session 的 Transaction 不能在 Replica 並行回放，要實現非常簡單：\n1 2 3 4 5 6 7 8 9 10 int64 session_parent= thd-\u0026gt;rpl_thd_ctx.dependency_tracker_ctx(). get_last_session_sequence_number(); //取本session的上一次事务的seq number if (session_parent != 0 \u0026amp;\u0026amp; session_parent \u0026lt; sequence_number) //如果本session已经做过事务并且本次当前的seq number大于上一次的seq number commit_parent= std::max(commit_parent, session_parent); //说明这个session做过多次事务不允许并发，修改为order_commit生成的last commit thd-\u0026gt;rpl_thd_ctx.dependency_tracker_ctx(). set_last_session_sequence_number(sequence_number); //设置session_parent的值为本次seq number的值 關於 binlog_transaction_dependency_history_size 參數說明 該參數默認值為 25000，代表的是 WriteSet 裡元素的數量。\n從前面 WriteSet 實現細節說明中我們可以知道修改一行數據可能會產生多個 Hash，所以這個值不會等於修改的行數，可以理解為如下：\n5.7 版本：binlog_transaction_dependency_history_size = 修改的行數 * ( 1 + UK 數量 ) * 2 8.0 版本：binlog_transaction_dependency_history_size = 修改的行數 * ( 1 + UK 數量 ) 備註：不同原因在於 5.7 會生成包含 collation 和不包含 collation，在 8.0 中則沒有。\n如果將這個參數加大，那麼 Source 上的 WriteSet 就能放越多的元素，也就是說 Transaction 可以生成更小的 last_commited，這在 Replica 上就能提高並行回放的效率，當然缺點就是在 Source 會消耗更多的資源。\nWriteSet 不適用情境 以下情境不適用 WriteSet，MySQL 會自動退回使用 commit_order (基於 group commit) 模式\n沒有 PK 也沒有 UK DDL session 的 hash 算法換 history 不同 Transaction 更新了有 Forign key 關聯的欄位 slave_preserve_commit_order 介紹 當開啟 MTS 且 slave_parallel_type = LOGICAL_CLOCK (不論具體是基於 commit_order 還是 writeset) 的時候，有可能會發生 Source 和 Replica 執行順序不同的情況，雖然這並不會導致資料不一致的狀況，但是可能會發生在 Source 上先看到 T1 才看到 T2 卻在 Replica 上卻是先看到 T2 才看到 T1 執行，也就是說在 Source 和 Replica 各自的 binlog 歷史紀錄順序也會不一致，沒有保證 Causal Consistency。\n💡 Causal Consistency (因果一致性) 意思是如果兩個事件有因果關係，那麼在所有節點都必須能觀測到這種因果關係。\n如果評估業務需要保證Causal Consistency，除了不使用 MTS 使用單線程 replication 也可以透過設置 slave_preserve_commit_order=ON 來避免，這會讓 Replica 上回放的 Transaction 在進入 flush 階段之前會先等待 sequence_number 之前的 Transaction 先進入 flush 階段。\nGAP 如果 slave_preserve_commit_order = OFF 除了上面提到 Causal Consistency 還有一個問題在官方文檔中稱為 GAP。\n開啟 MTS 時透過 show slave status 查看 Exec_Source_Log_Pos 指的是 low-watermark 也就是保證這個 postition 之前的 Transaction 都已經 commit，但是該 postition 之後的 Transaction 有可能 commit 也可能沒有 commit，\n相關參數 slave_parallel_workers (5.6 ~ 8.0.25)、replica_parallel_workers (8.0.26 ~)\n設定要在 replica 並行的 thread 數量。\n如果 slave 有多個 channel，則每個 channel 都會有此數量的 thread。\n設置此參數後必須重新 START REPLICA 才會生效。\nslave_parallel_type (5.7 ~ 8.0.25)、replica_parallel_type (8.0.26 ~ 8.0.29)\n設定在 replica 上允許哪些 Transaction 並行回放\nDATABASE：Transaction 必須作用於不同 Database 才能並行。 LOGICAL_CLOCK：基於 Source 寫入 binlog 的 timestamp 來決定 Transaction 的並行，也就是基於 Group Commit。 建議將 binlog_transaction_dependency_tracking 設置為 WRITESET 或 WRITESET_SESSION ，這樣在合適的情況下會走 WriteSet 來提高並行度。\n預計 8.0.29 之後棄用此參數，總是以 LOGICAL_CLOCK 的方式運行。\nbinlog_group_commit_sync_delay\n控制 binlog commit 之後等待 N 微秒後才 fsync 到 Disk，設置越大單個 Group 可以有更多時間等到更多的 Transaction 一起 fsync Disk，減少 fsync 的次數及減少每個 Transaction commit 的單位時間。\n此外適度的增加對於以下設置的 MTS 也能增加在 Slave 的並行度：\n1 2 3 4 5 # Master binlog_transaction_dependency_tracking = COMMIT_ORDER # Slave slave_parallel_type = LOGICAL_CLOCK 注意：會增加 server 上 transaction 的延遲，也就是 client 端收到 transaction commit 的時間會變晚，另外相應的會增加資源的競爭，因此需評估最好的設置。\n補充：在有 Group Commit 之後，sync_binlog 的單位指的是 Group 而不是 Transaction，例如：sync_binlog = 1000，表示的不是每 1000 個 Transaction 就 sync binlog，而是每 1000 個 Group 才 sync binlog。\nbinlog_group_commit_sync_no_delay_count\n在 Group commit 中等待的 N 個 Transaction 後就不等待 binlog_group_commit_sync_delay 設置的時間直接開始 sync binlog。\n當 binlog_group_commit_sync_delay = 0 ，此參數無效。\nslave_preserve_commit_order (5.7 ~ 8.0.25)、replica_preserve_commit_order (8.0.26 ~)\n只有當 slave_parallel_type = LOGICAL_CLOCK 且 log-slave-updates 開啟時才能設置。\n當設置為 0 或 OFF 時，在 Replica 上的讀取操作無法滿足 Causal Consistency ，在 Source 和 Replica 上 Transaction 在 binlog 中可能有不同的寫入順序，另外在檢查 Replica 上最近執行的 Transaction 無法保證對應到 Source 上該 Transaction 位置之前的 Transaction 都已經執行完畢。\n設置為 1 或 ON 確保 Transaction 在執行時按照在 relay log 中的順序，這可以讓 Master 和 Replica 有相同的 Transaction history log，也就是符合 Causal Consistency。\nbinlog_transaction_dependency_tracking (5.7.22 ~)\n指定 Source 依據什麼方式來生成 Transaction 之間的依賴關係寫入 binlog，協助 Replica 確定那些 Transaction 能夠並行執行。\n必須設置 replica_parallel_type 為 LOGICAL_CLOCK。\n有以下三種值：\nCOMMIT_ORDER：使用 5.7 Group commit 的方式判斷。 WRITESET：使用 WriteSet 的方式判斷 Transaction 是否有衝突。 WRITESET_SESSION：WRITESET 的基礎上保證同一個 session 內的 Transaction 不可並行。 binlog_transaction_dependency_history_size (8.0 ~)\nWriteSet 會判斷 Transaction 之間是否衝突，因此需要將 commit 的 Transaction 修改的行 hash 後暫時保存在內存。\n此參數用來設定儲存的 hash 上限，超過此上限會清除先前的歷史紀錄。\n若 Source 性能有餘裕可以考慮提升此參數，進一步提高 Replica 的並行度。\ntransaction_write_set_extraction\n設定 WriteSet 使用的 Hash 演算法。\nMySQL 5.7 預設為 OFF，MySQL 8.0.26 後棄用，一般不用特別調整。\n官方測試數據 以下為官方使用SYSBENCH進行壓測的圖表，可以觀察到：\n在 Source 低並行率的情況，WRITESET 的機制下 Replica 仍舊能夠有良好的並行率。 當 Source 並行率越高，COMMIT_ORDER 和 WriteSet 差距會縮小。 親自測試 環境：Mysql 8.0.12，測試前stop slave，待sysbench跑完後在start slave\n確認在performance_schema中，MTS相關的統計ENABLED皆有開啟(YES)\n(*啟用或禁用transaction event的收集)\n(分別為當前的transaction event，每個線程最近的transaction event，global(跨線程)最近的transaction event)\n查詢MTS並行度的語法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 select thread_id,count_star from events_transactions_summary_by_thread_by_event_name where thread_id in ( select thread_id from replication_applier_status_by_worker ); OR USE test; CREATE VIEW rep_thread_count AS SELECT a.THREAD_ID AS THREAD_ID,a.COUNT_STAR AS COUNT_STAR FROM performance_schema.events_transactions_summary_by_thread_by_event_name a WHERE a.THREAD_ID in (SELECT b.THREAD_ID FROM performance_schema.replication_applier_status_by_worker b); SELECT SUM(COUNT_STAR) FROM rep_thread_count INTO @total; SELECT 100*(COUNT_STAR/@total) AS thread_usage FROM rep_thread_count; #replication_applier_status_by_worker可以查看replication各個線程的運作狀況 #events_transactions_summary_by_thread_by_event_name彙總的每個線程的事件名稱，包含已關閉線程 #透過replication...table找出正在運作的線程再到event...table找到他們的count_star(執行的transaction數量) 首次壓測以Threads 1 進行10分鐘壓測\n在commit_order下測試(即MySQL 5.7使用)\n在WriteSet下測試(MySQL 8.0新方案)\n接著試試看Threads 128進行10分鐘壓測\n在commit_order下測試(即MySQL 5.7使用)\n在WriteSet下測試(MySQL 8.0新方案)\n測試結果基本上和官方提供的差不多，主要是解決在Master低並行度的情況下，提高MTS的效率。\nLOG 當開啟 MTS 且 log_error_verbosity = 3 (NOTE) 時，會在\n1 2023-01-30T03:08:36.440821Z 6 [Note] [MY-010559] [Repl] Multi-threaded slave statistics for channel \u0026#39;\u0026#39;: seconds elapsed = 277; events assigned = 20795393; worker queues filled over overrun level = 0; waited due a Worker queue full = 0; waited due the total size = 0; waited at clock conflicts = 12923330700 waited (count) when Workers occupied = 0 waited when Workers occupied = 0 懶人包 MySQL 5.7~5.7.21 參數設定 Source (Master)\n1 2 3 # 以下非必須，依據實際情況評估調整 binlog_group_commit_sync_delay = ? binlog_group_commit_sync_no_delay_count = ? Replica (Slave)\n1 2 3 4 # 推薦調整 slave_parallel_workers = ? slave_parallel_type = LOGICAL_CLOCK slave_preserve_commit_order = ON MySQL 5.7.22~8.0.XX 參數設定 Source (Master)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 推薦調整 binlog_transaction_dependency_tracking = WRITESET_SESSION transaction_write_set_extraction = XXHASH64 # 以下依據實際情況評估調整 # 優先調整 binlog_transaction_dependency_history_size = ? # 調整優先度低，因為退化回 commit order 時才有效，情境為： # 1. 沒有 pk 或 uk # 2. DDL 語句 # 3. Transaction 的更新包含 FK # 4. history 剛被清空 # 5. 同一個 session 的 Transaction (WRITESET_SESSION) binlog_group_commit_sync_delay = ? binlog_group_commit_sync_no_delay_count = ? Replica (Slave)\n1 2 3 4 # 推薦調整 slave_parallel_workers = ? slave_parallel_type = LOGICAL_CLOCK slave_preserve_commit_order = ON MTS 效率確認 調整後可以使用以下語法查看調整後 MTS 並行的效率，理想的情況下同一個 channel 的每個 sql thread 的 count_star 應該差不多：\n1 2 3 4 5 6 7 8 9 10 11 12 -- mysql 5.7 需先開啟以下設定 update performance_schema.setup_consumers set enabled= \u0026#39;yes\u0026#39; where name like \u0026#39;events_transactions%\u0026#39; update performance_schema.setup_instruments set enabled= \u0026#39;yes\u0026#39; where name like \u0026#39;transaction\u0026#39; -- mysql 5.7 需先開啟以上設定 SELECT replication_status.CHANNEL_NAME, replication_status.thread_id, enent_summary.count_star FROM performance_schema.events_transactions_summary_by_thread_by_event_name AS enent_summary INNER JOIN performance_schema.replication_applier_status_by_worker AS replication_status USING(thread_id) BUG MySQL Bugs: #103636: Slave hangs with slave_preserve_commit_order On\n說明：當 replica 設置了 replica_preserve_commit_order = 1 在高負載下長時間使用時，可能會用完 commit order sequence tickets 導致 applier 掛起 (hang) 並且無期限的持續等待 commit order queue。\n影響版本：MySQL 8.0.28 之前\n修復版本： MySQL 8.0.28\ngithub 資訊：BUG#32891221 REPLICA HANGS WITH REPLICA_PRESERVE_COMMIT_ORDER ON · mysql/mysql-server@f6bb5e7 · GitHub\n參考 MySQL · 特性分析 · 8.0 WriteSet 并行复制\n速度提升5~10倍，基于WRITESET的MySQL并行复制 #M1013# - VicLW - 博客园 (cnblogs.com)\nMySQL 5.7并行复制中并行的真正含义_仲培艺的博客-CSDN博客\nMySQL · 特性分析 · LOGICAL_CLOCK 并行复制原理及实现分析 (taobao.org)\nMySQL :: WL#6314: MTS: Prepared transactions slave parallel applier\nMySQL :: WL#7165: MTS: Optimizing MTS scheduling by increasing the parallelization window on master\nMySQL-组提交与并行复制 - 掘金 (juejin.cn)\nMySQL :: WL#9556: Writeset-based MTS dependency tracking on master\nMySQL · 引擎特性 · Group Replication内核解析 (taobao.org)\n社区投稿 | 基于 WRITESET 的并行复制方式 (actionsky.com)\nMySQL :: Improving the Parallel Applier with Writeset-based Dependency Tracking\nMySQL Group Replication冲突检测机制再剖析 - 知乎 (zhihu.com)\n深入浅析一致性模型之Causal Consistency - 知乎 (zhihu.com)\nMySQL :: MySQL 8.0 Reference Manual :: 17.5.1.34 Replication and Transaction Inconsistencies\nMySQL :: MySQL 8.0 Reference Manual :: 13.4.2.8 START REPLICA Statement\nMySQL :: MySQL 8.0 Reference Manual :: 13.7.7.35 SHOW REPLICA STATUS Statement\n","date":"2025-04-07T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-mts/","title":"並行複製 (Multi-Thread Slave, MTS)"},{"content":"曾經在正式環境遇過一個特殊的情境，我們都知道 DEADLOCK 的成因在於不同的加鎖順序，加上這兩句 WHERE條件是相似的語法，卻還是遇到了 DEADLOCK，因此我的第一個反應是兩個 TRANSACTION 中已執行語句的 LOCK 未釋放，導致互相阻塞對方引起的。不過事後查看 LOG 加上詢問開發確認了該語句皆是單獨執行，只好回頭透過 EXPLAIN 確認執行計畫，發現兩句語法走了不同的 INDEX以此找到思路，最後了解發生成因並找到解決方案，更重要的是知道了 **隱式鎖(implicit lock)**的存在。\n重現 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 -- 準備資料 CREATE DATABASE test_g_order; USE test_g_order; CREATE TABLE `g_order` ( `id` bigint(20) unsigned NOT NULL COMMENT \u0026#39;注單ID\u0026#39;, `round_id` bigint(20) unsigned NOT NULL COMMENT \u0026#39;期數ID\u0026#39;, `site` char(10) NOT NULL COMMENT \u0026#39;站台代號\u0026#39;, `user` varchar(10) NOT NULL COMMENT \u0026#39;使用者ID\u0026#39;, `status` tinyint(1) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;注單狀態\u0026#39;, `game_id` varchar(20) NOT NULL COMMENT \u0026#39;遊戲ID\u0026#39;, `wager` varchar(50) NOT NULL COMMENT \u0026#39;玩法\u0026#39;, `bet_info` json NOT NULL COMMENT \u0026#39;下注資訊\u0026#39;, `bet` decimal(25,4) NOT NULL COMMENT \u0026#39;下注額度(無負值)\u0026#39;, `pay` decimal(25,4) NOT NULL COMMENT \u0026#39;派彩金額(無負值)\u0026#39;, `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;注單創建時間\u0026#39;, `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT \u0026#39;注單更新時間\u0026#39;, `round_closed_at` timestamp NOT NULL DEFAULT \u0026#39;0000-00-00 00:00:00\u0026#39; COMMENT \u0026#39;關盤時間\u0026#39;, `odds_key` varchar(50) GENERATED ALWAYS AS (json_unquote(json_extract(`bet_info`,\u0026#39;$.odds.key\u0026#39;))) VIRTUAL, PRIMARY KEY (`id`,`round_closed_at`), KEY `ID_report` (`status`,`site`,`user`,`created_at`), KEY `ID_settle` (`round_id`,`status`,`game_id`,`wager`,`odds_key`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=\u0026#39;訪客注單\u0026#39;; INSERT INTO `g_order` (`id`, `round_id`, `site`, `user`, `status`, `game_id`, `wager`, `bet_info`, `bet`, `pay`, `created_at`, `updated_at`, `round_closed_at`) VALUES (1,1,\u0026#39;site_1\u0026#39;,\u0026#39;user_1\u0026#39;,1,\u0026#39;game_1\u0026#39;,\u0026#39;any\u0026#39;,\u0026#39;{\\\u0026#34;odds\\\u0026#34;: {\\\u0026#34;key\\\u0026#34;: \\\u0026#34;2\\\u0026#34;}}\u0026#39;,10000.0000,0.0000,\u0026#39;2019-07-02 10:33:28\u0026#39;,\u0026#39;2019-07-04 07:00:32\u0026#39;,\u0026#39;2019-07-02 10:30:00\u0026#39;), (2,1,\u0026#39;site_1\u0026#39;,\u0026#39;user_1\u0026#39;,1,\u0026#39;game_1\u0026#39;,\u0026#39;any\u0026#39;,\u0026#39;{\\\u0026#34;odds\\\u0026#34;: {\\\u0026#34;key\\\u0026#34;: \\\u0026#34;3\\\u0026#34;}}\u0026#39;,10000.0000,0.0000,\u0026#39;2019-07-02 10:33:35\u0026#39;,\u0026#39;2019-07-04 07:00:32\u0026#39;,\u0026#39;2019-07-02 10:30:00\u0026#39;), (3,1,\u0026#39;site_1\u0026#39;,\u0026#39;user_1\u0026#39;,1,\u0026#39;game_1\u0026#39;,\u0026#39;sum\u0026#39;,\u0026#39;{\\\u0026#34;odds\\\u0026#34;: {\\\u0026#34;key\\\u0026#34;: \\\u0026#34;ALL\\\u0026#34;}}\u0026#39;,20000.0000,0.0000,\u0026#39;2019-07-02 10:33:42\u0026#39;,\u0026#39;2019-07-04 07:00:32\u0026#39;,\u0026#39;2019-07-02 10:30:00\u0026#39;); -- 同時執行兩句語法，為了還原當時情境需使用 force index 指定索引 UPDATE test_g_order.g_order force index(ID_report) SET status = 3, pay = bet * 10 WHERE round_closed_at = \u0026#39;2019-07-02 10:30:00\u0026#39; AND round_id = 1 AND game_id = \u0026#39;game_1\u0026#39; AND wager = \u0026#39;compare\u0026#39; AND status = 1 AND odds_key IN (\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;); UPDATE test_g_order.g_order force index(ID_settle) SET status = 3, pay = 0 WHERE round_closed_at = \u0026#39;2019-07-02 10:30:00\u0026#39; AND round_id = 1 AND game_id = \u0026#39;game_1\u0026#39; AND wager = \u0026#39;any\u0026#39; AND status = 1; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 ------------------------ LATEST DETECTED DEADLOCK ------------------------ 2020-09-29 03:38:46 0x7f22347f8700 *** (1) TRANSACTION: TRANSACTION 12800, ACTIVE 0 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s) MySQL thread id 11343, OS thread handle 139784886118144, query id 803 10.17.117.203 sysbench Searching rows for update UPDATE g_order force index(ID_report) SET status = 3, winlose = 1, updated_at = CURTIME(), paid_amount = bet_amount * bet_info-\u0026gt;\u0026#39;$.odds.value\u0026#39; WHERE round_closed_at = \u0026#39;2019-07-02 10:34:00\u0026#39; AND round_id = 4781292 AND game_id = \u0026#39;652B75-SSC5\u0026#39; AND wager = \u0026#39;compare\u0026#39; AND status = 1 AND odds_key IN (\u0026#39;1:OVER\u0026#39;,\u0026#39;2:UNDER\u0026#39;,\u0026#39;3:OVER\u0026#39;,\u0026#39;4:UNDER\u0026#39;,\u0026#39;5:OVER\u0026#39;) *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 139 page no 3 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 12800 lock_mode X locks rec but not gap waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 22; compact format; info bits 0 0: len 8; hex 0000a40000001cdb; asc ;; 1: len 4; hex 5d1b3318; asc ] 3 ;; 2: len 6; hex 0000000031ff; asc 1 ;; 3: len 7; hex 78000001700110; asc x p ;; 4: len 8; hex 000000000048f4ea; asc H ;; 5: len 6; hex 323238373335; asc 228735;; 6: len 5; hex 3530306370; asc 500cp;; 7: len 30; hex 35656137636538392d373365332d343565372d393932342d636631383836; asc 5ea7ce89-73e3-45e7-9924-cf1886; (total 36 bytes); 8: len 1; hex 00; asc ;; 9: len 1; hex 03; asc ;; 10: len 11; hex 3036303232452d46415433; asc 06022E-FAT3;; 11: len 3; hex 616e74; asc ant;; 12: len 3; hex 434e59; asc CNY;; 13: len 18; hex 616e792d657175616c2d6e6f742d73616d65; asc any-equal-not-same;; 14: len 30; hex 0002004d001200040016000500001b000249006f6464736974656d730200; asc M I oddsitems ; (total 78 bytes); 15: len 1; hex 02; asc ;; 16: len 12; hex 800000000000000027100000; asc \u0026#39; ;; 17: len 12; hex 800000000000000026480000; asc \u0026amp;H ;; 18: len 12; hex 800000000000000000000000; asc ;; 19: len 4; hex 5d1b32f8; asc ] 2 ;; 20: len 4; hex 5f72ac46; asc _r F;; 21: len 0; hex ; asc ;; *** (2) TRANSACTION: TRANSACTION 12799, ACTIVE 0 sec updating or deleting mysql tables in use 1, locked 1 5 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 1 MySQL thread id 11342, OS thread handle 139784886388480, query id 802 10.17.117.203 sysbench updating UPDATE g_order force index(ID_settle) SET status = 3, winlose = 2, updated_at = CURTIME(), paid_amount = 0 WHERE round_closed_at = \u0026#39;2019-07-02 10:34:00\u0026#39; AND round_id = 4781290 AND game_id = \u0026#39;06022E-FAT3\u0026#39; AND wager = \u0026#39;any-equal-not-same\u0026#39; AND status = 1 *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 139 page no 3 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 12799 lock_mode X locks rec but not gap Record lock, heap no 2 PHYSICAL RECORD: n_fields 22; compact format; info bits 0 0: len 8; hex 0000a40000001cdb; asc ;; 1: len 4; hex 5d1b3318; asc ] 3 ;; 2: len 6; hex 0000000031ff; asc 1 ;; 3: len 7; hex 78000001700110; asc x p ;; 4: len 8; hex 000000000048f4ea; asc H ;; 5: len 6; hex 323238373335; asc 228735;; 6: len 5; hex 3530306370; asc 500cp;; 7: len 30; hex 35656137636538392d373365332d343565372d393932342d636631383836; asc 5ea7ce89-73e3-45e7-9924-cf1886; (total 36 bytes); 8: len 1; hex 00; asc ;; 9: len 1; hex 03; asc ;; 10: len 11; hex 3036303232452d46415433; asc 06022E-FAT3;; 11: len 3; hex 616e74; asc ant;; 12: len 3; hex 434e59; asc CNY;; 13: len 18; hex 616e792d657175616c2d6e6f742d73616d65; asc any-equal-not-same;; 14: len 30; hex 0002004d001200040016000500001b000249006f6464736974656d730200; asc M I oddsitems ; (total 78 bytes); 15: len 1; hex 02; asc ;; 16: len 12; hex 800000000000000027100000; asc \u0026#39; ;; 17: len 12; hex 800000000000000026480000; asc \u0026amp;H ;; 18: len 12; hex 800000000000000000000000; asc ;; 19: len 4; hex 5d1b32f8; asc ] 2 ;; 20: len 4; hex 5f72ac46; asc _r F;; 21: len 0; hex ; asc ;; Record lock, heap no 3 PHYSICAL RECORD: n_fields 22; compact format; info bits 0 0: len 8; hex 0000a40000001cdc; asc ;; 1: len 4; hex 5d1b3318; asc ] 3 ;; 2: len 6; hex 0000000031fc; asc 1 ;; 3: len 7; hex 760000016f01c6; asc v o ;; 4: len 8; hex 000000000048f4ea; asc H ;; 5: len 6; hex 323238373335; asc 228735;; 6: len 5; hex 3530306370; asc 500cp;; 7: len 30; hex 35656137636538392d373365332d343565372d393932342d636631383836; asc 5ea7ce89-73e3-45e7-9924-cf1886; (total 36 bytes); 8: len 1; hex 00; asc ;; 9: len 1; hex 01; asc ;; 10: len 11; hex 3036303232452d46415433; asc 06022E-FAT3;; 11: len 3; hex 616e74; asc ant;; 12: len 3; hex 434e59; asc CNY;; 13: len 18; hex 616e792d657175616c2d6e6f742d73616d65; asc any-equal-not-same;; 14: len 30; hex 0002004d001200040016000500001b000249006f6464736974656d730200; asc M I oddsitems ; (total 78 bytes); 15: len 1; hex 02; asc ;; 16: len 12; hex 800000000000000027100000; asc \u0026#39; ;; 17: len 12; hex 800000000000000026480000; asc \u0026amp;H ;; 18: len 12; hex 800000000000000000000000; asc ;; 19: len 4; hex 5d1b32ff; asc ] 2 ;; 20: len 4; hex 5f72ac45; asc _r E;; 21: len 0; hex ; asc ;; *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 139 page no 4 n bits 72 index ID_report of table `test_g_order`.`g_order` trx id 12799 lock_mode X locks rec but not gap waiting Record lock, heap no 2 PHYSICAL RECORD: n_fields 6; compact format; info bits 0 0: len 1; hex 01; asc ;; 1: len 5; hex 3530306370; asc 500cp;; 2: len 30; hex 35656137636538392d373365332d343565372d393932342d636631383836; asc 5ea7ce89-73e3-45e7-9924-cf1886; (total 36 bytes); 3: len 4; hex 5d1b32f8; asc ] 2 ;; 4: len 8; hex 0000a40000001cdb; asc ;; 5: len 4; hex 5d1b3318; asc ] 3 ;; *** WE ROLL BACK TRANSACTION (1) 單獨測試 查看兩句語法單獨執行的 LOCK 狀況\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 -- Transaction 1 SET GLOBAL innodb_status_output_locks=ON; begin; UPDATE test_g_order.g_order force index(ID_report) SET status = 3, pay = bet * 10 WHERE round_closed_at = \u0026#39;2019-07-02 10:30:00\u0026#39; AND round_id = 1 AND game_id = \u0026#39;game_1\u0026#39; AND wager = \u0026#39;compare\u0026#39; AND status = 1 AND odds_key IN (\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;); show engine innodb status\\G ------------ TRANSACTIONS ------------ Trx id counter 5901 Purge done for trx\u0026#39;s n:o \u0026lt; 5900 undo n:o \u0026lt; 0 state: running but idle History list length 0 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 421338064415296, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421338064414440, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 5900, ACTIVE 6 sec 3 lock struct(s), heap size 1136, 7 row lock(s) MySQL thread id 20189, OS thread handle 139863067211520, query id 44318 localhost root starting show engine innodb status **# 第一步驟是在整個TABLE上加上 IX鎖 (意向排他鎖)，來預防其他third對整個TABLE加S鎖或X鎖** TABLE LOCK table `test_g_order`.`g_order` trx id 5900 lock mode IX **# 第二步因為透過index ID_report 來找符合的row，因此在符合的INDEX加上 X鎖(next-key lock)** RECORD LOCKS space id 4 page no 5 n bits 72 index ID_report of table `test_g_order`.`g_order` trx id 5900 lock_mode **# 因為目前 ID_report 所有的值都符合條件，所以也在正無窮上加 nexk-key lock** Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; ... **# 第三步便是透過INDEX找到Primay key並在其上加上X鎖 (Record lock)** RECORD LOCKS space id 4 page no 4 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 5900 lock_mode X locks rec but not gap ... **# 因為第一步驟已經在正無窮加上 next-key lock，所以不需要補上 gap lock** SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+---------------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+---------------+-------------+ | 5950 | g_order | NULL | TABLE | IX | GRANTED | | 5950 | g_order | ID_report | RECORD | X | GRANTED | | 5950 | g_order | PRIMARY | RECORD | X,REC_NOT_GAP | GRANTED | +------+-------------+------------+-----------+---------------+-------------+ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 -- Transaction 2 -- 開啟moniter，觀察lock情形 SET GLOBAL innodb_status_output_locks=ON; begin; UPDATE test_g_order.g_order force index(ID_settle) SET status = 3, pay = 0 WHERE round_closed_at = \u0026#39;2019-07-02 10:30:00\u0026#39; AND round_id = 1 AND game_id = \u0026#39;game_1\u0026#39; AND wager = \u0026#39;any\u0026#39; AND status = 1; show engine innodb status\\G ------------ TRANSACTIONS ------------ Trx id counter 5899 Purge done for trx\u0026#39;s n:o \u0026lt; 5899 undo n:o \u0026lt; 0 state: running but idle History list length 2 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 421338064415296, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421338064414440, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 5894, ACTIVE 10 sec 4 lock struct(s), heap size 1136, 5 row lock(s), undo log entries 2 MySQL thread id 20189, OS thread handle 139863067211520, query id 44245 localhost root starting show engine innodb status **# 第一步驟是在整個TABLE上加上 IX鎖 (意向排他鎖)，來預防其他third對整個TABLE加S鎖或X鎖** TABLE LOCK table `test_g_order`.`g_order` trx id 5894 lock mode IX **# 第二步因為透過index ID_settle 來找符合的row，因此在符合的INDEX加上 X鎖(next-key lock)** RECORD LOCKS space id 4 page no 6 n bits 72 index ID_settle of table `test_g_order`.`g_order` trx id 5894 lock_mode X **# 第三步便是透過INDEX找到Primay key並在其上加上X鎖 (Record lock)** RECORD LOCKS space id 4 page no 4 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 5894 lock_mode X locks rec but not gap **# 第四步：需要在第一個不符合條件的Index ID_settle 加上X鎖 (gap lock)，避免INSERT新的資料** RECORD LOCKS space id 4 page no 6 n bits 72 index ID_settle of table `test_g_order`.`g_order` trx id 5894 lock_mode X locks gap before re SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+---------------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+---------------+-------------+ | 5943 | g_order | NULL | TABLE | IX | GRANTED | | 5943 | g_order | ID_settle | RECORD | X | GRANTED | | 5943 | g_order | PRIMARY | RECORD | X,REC_NOT_GAP | GRANTED | | 5943 | g_order | ID_settle | RECORD | X,GAP | GRANTED | +------+-------------+------------+-----------+---------------+-------------+ 先執行 Transaction 1 再執行 Transaction 2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 ------------ TRANSACTIONS ------------ Trx id counter 11644 Purge done for trx\u0026#39;s n:o \u0026lt; 11642 undo n:o \u0026lt; 0 state: running but idle History list length 3 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 421338064415296, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421338064414440, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 11643, ACTIVE 6 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s) MySQL thread id 141084, OS thread handle 139863066326784, query id 287362 10.17.117.203 root Searching rows for update UPDATE test_g_order.g_order force index(ID_settle) SET status = 3, pay = 0 WHERE round_closed_at = \u0026#39;2019-07-02 10:30:00\u0026#39; AND round_id = 1 AND game_id = \u0026#39;game_1\u0026#39; AND wager = \u0026#39;any\u0026#39; AND status = 1 ------- TRX HAS BEEN WAITING 6 SEC FOR THIS LOCK TO BE GRANTED: **# Transaction 2 等待 Transaction 1 釋放 PRIMARY KEY 上的 LOCK** RECORD LOCKS space id 216 page no 4 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 11643 lock_mode X locks rec but not gap waiting **# Transaction 2** ------------------ **# 第一步驟是在整個TABLE上加上 IX鎖 (意向排他鎖)，來預防其他third對整個TABLE加S鎖或X鎖** TABLE LOCK table `test_g_order`.`g_order` trx id 11643 lock mode IX **# 第二步因為透過index ID_settle 來找符合的row，因此在符合的INDEX加上 X鎖(next-key 包含了gap)** RECORD LOCKS space id 216 page no 6 n bits 72 index ID_settle of table `test_g_order`.`g_order` trx id 11643 lock_mode X **# 第三步便是透過INDEX找到Primay key並在其上加上X鎖 (Record lock不含gap)** RECORD LOCKS space id 216 page no 4 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 11643 lock_mode X locks rec but not gap waiting **# Transaction 1** ---TRANSACTION 11642, ACTIVE 7 sec 3 lock struct(s), heap size 1136, 7 row lock(s) MySQL thread id 141082, OS thread handle 139863067801344, query id 287365 10.17.117.203 root starting show engine innodb status **# 第一步驟是在整個TABLE上加上 IX鎖 (意向排他鎖)，來預防其他third對整個TABLE加S鎖或X鎖** TABLE LOCK table `test_g_order`.`g_order` trx id 11642 lock mode IX **# 第二步因為透過index ID_report 來找符合的row，因此在符合的INDEX加上 X鎖(next-key 包含了gap)** RECORD LOCKS space id 216 page no 5 n bits 72 index ID_report of table `test_g_order`.`g_order` trx id 11642 lock_mode X **# 因為目前 ID_report 所有的值都符合條件，所以也在正無窮上加 nexk-key lock** Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0 0: len 8; hex 73757072656d756d; asc supremum;; **# 第三步便是透過INDEX找到Primay key並在其上加上X鎖 (Record lock不含gap)** RECORD LOCKS space id 216 page no 4 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 11642 lock_mode X locks rec but not gap SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +-------+-------------+------------+-----------+---------------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +-------+-------------+------------+-----------+---------------+-------------+ | 11642 | g_order | NULL | TABLE | IX | GRANTED | | 11642 | g_order | ID_report | RECORD | X | GRANTED | | 11642 | g_order | PRIMARY | RECORD | X,REC_NOT_GAP | GRANTED | | 11643 | g_order | NULL | TABLE | IX | GRANTED | | 11643 | g_order | ID_settle | RECORD | X | GRANTED | | 11643 | g_order | PRIMARY | RECORD | X,REC_NOT_GAP | WAITING | +-------+-------------+------------+-----------+---------------+-------------+ 先執行 Transaction 2 再執行 Transaction 1，可以發現 Transaction 2 多了一個 LOCK\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 ------------ TRANSACTIONS ------------ Trx id counter 5957 Purge done for trx\u0026#39;s n:o \u0026lt; 5956 undo n:o \u0026lt; 0 state: running but idle History list length 2 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 421338064415296, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 421338064414440, not started 0 lock struct(s), heap size 1136, 0 row lock(s) ---TRANSACTION 5956, ACTIVE 12 sec starting index read mysql tables in use 1, locked 1 LOCK WAIT 2 lock struct(s), heap size 1136, 1 row lock(s) MySQL thread id 25903, OS thread handle 139863067506432, query id 56073 localhost root Searching rows for update UPDATE test_g_order.g_order force index(ID_settle) SET status = 3, pay = bet * 10 WHERE round_closed_at = \u0026#39;2019-07-02 10:30:00\u0026#39; AND round_id = 1 AND game_id = \u0026#39;game_1\u0026#39; AND wager = \u0026#39;compare\u0026#39; AND status = 1 AND odds_key IN (\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;) ------- TRX HAS BEEN WAITING 12 SEC FOR THIS LOCK TO BE GRANTED: **# Transaction 1 等待 Transaction 2 釋放 ID_report Index 上的 LOCK** RECORD LOCKS space id 4 page no 5 n bits 72 index ID_report of table `test_g_order`.`g_order` trx id 5956 lock_mode X waiting **# Transaction 1** ------------------ **# 第一步驟是在整個TABLE上加上 IX鎖 (意向排他鎖)，來預防其他third對整個TABLE加S鎖或X鎖** TABLE LOCK table `test_g_order`.`g_order` trx id 5956 lock mode IX **# 第二步因為透過index ID_report 來找符合的row，因此在符合的INDEX加上 X鎖(next-key 包含了gap)** RECORD LOCKS space id 4 page no 5 n bits 72 index ID_report of table `test_g_order`.`g_order` trx id 5956 lock_mode X waiting **# Transaction 2** ---TRANSACTION 5951, ACTIVE 18 sec 5 lock struct(s), heap size 1136, 6 row lock(s), undo log entries 2 MySQL thread id 25899, OS thread handle 139863067211520, query id 56077 localhost root starting show engine innodb status **# 第一步驟是在整個TABLE上加上 IX鎖 (意向排他鎖)，來預防其他third對整個TABLE加S鎖或X鎖** TABLE LOCK table `test_g_order`.`g_order` trx id 5951 lock mode IX **# 第二步因為透過index ID_settle 來找符合的row，因此在符合的INDEX加上 X鎖(next-key 包含了gap)** RECORD LOCKS space id 4 page no 6 n bits 72 index ID_settle of table `test_g_order`.`g_order` trx id 5951 lock_mode X **# 第三步便是透過INDEX找到Primay key並在其上加上X鎖 (Record lock不含gap)** RECORD LOCKS space id 4 page no 4 n bits 72 index PRIMARY of table `test_g_order`.`g_order` trx id 5951 lock_mode X locks rec but not gap **# 第四步Index ID_settle 加上X鎖 (Gap Lock)** RECORD LOCKS space id 4 page no 6 n bits 72 index ID_settle of table `test_g_order`.`g_order` trx id 5951 lock_mode X locks gap before rec **# 第五步Index ID_report 加上X鎖 (Record lock不含gap)** RECORD LOCKS space id 4 page no 5 n bits 72 index ID_report of table `test_g_order`.`g_order` trx id 5951 lock_mode X locks rec but not gap SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+---------------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+---------------+-------------+ | 5956 | g_order | NULL | TABLE | IX | GRANTED | | 5956 | g_order | ID_report | RECORD | X | WAITING | | 5951 | g_order | NULL | TABLE | IX | GRANTED | | 5951 | g_order | ID_settle | RECORD | X | GRANTED | | 5951 | g_order | PRIMARY | RECORD | X,REC_NOT_GAP | GRANTED | | 5951 | g_order | ID_settle | RECORD | X,GAP | GRANTED | | 5951 | g_order | ID_report | RECORD | X,REC_NOT_GAP | GRANTED | +------+-------------+------------+-----------+---------------+-------------+ 經由以上測試，我們確認了此例的 Lock 的成因如下表格－\nTransaction 1 Transaction 2 Lock IX(TABLE) Lock IX(TABLE) Lock ID_report(Next-Key) Lock ID_settle(Next-Key) Lock primary key(Record) Lock ID_settle(Gap) Waiting Lock PK(Record) Waiting Lock convert impli to expli ID_report(Record) DEADLOCK DEADLOCK 在分析個過程中，我們可以看到當優先執行 Transaction 2時，我們可以看到最後一個 wating Lock ID_report (no gap) 是不存在的，直到我們執行 Transaction 1時，這一個 LOCK才會出現，這就是 隱式鎖(implicit lock) 。\n什麼是隱式鎖? 在 MySQL官方文檔 中關於隱式鎖就只有這麼一條說明－\nWhen UPDATE modifies a clustered index record, implicit locks are taken on affected secondary index records.\n資訊量實在不是很足夠，再加上討論到的文章其實不是很多，因此只好搭配少量的文章搭配源碼來了解，下方出現的源碼取自 8.0 版本，並加上一些個人加上的註解方便理解。\n延遲加鎖機制 讓我們試想一下，如果一張表上面有多個索引，這樣在異動其中一筆資料的時候，豈不是要在好幾個 B+Tree 上同時加鎖嗎 ?\n加鎖也是一筆開銷，如果衝突的可能性很小的時候，多數的鎖應該都是不必要的。\nInnodb 實現了一個延遲加鎖機制，以此來減少加鎖的數量，減少效能損耗的同時也提升併發性能。\n隱式鎖的簡介 Innodb 實現的延遲加鎖的機制，在源碼中被稱為**隱式鎖(implicit lock)**\n隱式鎖沒有實際加鎖，而是一種 logical entity，transaction 是否持有是透過一些過程來計算的。\n隱式鎖中有一個重要的元素： db_trx_id！用來儲存產生該筆紀錄的 transaction ID，這是在 MVCC 中實現 快照讀 也有使用到的元素。\n隱式鎖的特點 只有在很可能發生衝突時才加鎖，減少鎖的數量 隱式鎖式針對 B+Tree 上被修改的紀錄，因此都是 record lock，不可能是 gap lock 或 next-key lock 和顯式鎖的區別： 顯式鎖 (explicit lock) 隱式鎖 (implicit lock) 實際加鎖 邏輯加鎖 佔用內存 不佔用內存 隱式鎖的使用 INSERT 操作一般只會加隱式鎖，不加顯示鎖。除了以下情況：\n若 INSERT 的位置有 gap lock 時，則會加上 insert intention lock。 若 INSERT 的位置發生唯一鍵衝突時，則會將對方的隱式鎖升級為顯示鎖，自己則加上 shared lock 等待。 UPDATE 和 DELETE 操作在查詢時，會直接對查詢走的 index 和 primary key 使用顯示鎖，其他的 index 使用隱式鎖。\n隱式鎖的具體過程 如果 transaction 要獲取行鎖 (不論是顯式或隱式)，則需要先判斷是否存在活躍的隱式鎖 cluster index：首先取得在該紀錄上持有隱式鎖的 transaction id，隨後透過 cluster index 中的隱藏欄位 db_trx_id 判斷前者是否為活躍事務。\nsecondary index： 從 secondary index page 中取得 PAGE_MAX_TRX_ID (T1)\nPAGE_MAX_TRX_ID：該字段存在於 secondary index page 中，用於保存修改該 page 的最大 Transaction ID，當該 page 的任何紀錄被更新後，都會更新此值。\n取得 InnoDB 活躍中事務中 最小的 Transaction ID (T2)\n假如 T1 \u0026lt; T2 則說明修改這個 page 的 T1 已經 commit ，因此不存在隱式鎖。\n反之，則必須再透過 cluster index 搭配 undo log 回溯舊版本數據進行判斷，此步驟較為複雜暫不詳解 (可透過 storage\\innobase\\row\\row0vers.cc 中 row_vers_impl_x_locked 和 row_vers_impl_x_locked_low 了解詳細過程)\n若為活躍事務，則為該活躍事務將 implicit lock 轉換為 explicit lock\n另外可已注意到 implicit lock 轉換後的 explicit lock 不會有 gap lock\n等待加鎖成功後修改數據，並且將自己的 Transaction id 寫入 db_trx_id；或者是 timeout。\n參考 Introduction to Transaction Locks in InnoDB Storage Engine (from oracle blog) - plant MySQL 備份\nIntroduction to Transaction Locks in InnoDB Storage Engine (from oracle blog) - CSDN 備份\npercona live - mysql conference 2015 - Understanding InnoDB locks and deadlocks (page 44)\nUnderstanding-InnoDB-locks-and-deadlocks.pdf\nM18 Deep Dive InnoDB Transactions and Write Paths\nDeep-Dive_-InnoDB-Transactions-and-Write-Paths.pdf\nMySQL数据库InnoDB存储引擎中的锁机制\nMySQL加锁分析\nInnoDB Transaction Lock and MVCC - 何登成 (page 31)\nInnoDB Transaction Lock and MVCC.pdf\nMySQL · 引擎特性 · InnoDB 事务子系统介绍 (數據庫內核月報 - 2015/12)\nMySQL · 引擎特性 · InnoDB 事务锁系统简介 (數據庫內核月報 - 2016/01)\nMySQL · 引擎特性 · InnoDB隐式锁功能解析 (數據庫內核月報 - 2020/09)\nMySQL锁系列（一）之锁的种类和\ninnodB的隐式锁\n","date":"2025-04-01T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-implicit-lock/","title":"隱式鎖"},{"content":"在研究 MySQL MTS 時了解到 MySQL 有 Group Commit 機制，因此進行深入了解。\n本文以下內容都基於 sync_binlog = 1 \u0026amp; innodb_flush_log_at_trx_commit = 1 的情境。\n前置知識 InnoDB Group Commit InnoDB 出於性能考量使用了 WAL (write-ahead logging) 技術：將更新操作修改內存中的數據修改後，先寫 log (InnoDB redo log) 就可以返回告訴 client 端 transaction 已經完成 commit， 後續再慢慢將 dirty page 寫入 Disk 持久化數據修改後的結果。\n這樣除了可以透過 redo log 達到原子性 (atomicity) 和持久性 (durability) 的同時也能增加效率，因為寫 Log 是順序寫入相較於修改數據的隨機寫入快上許多。\n雖然 WAL 技術下順序寫入的 redo log 比隨機寫入快，但是每次 Transaction commit 之前我們還是必須調用 fsync() 將 redo log 持久化到 Disk，然而 fsync() 是昂貴的操作 (消耗較多 IO 資源，並且響應較慢)，因此早在 MySQL 5.0 之前，就在 InnoDB redo log 上實現了 Group Commit 優化：將多個 Transaction 放入對列後一起 commit，減少 fsync() 的次數。\nBinlog/Engine 2PC 在大部分的情境下，為了實現 replication 和基於時間點的恢復，一般 MySQL 實例都會開啟 binlog 來達成相應的目的，這個時候為了保證 Transaction 在 server 層 Log (Binlog) 和 engine 層 Log (例如：InnoDB 的 Redolog) 之間的原子性 (Atomicity)，因此需要透過兩階段提交 (Two-Phase-Commit, 2PC) 來確保，MySQL 透過內部 XA Transaction 來實現 2PC：\n在上述過程下 MySQL 確保了 transaction 在 redo log 和 binlog 之間的原子性 (Atomicity)。\n為什麼這樣能確保 redo log 和 binlog 之間的原子性 (Atomicity) 呢？\nMySQL crash recovery 的流程：\n掃描最後一個 binlog 文件，提取其中的 XID\n備註：只需要掃描最後一個 binlog 是因為 MySQL 在 rotate 到新的 binlog 文件時，總是保證沒有正在 commit 的 Transaction 之後，會調用 fsync() 持久化 redo log，來保證舊的 binlog 裡的所有 Transaction 都在 redo log 中 commit。\n將 redo log 中還在 prepare 的 Transaction 的 XID 和 binlog 比對：\n如果已經在 binlog，則 commit trnsaction。 如果不在 binlog，則 rollback transaction。 由上述步驟我們可以知道當 MySQL Crash 後，透過 Crash Recovery 可以保證 Transaction 在 redo log 和 binlog 的 commit 狀態是一致的，也就達到 redo log 和 binlog 之間的原子性 (Atomicity)。\nMySQL 5.5(含)之前 InnoDB Group Commit Bug 在 MySQL 5.5 (含)之前的版本，當 Binlog 開啟時會導致 InnoDB Group Commit 失效，這導致了效能的急遽下降，尤其是當 sync_binlog = 1 \u0026amp; innodb_flush_log_at_trx_commit = 1 的時候簡直是災難。\n在 MySQL 5.5 的時候 2PC 的具體過程如下：\n在上述過程中 InnoDB Prepare 階段的最後會上一個 prepare_commit_mutex 的鎖，並在 InnoDB Commit 階段釋放，用來確保同一個時刻只有一個線程在處理 Binlog 寫入和 InnoDB Commit，保證 Transaction 在 Binlog 和 Redo Log 中 Commit 順序是一致的。\n可以發現有以下問題：\n因為一次只能有一個 Transaction 取得 prepare_commit_mutex 這個鎖，導致無法應用 InnoDB Group Commit，每一個 Transaction 都必須單獨 fsync()。 一個 Transaction 就調用了 3次 fsync()： InnoDB Prepare (寫 redolog) Binlog Commit (寫 binlog) InnoDB Commit (寫 commit) 也就是說在開啟雙 1 時，每個 Transaction 都必須單獨 fsync() 3 次導致了性能的急遽下降，這就是很知名的 **MySQL Bugs: #13669: Group commit is broken in 5.0** 同時也有人提議讓 Binlog 也支援 Group Commit： MySQL Bugs: #49326: Support group commit for the binlog。\nMySQL 5.6 BinLog Group Commit 在 MySQL 5.6 時 binlog 實現了 Group Commit 減少了 binlog 的 fsync() 次數，同時透過將 commit 操作拆分成 3 個階段 (同時 prepare_commit_mutex 大鎖也被拆分為 3 個小鎖) 以此來並行執行增加效率。\nMySQL 5.6 的時候 2PC 的具體過程如下：\n和 MySQL 5.5 相比，可以看到 prepare 階段保持不變，但移除了 prepare_commit_mutex 這把大鎖，並將 commit 階段拆分為以下三個過程：\nflush 階段：寫入 binlog 文件，也就是寫入 OS Page Cache 不強制執行 fsync() 寫入 Disk。 sync 階段：對 binlog 文件做 fsync() 操作 (也就是 binlog group commit)。 commit 階段：執行 InnoDB commit 操作。 在每個階段都有一個對列，同一個對列中第一個進入的 Transaction (稱為 Leader) 會帶領後續進入的 Transaction (稱為 Follower) 執行該階段的任務。\n在執行該階段的任務時會持有該階段的鎖，保證一個階段只有一個對列在工作，同時每個對列中的 Transaction 依次執行，這確保了 Transaction 寫入的順序。\nMySQL 5.7 RedoLog Group Commit 在 5.6 的時候雖然實現了 binlog group commit 的優化，但是 InnoDB redo log 仍沒有。\n在 MySQL 5.7 的時候 2PC 的具體過程如下：\n和 MySQL 5.6 相比，在 InnoDB Prepare 的時候不進行 redolog 的 fsync()，而是在 flush 階段寫 binlog 文件前進行 redolog 的 write/fsync，在 flush 階段已經有對列了等於實現了 InnoDB Group Commit 的動作，大幅減少了 redolog 執行的 fsync() 操作。\n具體可以這樣優化的原因需要從 Crash Recovery 的邏輯來看－\n從上述 crash recovery 的恢復邏輯中我們可以知道，只要保證 InnoDB Prepare 的 RedoLog 只要在寫入 binlog 之前完成 write/fsync 即可，因此 RedoLog 的 write/fsync 可以移到 flush 階段內 binlog 寫入之前。\n💡 這是由阿里巴巴貢獻的優化：[MySQL Bugs: #73202: write/sync redo log before flush thread cache to binlog](https://bugs.mysql.com/bug.php?id=73202) 圖解 Group Commit 參數調優 此外還新增了以下 2 個參數用來控制 sync 階段等待的時間點：\nbinlog_group_commit_sync_delay = N：對列等待 N 微秒後，開始 sync binlog。 binlog_group_commit_sync_no_delay_count = N：當對列中的 Transaction 達到 N 個後就忽略 binlog_group_commit_sync_delay 的設定開始 sync binlog。 當以上設定越大時，就能一次 commit 更多的 transaction 也就是調用更少的 fsync()，但同時 client 端也需先等待才能收到 commit 的回覆，因此需要謹慎評估適合的值。\n5.7 基於 Group Commit 的 MTS 優化 5.7 這個版本也優化了 MTS 的回放效率，在 5.6 時只有不同 Database 的 Transaction 才能在 Replica 並行回放，在 5.7 時只要在 Source 是同一個 Group 一起 Commit 的 Transaction 就能在 Replica 並行回放，實現方式是在 Binlog 中添加以下 2 個值：\nsequence_number：每個 Transaction 的序列號，在同一個 Binlog 文件中不會重複。 last_commited：紀錄 binlog group commit 時 leader 的 sequence_number 透過 mysqlbinlog 可以看到 binlog 中每個 Transaction 都有這 2 個變量\n也就是只要 Transaction 在 Binlog 中的 last_committed 相同，那麼就可以在 Replica 並行回放。\n參考 MySQL · 源码分析 · 内部 XA 和组提交 (taobao.org)\nMySQL · 性能优化· Group Commit优化 (taobao.org)\nMySQL · 特性分析 · 8.0 WriteSet 并行复制 (taobao.org)\nMySQL · 引擎特性 · 主库 binlog 概览 (taobao.org)\nMySQL · 引擎特性 · InnoDB 事务子系统介绍 (taobao.org)\nMySQL · 引擎特性· InnoDB undo log 漫游\nMySQL · 引擎特性 · InnoDB redo log漫游 (taobao.org)\nMySQL · 引擎特性 · InnoDB 崩溃恢复过程 (taobao.org)\n金融级角度专业理解MySQL两阶段提交\nMySQL/InnoDB和Group Commit(1) - Life, Database and Cloud Computing (orczhou.com)\nMySQL5.7 核心技术揭秘：MySQL Group commit | Focus on MySQL,Focus on Life (keithlan.github.io)\n图解MySQL | MySQL组提交(group commit) (actionsky.com)\nMySQL Musings: Binary Log Group Commit in MySQL 5.6\nMySQL 的 crash-safe 原理解析 - 知乎 (zhihu.com)\nMysql+Innodb源代码调试跟踪分析+何登成_IT168文库 - 百度文库 (baidu.com)\nmysql 事务提交过程 - yuyue2014 - 博客园 (cnblogs.com)\nMySQL 5.7版本XA事务若干bug分析 - 知乎 (zhihu.com)\n深入剖析MySQL group commit实现 （上）-社区博客-网易数帆 (163.com)\n深入剖析MySQL group commit实现（下）-社区博客-网易数帆 (163.com)\n","date":"2025-03-27T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-group-commit/","title":"Group Commit"},{"content":"GTID 的全名是 Global Transaction identifier, MySQL 會為每一個 DML/DDL 操作都分配一個在整個 replicaion topology 都唯一的 GTID。\n在 replication 環境中，master 可以直接透過 GTID 定位發送 binlog 給 slave 不再需要指定 binlog 名稱和 postition 在同步上更為方便。此外 Slave 還會保留從 Master 同步過來的 Transaction 相同的 GTID，並持久化到 mysql.gtid_executed，搭配上 GTID 的自動跳過功能，保證了相同 GTID 的 Transaction 在同一個 instance 中只會執行一次，更加有助於 Replication 的一致性。\nGTID 組成 GTID 的組成為 source_id:transaction_id，範例 3E11FA47-71CA-11E1-9E33-C80AA9429562:23\nsource_id：該 DML/DDL 最原始執行的 server 其 UUID。\n在源碼中稱為 sid，會在 MySQL 啟動時從 auto.cnf 取得，如果沒有則根據啟動時間、線程的 LWP ID 及隨機內存地址生成後並記錄在 auto.cnf 中。\n注意：也就是說如果刪除現有的 auto.cnf 會在下次啟動時產生一個不同的 server uuid。\ntransaction_id：原始 server 為該 DML/DDL 操作分配的唯一序列號，該序列號是順序遞增的。\n在源碼中稱為 gno 會在 Transaction 進入 Flush 階段中生成，MySQL 內部維護了一個全局變量 next_free_gno 的計數來生成 gno。\nGTID Life cycle 以下以 MySQL 8.0.17 以上來說明\n當 Transaction 在 Master 上執行時，會在 commit 過程中的 Flush 階段生成 GTID 。\n當分配 GTID 之後會將 Transaction 和其對應的 GTID 一起寫入 binlog (尚未進入 sync 階段進行 fsync 因此只是寫入 OS cache) 同時更新 mysql.gtid_executed 表及 @@GLOBAL.gtid_executed 變量。\n當 sync_binlog ≠ 1 時，就在 Flush 階段將 binlog 寫入 OS cache 後發送 binlog event 給 slave。\n當 sync_binlog = 1 時，在 sync 階段 fsycn 到 disk 後才發送 binlog event 給 slave。\n因此當 sync_binlog ≠ 1 時，當 Master crash 時可能導致 Slave 進度大於 Master。\nMaster 的 dump 線程將 binlog event 傳送給 Slave 保存至 relay log。\n詳細過程 在 Slave 的 IO_Thread 建立連線時，會將 Retrieved_Gtid_Set 和 Executed_Gtid_Set的並集 (UNION) 及自己的 server_id 發送給 Master。 Master 確認自己的 gtid_purged 是否為 Slave 發送的子集，以此來檢查 master 的 binlog 尚未 purge。 Master 判斷 Slave 有哪些 GTID 還沒執行，並發送對應的 binlog 給 Slave。 Slave 從 relay log 讀取 GTID，並將 gtid_next 設為該 GTID，並判斷以下：\n從 @@GLOBAL.gtid_owned 中確認沒有其他線程正在使用該 GTID，保證一次只有一個線程在處理該 GTID。 從 @@GLOBAL.gtid_executed 中確認該 GTID 是否已經應用過。 如果該 GTID 尚未被被應用，則在 Slave 應用該 Event 並維持該 Event 在 Master 上的 GTID，同時更新 mysql.gtid_executed 表及 @@GLOBAL.gtid_executed 變量。若有開啟 log_slave_update 則也寫入 binlog。\n在 8.0.17 (含 5.7 所有版本) 之前 mysql.gtid_executed 並不總是及時更新：\n當 log_bin = OFF 或者 log_slave_update = OFF 時，則 transaction 和 mysql.gtid_executed 會一起 commit 或 rollback。\n當 slave log_bin = ON 且 log_slave_update = ON 時 (注意：如果是 master log_bin = ON 也適用)， 每當 binlog rotate 或者 server 關閉時，才會將先前 binlog 的所有 transaction gtid 寫入 mysql.gtid_executed 表。\n當 server crash 時，會在 crash recovery 時將 binlog 中的 GTID 添加到 mysql.gtid_executed 表。\n注意：當開啟時 log_bin = OFF 時，會無法恢復 GTID 導致無法啟動 replication。\n會使用每次 Transaction commit 時更新的 @@GLOBAL.gtid_executed 來表示 server 的 GTID 狀態，而不是使用 mysql.gtid_executed 表(因為不會即時更新)。\n因為以上行為當開啟 gtid 模式且 log_slave_update = ON 時，必須要同時設置 sync_binlog = 1 \u0026amp; innodb_flush_log_at_trx_commit = 1，否則會導致 relication 在 OS crash 時發生問題。\n從 8.0.17 開始為了實現 clone 功能 (WL#9211) 更改了此行為，不論如何設置 mysql.gtid_executed 表總是和對應的 Event 一起 commit (rollback) 。\nmysql.gtid_execute 表 設計的初衷是用於當 slave 未開啟 binlog 或者是 log_slave_update = OFF 時，或者是當 binlog 丟失時能夠保留 GTID 的狀態，因此會在這張表中持久化已經執行的 GTID SET。\n💡 RESET MASTER 會清空此表 壓縮 隨著時間推移 mysql.gtid_executed 表會有許多筆資料：\n1 2 3 4 5 6 7 8 9 10 11 +--------------------------------------+----------------+--------------+ | source_uuid | interval_start | interval_end | |--------------------------------------+----------------+--------------| | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 37 | 37 | | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 38 | 38 | | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 39 | 39 | | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 40 | 40 | | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 41 | 41 | | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 42 | 42 | | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 43 | 43 | +--------------------------------------+----------------+--------------+ 為了節省空間，MySQL 會定期壓縮 mysql.gtid_executed 表，壓縮的方式如下：\n1 2 3 4 5 +--------------------------------------+----------------+--------------+ | source_uuid | interval_start | interval_end | |--------------------------------------+----------------+--------------| | 3E11FA47-71CA-11E1-9E33-C80AA9429562 | 37 | 43 | +--------------------------------------+----------------+--------------+ 啟用 binlog 時，當發生 binlog rotation 時會壓縮 mysql.gtid_executed 表。\n當禁用 binlog 時會依據 gtid_executed_compression_period 的值決定壓縮的時機點，每當處理 N 個 Transaction 後會喚醒壓縮線程 (thread/sql/compress_gtid_table) 壓縮 mysql.gtid_executed 表。\n在 8.0.17 之前預設值為 1000，表示每 1000 個 Transaction 進行壓縮，在該版本之前不建議在關閉 binlog 時設定為 0，這將會增加所需的 disk 空間。\n從 8.0.17 開始建議設置為 0 (8.0.23 預設值)，這是因為從該版本開始 InnoDB 的 Transaction 寫入會由另一個 innodb/clone_gtid_thread 線程來控制寫入和壓縮， compress_gtid_table 線程會干擾其作業並降低速度。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mysql\u0026gt; SELECT * FROM performance_schema.threads WHERE NAME LIKE \u0026#39;%gtid%\u0026#39;\\G *************************** 1. row *************************** THREAD_ID: 26 NAME: thread/sql/compress_gtid_table TYPE: FOREGROUND PROCESSLIST_ID: 1 PROCESSLIST_USER: NULL PROCESSLIST_HOST: NULL PROCESSLIST_DB: NULL PROCESSLIST_COMMAND: Daemon PROCESSLIST_TIME: 1509 PROCESSLIST_STATE: Suspending PROCESSLIST_INFO: NULL PARENT_THREAD_ID: 1 ROLE: NULL INSTRUMENTED: YES HISTORY: YES CONNECTION_TYPE: NULL THREAD_OS_ID: 18677 系統變量 gtid_executed 和 gtid_purged 的初始化與更新 初始化 每個 binlog 的開頭都有 Previous-GTIDs：這是由上一個 binlog 文件的 Previous-GTIDs 和上一個 binlog 文件所有的 Transaction GTID 組成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ~ -\u0026gt; mysqlbinlog --no-defaults --base64-output=DECODE-ROWS -vvv mysql-bin.000004 ... #230217 8:17:55 server id 1 end_log_pos 125 CRC32 0xa9000aca Start: binlog v 4, server v 8.0.21 created 230217 8:17:55 at startup ROLLBACK/*!*/; # at 125 #230217 8:17:55 server id 1 end_log_pos 196 CRC32 0xf3d86d46 Previous-GTIDs # 6c3c06b0-ae9b-11ed-a26c-0242ac1d0002:1-3 ... SET @@SESSION.GTID_NEXT= \u0026#39;6c3c06b0-ae9b-11ed-a26c-0242ac1d0002:4\u0026#39;/*!*/; ... SET @@SESSION.GTID_NEXT= \u0026#39;6c3c06b0-ae9b-11ed-a26c-0242ac1d0002:5\u0026#39;/*!*/; ... # End of log file ~ -\u0026gt; mysql-docker $ mysqlbinlog --no-defaults --base64-output=DECODE-ROWS -vvv mysql-bin.000005 ... #230217 8:19:12 server id 1 end_log_pos 125 CRC32 0xd5587e96 Start: binlog v 4, server v 8.0.21 created 230217 8:19:12 at startup # Warning: this binlog is either in use or was not closed properly. ROLLBACK/*!*/; # at 125 #230217 8:19:12 server id 1 end_log_pos 196 CRC32 0x2416aa2b Previous-GTIDs # 6c3c06b0-ae9b-11ed-a26c-0242ac1d0002:1-5 ... gtid_executed 和 gtid_purged 這 2 個系統變量在 MySQL 啟動時會透過 binlog 計算進行初始化：\ngtid_executed：由最新的 binlog 文件的 Previous-GTIDs、最新的 binlog 文件所有的 Transaction GTID、mysql.gtid_excuted 並集 (UNION) 計算得出。 gtid_purged： 將最新的 binlog 文件的 Previous-GTIDs、最新的 binlog 文件所有的 Transaction GTID 相加，計算出 gtids_in_binlog (表示曾出現在 binlog 的所有 gtid)。\n將 gtids_in_binlog 減去最舊的 binlog 文件的 Previous-GTIDs，計算出 gtids_in_binlog_not_purged (表示所在的 binlog 尚未被清除的 gtid)。\n將 gtid_executed 減去 gtids_in_binlog_not_purged，得出在 server 上執行過但 binlog 已被清楚的 GTID SET。\n由上計算得知如果 binlog 未開啟時，gtid_purged = gtid_executed 。\n更新 gtid_executed： 會在 Transaction commit 的時候同步更新。 set global gtid_purged，設為原先 gtid_execute 和新設置 gtid_purged 的並集 (UNION)。 gtid_purged： 當 log_slave_updates = OFF 時，會在 Transaction commit 的時候同步更新。 當 Master 開啟 binlog 時，當執行 purge binary logs 或 binlog 超過 expire_logs_days (binlog_expire_logs_seconds) 的設置時，觸發清除 binlog 的動作更新。 當 Slave 開啟 log_slave_updates，當執行 purge binary logs 或 binlog 超過 expire_logs_days (binlog_expire_logs_seconds) 的設置時，觸發清除 binlog 的動作更新。 當 Slave 關閉 log_slave_updates ，會在 Transaction commit 的時候同步更新。 set global gtid_purged，被設定或增加指定 gtid set。 共同： RESET MASTER 時設為空值。 在 MySQL 啟動時初始化。 Master 未開啟 binlog 時，因為不會產生 GTID，因此不會有任何更新。 GTID 相關變量 gtid_mode 控制是否開啟 GTID 功能。\n可以設置為以下值：\nOFF：所有新的或回放的 Transaction 都是 anonymous。 OFF_PERMISSIVE：所有新的 Transaction 都是 anonymous，但回放的 Transaction 可以是 anonymous 也可以包含 GTID。 ON_PERMISSIVE：所有新的 Transaction 都包含 GTID，但回放的 Transaction 可以是 anonymous 也可以包含 GTID。 ON：必須同時設置 enforce_gtid_consistency = ON。 在修改 gtid_mode 時一次只能變更為上一個或下一個值，例如：原先設置為 OFF_PERMISSIVE 則只能設置為 OFF 或 ON_PERMISSIVE。\nenforce_gtid_consistency 控制是否允許違反 GTID 一致性的語句執行，必須設置為 ON 才能設置 gtid_mode = ON。\n可以設置為以下值：\nOFF (0)：允許所有違反 GTID 一致性的語句執行。 ON (1)：不允許任何違反 GTID 一致性的語句執行。 WARN (2)：允許所有違反 GTID 一致性的語句執行，但會產生 warning。 只有在語句寫入 binlog 時才會檢查，也就是未開啟 binlog 或當語句被 filter 過濾時不會檢查。\n違反 GTID 一致性的語句可以參考 GTID 限制 章節。\ngtid_next gtid_next 用於指定如何獲取下一個 GTID。\ngtid_next 可以設為以下值：\nAUTOMATIC：使用下一個自動生成的 GTID。 ANONYMOUS：Transaction 沒有 GTID，只有 gtid_mode = OFF 時才能設置的值。 指定 GTID 將 gtid_next 設置為指定 GTID 後，需要在 Transaction commit 或 rollback 後，必須在執行其他語句之前再次顯式的 SET GTID_NEXT：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 mysql\u0026gt; set gtid_next = \u0026#39;08d3c091-addb-11ed-8959-0242ac1c0002:5\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; insert into test values(2,20); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; rollback; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; insert into test values(2,20); ERROR 1837 (HY000): When @@SESSION.GTID_NEXT is set to a GTID, you must explicitly set it to a different value after a COMMIT or ROLLBACK. Please check GTID_NEXT variable manual page for detailed explanation. Current @@SESSION.GTID_NEXT is \u0026#39;08d3c091-addb-11ed-8959-0242ac1c0002:5\u0026#39;. gtid_owned 此為 read-only 的變量，根據 Scope 的不同有不同意思：\nGlobal：列出 server 正在使用的所有 GTID 以及擁有該 GTID 的線程 ID。\n主要用於開啟 MTS 時，檢查是否有其他 applier 已經在應用該 GTID，避免同一個 GTID 在同時被多個線程同時處理。\nSession：列出該 session 使用中的 GTID。\n當手動設置 gtid_next 為指定 GTID 時，可以在 Transaction 在 commit (rollback) 之前透過 gtid_owned 觀察到此設置。\n當 gtid_next = AUTOMATIC 時，只有在 Trasnsaction commit 時能從 gtid_next 中短暫觀察到，其餘時候會是空值。\ngtid_executed 此為 read-only 的變量，指的是所有該 server 已經執行的 GTID，也會等同於 SHOW MASTER ( | SLAVE ) STATUS 中的 Executed_Gtid_Set 值。\n當執行 RESET MASTER 時會將 gtid_executed 設置為空值。\ngtid_executed 的 Gtid_Set 會包含 gtid_purged 的 Gtid_Set ，因此在任何時候執行 GTID_SUBTRACT(@@GLOBAL.gtid_executed, @@GLOBAL.gtid_purged) 可以得到未清除的 binlog 中所有的 GTID。\ngtid_purged 此變量表示在 server 上已經執行，但是對應的 binlog 已經被清除的 GTID SET，因此 gtid_purged 為 gtid_executed 的子集。\n以下情況的 GTID 會包含在 gtid_purged：\n當 slave 未開啟 log_slave_updates 時，已經回放的 Transaction 的 GTID。 包含該 GTID 的 binlog 已經被清除。 透過 SET @@GLOBAL.gtid_purged 來顯示設置。 當執行 RESET MASTER 時會將 gtid_purged 設置為空值。\n可以透過 SET @@GLOBAL.gtid_purged 來顯示設定，有以下兩種方式：\n將 gtid_purged 變更為指定的 GTID SET：\n1 SET @@GLOBAL.gtid_purged = \u0026#39;gtid_set\u0026#39; 經過此設置後 gtid_purged 等於 gtid_set，且 gtid_executed 值 (mysql.gtid_executed) 等於 gtid_executed 原本的值和 gtid_set 的並集 (UNION)。\ngtid_set 限制：\n指定的 gtid_set 必須是 gtid_purged 當前值的超集 (superset)，也就是新設置的 GTID SET 必須包含原本的 gtid_purged。 指定的 gtid_set不得和 gtid_subtract(gtid_executed,gtid_purged) 相交，也就是新設置的 GTID SET 不能包含在 gtid_executed 中尚未被清除的值。 指定的 gtid_set 不能包含 @@global.gtid_owned 中的任何 GTID，也就是不能包含當前 server 正在執行的 gtid。 用途範例：使用 mysqldump 還原 slave 上損壞的表，因為備份檔和原先 slave 的 gtid 有重疊，因此可以使用使方式進行 gtid_purged 的設置。\n為 gtid_purged append (新增) 指定的 GTID SET\n1 SET @@GLOBAL.gtid_purged = \u0026#39;+gtid_set\u0026#39; 經過此設置後 gtid_executed (包含 mysql.gtid_executed)、gtid_purged 會新增 gtid_set。\ngtid_set 限制：\ngtid_set 不得與 gtid_executed 的當前值相交，也就是新附加上去的 GTID SET 不能包含在 gtid_executed 和 gtid_purged 中的 GTID。 指定的 gtid_set 不能包含 @@global.gtid_owned 中的任何 GTID，也就是不能包含當前 server 正在執行的 gtid。 用途範例：為了配置多個 channel 的 salve，將來自不同 master 的備份還原到同一個 server，因為兩者的 Transaction 不相交，因此使用 append 的方式更新 gtid_purged。\n注意：在 MySQL 5.7 中只能直接變更成指定的 GTID SET，無法使用 append 的方式，且只有當 gtid_executed 為空 (也就是 gtid_purged 值也為空) 時才可以更新 gtid_purged 的值\ngtid_executed_compression_period 此設置只有禁用 binlog 才有效，每當處理 N 個 Transaction 後會喚醒線程壓縮 mysql.gtid_executed 表，當設置為 0 時表示壓縮不固定執行，而是根據需要進行壓縮。\n當啟用 binlog 時，不會使用此設置，而是當 binlog rotation 時才會壓縮 mysql.gtid_executed 表。\nbinlog_gtid_simple_recovery 控制 MySQL 啟動時從 binlog 尋找 GTID 的行為。\nGTID 限制 不能在一個 Transaction 中同時涉及 nontransactional 儲存引擎 (例如：MyISAM) 和 transactional儲存引擎 (例如：InnoDB) 的表進行更新。\n不支持 sql_slave_skip_counter，除非 slave 在 CHANGE MASTER 時包含了 ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS 才能使用 sql_slave_skip_counter。\n備註：ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS 該功能用來在未開啟 GTID 的 Master 和開啟 GTID 的 Slave 進行 Replication，且會為 Slave 執行的 Transaction 生成 GTID。\n不支持 CHANGE MASTER 時使用 IGNORE_SERVER_IDS 選項。\n在 MySQL 8.0.21 之前，不支援 CREATE TABLE \u0026hellip; SELECT 語句，因為該語句基於 STATEMENT 會產生一個 GTID，但ROW 格式紀錄會產生 2 個 GTID，這會導致無法正確處理 Transaction。\n在 MySQL 8.0.21 之後，因為支持 atomic (原子) DDL 操作，因此不再有該限制。\n在 MySQL 8.0.13 之前不能在 Transaction、Procedures、Functions 和 Triggers 內都不能使用 CREATE/DROP TEMPORARY TABLE，只能在非 Transaction 內且 autocommit = 1 時才能使用。\n從 MySQL 8.0.13 開始，當 binlog_format 設置為 ROW 或 MIXED 時，在使用 GTID 時允許使用 CREATE/DROP TEMPORARY TABLE，因為這些語句將不會寫入 binlog。\n在 MySQL 8.0.16 之前，不能在 mysql_upgrade 中加上 --write-binlog 選項。\n從 MySQL 8.0.16 開始，執行 mysql_upgrade 期間總是會自動禁用 binlog，因此沒有問題。\n在線開啟 GTID 在所有的 MySQL server 設置：\n1 SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY = WARN; 設置後讓 MySQL 接受正常的操作，並在期間從 Error Log 確認是否有出現 GTID 不支持的 Query，並對其進行修正。\n在所有的 MySQL server 設置：\n1 SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY = ON; 設置後所有 GTID 不支持的操作都將被拒絕。\n在所有的 MySQL server 設置：\n1 SET @@GLOBAL.GTID_MODE = OFF_PERMISSIVE; 表示 Master 生成的是 ANONYMOUS Transaction，Slave 可以應用 ANONYMOUS 、GTID Transaction。\n注意務必在所有 server 都設置此步驟後，才執行下一步驟。\n在所有的 MySQL server 設置：\n1 SET @@GLOBAL.GTID_MODE = ON_PERMISSIVE; 表示 Master 生成的是 GTID Transaction，Slave 可以應用 ANONYMOUS 、GTID Transaction。\n在所有的 MySQL server 中確定以下變量為 0：\n1 SHOW STATUS LIKE \u0026#39;ONGOING_ANONYMOUS_TRANSACTION_COUNT\u0026#39;; 該值就是尚未 commit ANONYMOUS Transaction 數量，因此必須確認該值為 0 表示沒有 ANONYMOUS Transaction 都是 GTID Transaction 。\nONGOING_ANONYMOUS_TRANSACTION_COUNT 增減的時機 在 Master 上 增加：當 FLUSH 階段分配 GTID 時，如果為 ANONYMOUS Transaction 則增加該計數。 減少：在 COMMIT 階段 InnoDB COMMIT 之後會減少該計數。 在 Slave 上 增加：當 SQL Tread 應用到 ANONYMOUS Transaction 則增加該計數。 減少：當 SQL Tread 執行 InnoDB COMMIT 之後會減少該計數。 當 ONGOING_ANONYMOUS_TRANSACTION_COUNT 都為 0 的時候，確認所有 slave 都有執行過對應 master binlog 的 position，並非指不能有延遲只是要確保所有的 ANONYMOUS Transaction 都已經被執行。\n在 Master 以下指令， 獲取 Master binlog、Master position\n1 2 # 獲取 Master binlog、Master position SHOW MASTER STATUS\\G 在 Slave 執行以下指令，確認 slave 是否已執行 master 對應的 binlog 及 position\n1 2 # 確認 slave 是否已執行 master 對應的 binlog 及 position SELECT MASTER_POS_WAIT(file, position); 如果 binlog 有用於 replication 以外的用途 (例如：基於時間點的備份和恢復)，請在此時確保包含 ANONYMOUS Transaction 的 Binlog 已不再需要。\n例如：在第 6 步完成後，在備份機上執行 flush logs 後進行備份。\n在所有的 MySQL server 設置：\n1 SET @@GLOBAL.GTID_MODE = ON; 在所有的 MySQL server 的 my.cnf 中添加\n1 2 gtid_mode=ON enforce_gtid_consistency=ON 在 slave 執行 change master\n1 2 3 STOP SLAVE [FOR CHANNEL \u0026#39;channel\u0026#39;]; CHANGE MASTER TO MASTER_AUTO_POSITION = 1 [FOR CHANNEL \u0026#39;channel\u0026#39;]; START SLAVE [FOR CHANNEL \u0026#39;channel\u0026#39;]; GTID 中的維運 SHOW SLAVE STATUS 在開啟 GTID 後，透過 SHOW SLAVE STATUS 會增加以下資訊：\nRetrieved_Gtid_Set：Slave 從 Master 收到的 GTID SET，也就是 IO_Thread 已經接收到的 GTID。\n當 relay-log-recovery = 1 或 RESET SLAVE 或 CHANGE MASTER 時會被清空。\n當 relay-log-recovery = 0 時，在 MySQL 重啟時會從 relay log 中掃描確認。\nExecuted_Gtid_Set：Slave 已經執行的 GTID SET (包含直接在 slave 上執行的語句)，等同於 gtid_executed。\n清除 GTID 歷史紀錄 如果要完全清楚 GTID 歷史紀錄可以使用 RESET MASTER 指令。\n執行前務必備份 binlog、binlog index 文件，獲取並且保存 gtid_executed 變量。\nRESET MASTER 執行以下操作：\ngtid_purged 被設為空字串。 gtid_executed 被設為空字串。 mysql.gtid_executed 表被清空。 刪除現有 binlog，並清除 binlog index 文件。 注意只有 RESET MSTER 會重置 GTID 的歷史紀錄，RESET SLAVE 沒有任何影響。\n跳過一個 Transaction 當有 Transaction 在 SQL_Thread 中發生錯誤時，可以透過 performance_schema 中的replication_applier_status_by_worker 該表中的 APPLYING_TRANSACTION 欄位獲取該 Transaction 的 GTID。\n當確認要跳過該失敗的 Transaction 時，在 GTID 模式下傳統的 sql_slave_skip_counter 不能使用，而是要使用以下方式：\n1 2 3 4 5 6 7 8 STOP SLAVE; # 將 GTID_NEXT 設為要跳過的 Transaction GTID SET GTID_NEXT=\u0026#39;aaa-bbb-ccc-ddd:N\u0026#39;; # 將該 Transaction GTID 設為一個空 Transaction BEGIN; COMMIT; SET GTID_NEXT=\u0026#39;AUTOMATIC\u0026#39;; START SLAVE; 在上述步驟後會將要跳過的 GTID 設為一個空的 Transaction 並將其應用，此時 slave 會認為自己已執行完畢該 GTID，因此可以將 GTID_NEXT 設回 AUTOMATIC 讓 slave 自行找到下一個要執行的 GTID。\n如果是有多個 channel 的 slave，commit 一個空的 Transaction 時不需要指定 channel，只有在 START SLAVE 才需要指定 channel 名稱。\n注意：此方法不適用 ASSIGN_GTIDS_TO_ANONYMOUS_TRANSACTIONS\n參考\nMySQL :: MySQL 8.0 Reference Manual :: 17.1.7.3 Skipping Transactions\nmysqldump 行為的變化 mysqldump 在開啟 gtid 後預設的 dump 行為會有所改變，這是因為 --set-gtid-purged 該選項預設值的影響：\nAUTO (預設值)：在開啟 GTID (gtid_mode = ON) 時自動設為 ON，在未開啟 GTID (gtid_mode = OFF) 時自動設為 OFF。\nON：備份檔中會包含 gtid_purgrd 且會添加 sql_log_bin = 0：\n1 2 3 4 5 6 7 8 SET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION.SQL_LOG_BIN; SET @@SESSION.SQL_LOG_BIN= 0; -- -- GTID state at the beginning of the backup -- SET @@GLOBAL.GTID_PURGED=\u0026#39;42fe5059-32a7-11e6-9d29-000c29fcecda:1\u0026#39;; 這樣的設置下會有以下結果：\n設置 sql_log_bin = 0：關閉了 binlog 紀錄，因此還原的機器不會生成新的 GTID。 設置 gtid_purgrd ：同時也會同時修改 gtid_executed 值及 mysql.gtid_executed 表。 此設置適合用於還原一個 slave 接上備份檔來源的 replication topology。\nOFF：備份檔中不會包含 gtid_purgrd 且不會添加 sql_log_bin = 0，此設置用於未開啟 GTID 的 MySQL 或是適合於還原一個和原本 replication topology 無關的新 master。\nCOMMENTED：從 8.0.17 開始可用，備份檔中會添加 sql_log_bin = 0，並在備份中用註解的方式記錄 gtid_purgrd。此方式較為彈性適合，用於不需生成新的 gtid (基本上表示會在同一個 replication topology) 但情境較為複雜的需要自行調整 gtid_purgrd 時，例如：還原後的機器會有多個 channel。\n因此當開啟 gtid 後在使用 mysqldump 時需要注意 --set-gtid-purged 的設置：\n當 gtid_mode = OFF 未開啟 GTID 時，可以不需要調整該參數或顯式指定為 OFF。\n當 gtid_mode = ON 開啟 GTID 時，若用於還原到同一個 replication topology 的機器，例如：新增一個 slave、為 slave 補上在 master binlog 上已經 purge 的資料……等，這時候就可以保留預設值或顯式指定為 ON。\n當 gtid_mode = ON 開啟 GTID 時，但還原到不同 replication topology 的機器或需要生成新的 GTID，例如：還原成一個新的 master……等，這時候就可以設置為 OFF。\n注意：如果在同一個 replication topology 中設置 OFF，除了可能 MS 無法順利建置，也可能導致在 MS 切換時 新 Slave (原本的 Master) 會收到 新 Master (原本的 Slave) 透過備份檔還原的資料導致重複執行的問題。\n當 gtid_mode = ON 開啟 GTID 時，雖然不需要生成新的 GTID 但情況特殊需要手動設置 gtid_purged 時，例如：還原的 Slave 上有多個 channel ……等，這時候就可以設置為 COMMENTED 後，根據實際需要手動調整該機器的 gtid_purgrd。\nReplication filter 曾經線上環境從傳統 Position 點位的 Replication 切換到 GTID 時發生了問題\nReplication 拓樸結構如下：\nA Instance 的 test database 同時同步 B, C Instance B Instance Replication 給 C，同時設置 Replicat_Do_DB 不包含 test database 當切換到 GTID 時，會因為以下情況丟失資料：\nA 執行對 test database 的異動 Query 同步給 B, C\nB 收到並執行 A 對 test database 的異動 Query 給 C\nC 收到 B 同步過來的 Query，但因為 Replicat_Do_DB 的設置，C 並不會執行 B 同步過來 test database 異動語法。\n注意： 儘管沒有真的執行，但此時該 GTID 會被加入到 C 的 gtid_executed 中\nC 隨後收到 A 同步過來的 test database 異動 Query，但因為該 GTID 在步驟 3 已經執行過，所以直接跳過。\n解決方案也很簡單：直接移除 B, C 之間的 replication filter，因為 GTID 不會重複執行不用像傳統 Position 一樣需要 filter 避免重複執行。\n截自官方文檔說明：\nImportant: For a multi-source replica in a diamond topology (where the replica replicates from two or more sources, which in turn replicate from a common source), when GTID-based replication is in use, ensure that any replication filters or other channel configuration are identical on all channels on the multi-source replica. With GTID-based replication, filters are applied only to the transaction data, and GTIDs are not filtered out. This happens so that a replica’s GTID set stays consistent with the source’s, meaning GTID auto-positioning can be used without re-acquiring filtered out transactions each time. In the case where the downstream replica is multi-source and receives the same transaction from multiple sources in a diamond topology, the downstream replica now has multiple versions of the transaction, and the result depends on which channel applies the transaction first. The second channel to attempt it skips the transaction using GTID auto-skip, because the transaction’s GTID was added to the gtid_executed set by the first channel. With identical filtering on the channels, there is no problem because all versions of the transaction contain the same data, so the results are the same. However, with different filtering on the channels, the database can become inconsistent and replication can hang.\nMySQL :: MySQL 8.0 Reference Manual :: 17.2.5.4 Replication Channel Based Filters\n","date":"2025-03-27T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-gtid/","title":"GTID"},{"content":"FullText Index(全文檢索) ngrame 全文解析器\nMySQL 從 5.7.6 開始內建 ngrame 全文解析器，用來支援中文、日文、韓文分詞\nInnoDB Full-Text Index inverted index(倒排索引) inverted index 經常被用於全文檢索，MySQL 的 Full-Text Index 也是基於 inverted index 來實現的。\ninverted index 將文檔中的不重複單詞構成一個列表，每一個單詞都會記錄包含此單詞的文檔列表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE TABLE small_test( `id` int unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;流水號\u0026#39;, `content` varchar(300) NOT NULL COMMENT \u0026#39;內文\u0026#39;, PRIMARY KEY (`id`), FULLTEXT KEY `content_index` (`content`) /*!50100 WITH PARSER `ngram` */ ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; INSERT INTO small_test(content) VALUES (\u0026#39;我是強森\u0026#39;),(\u0026#39;這是測試\u0026#39;),(\u0026#39;強森是我\u0026#39;); SET GLOBAL innodb_ft_aux_table = \u0026#39;johnson/small_test\u0026#39;; SELECT * FROM information_schema.INNODB_FT_INDEX_CACHE; +--------+--------------+-------------+-----------+--------+----------+ | WORD | FIRST_DOC_ID | LAST_DOC_ID | DOC_COUNT | DOC_ID | POSITION | +--------+--------------+-------------+-----------+--------+----------+ | 強森 | 2 | 4 | 2 | 2 | 6 | | 強森 | 2 | 4 | 2 | 4 | 0 | | 我是 | 2 | 2 | 1 | 2 | 0 | | 是強 | 2 | 2 | 1 | 2 | 3 | | 是我 | 4 | 4 | 1 | 4 | 6 | | 是測 | 3 | 3 | 1 | 3 | 3 | | 森是 | 4 | 4 | 1 | 4 | 3 | | 測試 | 3 | 3 | 1 | 3 | 6 | | 這是 | 3 | 3 | 1 | 3 | 0 | +--------+--------------+-------------+-----------+--------+----------+ InnoDB Full-Text Index Tables 在建立 Full-Text Index 之後，還會出現以下 table：\n1 2 3 4 5 6 7 8 9 10 11 -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_0000000000000129_index_1.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_0000000000000129_index_2.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_0000000000000129_index_3.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_0000000000000129_index_4.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_0000000000000129_index_5.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_0000000000000129_index_6.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_being_deleted_cache.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_being_deleted.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_config.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_deleted_cache.ibd -rw-r-----. 1 mysql mysql 114688 Jun 30 09:05 fts_00000000000004a6_deleted.ibd 可以分為 4 類－\nindex_1~6：數量固定會有 6 個文件用於儲存倒排索引，儲存的是 words、position 和 DOC_ID，會根據 word 進行排序並分區映射到不同的文件中。 倒排索引分為 6 個表用來支持 parallel index creation，預設為 2 個線程，當在大表創建 Full-Text Index 時，可以透過 innodb_ft_sort_pll_degree 來調大併行線程數。 deleted：包含資料已經刪除的 DOC_ID，但還沒從 Full-Text index 中刪除。 deleted_cache：為前者的內存緩存。 being_deleted：包含資料已經刪除的 DOC_ID，且當前正在從 Full-Text index 中刪除。 being_deleted_cache：為前者的內存緩存。 config：包含 Full-Text index 的內部狀態資訊，最重要的是其中有儲存 FTS_SYNCED_DOC_ID，該值用來記錄解析被寫到 disk 的 DOC_ID，在崩潰回覆時會根據這個值判斷哪些 DOC 需要重新解析並將其添加到 Full-text index cache，查詢 INFORMATION_SCHEMA.INNODB_FT_CONFIG 可以查看其中的資料。 InnoDB Full-Text Index Cache InnoDB Full-Text Index DOC_ID and FTS_DOC_ID Column InnoDB 需要透過 DOC_ID 來對應 Word 所在的紀錄，因此建立 Full-Text Index 的時候，也會在表上隱式建立一個 FTS_DOC_ID 的欄位，請參考以下事例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 mysql\u0026gt; CREATE TABLE small_test_2( -\u0026gt; `id` int unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;流水號\u0026#39;, -\u0026gt; `content` varchar(300) NOT NULL COMMENT \u0026#39;內文\u0026#39;, -\u0026gt; PRIMARY KEY (`id`) -\u0026gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; Query OK, 0 rows affected (0.03 sec) mysql\u0026gt; ALTER TABLE small_test_2 ADD FULLTEXT KEY `content_index` (`content`) /*!50100 WITH PARSER `ngram` */; Query OK, 0 rows affected, 1 warning (0.11 sec) Records: 0 Duplicates: 0 Warnings: 1 mysql\u0026gt; show warnings\\G *************************** 1. row *************************** Level: Warning Code: 124 Message: InnoDB rebuilding table to add column FTS_DOC_ID mysql\u0026gt; show extended columns from small_test_2; +-------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +-------------+--------------+------+-----+---------+----------------+ | id | int unsigned | NO | PRI | NULL | auto_increment | | content | varchar(300) | NO | MUL | NULL | | | FTS_DOC_ID | | NO | | NULL | | | DB_TRX_ID | | NO | | NULL | | | DB_ROLL_PTR | | NO | | NULL | | +-------------+--------------+------+-----+---------+----------------+ 5 rows in set (0.00 sec) 因此在該表上建立第一個 Full-Text Index 需要重建表，如果想要避免重建表可以在 CREATE TABLE 時預先建立此欄位，如下事例：\n1 2 3 4 5 6 7 8 9 10 mysql\u0026gt; CREATE TABLE small_test_3( -\u0026gt; `FTS_DOC_ID` BIGINT UNSIGNED NOT NULL AUTO_INCREMENT, -\u0026gt; `content` varchar(300) NOT NULL COMMENT \u0026#39;內文\u0026#39;, -\u0026gt; PRIMARY KEY (`FTS_DOC_ID`) -\u0026gt; ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; Query OK, 0 rows affected (0.12 sec) mysql\u0026gt; alter table small_test_3 add FULLTEXT KEY `content_index` (`content`) /*!50100 WITH PARSER `ngram` */; Query OK, 0 rows affected (0.36 sec) Records: 0 Duplicates: 0 Warnings: 0 刪除 Full-Text Index 時，為了避免下次建立時需重建表，因此不會移除 FTS_DOC_ID 欄位。\nInnoDB Full-Text Index delete handling 為了避免 delete 原表資料時，在索引表中出現大量的 delete 引發資源爭用的問題，已刪除的 DOC_ID 會被記錄在 deleted 表中且不會在索引表中移出，而是會在返回查詢結果之前，透過 deleted 表來過濾已刪除的 DOC_ID。可以透過設置 innodb_optimize_fulltext_only = ON 後執行 OPTIMIZE TABLE 來重建 Full-Text Index 來移除已刪除 DOC_ID 的索引，這些會被轉存到 being_deleted 檔案中。\nInnoDB Full-Text Index Transaction Handling InnoDB Full-Text Indexes 相關 TABLE information_schema 下有提供觀察 Full-Text Index 的表，在使用前須要先設定 innodb_ft_aux_table 調整為想要觀察的表，否則除了 INNODB_FT_DEFAULT_STOPWORD 以外都會是 empty。\n1 SET GLOBAL innodb_ft_aux_table = \u0026#39;database_name/table_name\u0026#39;; 共有以下 6 張表－\nINNODB_FT_CONFIG： INNODB_FT_INDEX_TABLE INNODB_FT_INDEX_CACHE INNODB_FT_DEFAULT_STOPWORD INNODB_FT_DELETED INNODB_FT_BEING_DELETED 全文檢索模式 IN NATURAL LANGUAGE MODE (自然語言模式) 此為默認的方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 mysql\u0026gt; select * from small_test; +----+-----------------------------+ | id | content | +----+-----------------------------+ | 1 | MySQL 的全文檢索測試 | | 2 | MySQL vs Solr | | 3 | Solr 的全文檢索 | | 4 | ES 的全文檢索 | +----+-----------------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; SELECT * FROM small_test -\u0026gt; WHERE MATCH(`content`) -\u0026gt; AGAINST (\u0026#39;MySQL\u0026#39;); +----+-----------------------------+ | id | content | +----+-----------------------------+ | 1 | MySQL 的全文檢索測試 | | 2 | MySQL vs Solr | +----+-----------------------------+ 2 rows in set (0.01 sec) IN Boolean 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 mysql\u0026gt; select * from small_test; +----+-----------------------------+ | id | content | +----+-----------------------------+ | 1 | MySQL 的全文檢索測試 | | 2 | MySQL vs Solr | | 3 | Solr 的全文檢索 | | 4 | ES 的全文檢索 | +----+-----------------------------+ 4 rows in set (0.00 sec) mysql\u0026gt; SELECT * FROM small_test -\u0026gt; WHERE MATCH(`content`) -\u0026gt; AGAINST (\u0026#39;+Mysql -Solr\u0026#39; IN BOOLEAN MODE); +----+-----------------------------+ | id | content | +----+-----------------------------+ | 1 | MySQL 的全文檢索測試 | +----+-----------------------------+ 1 row in set (0.00 sec) With Query Expansion (查詢擴展) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 mysql\u0026gt; SELECT * FROM small_test; +----+-----------------------------+ | id | content | +----+-----------------------------+ | 1 | MySQL 的全文檢索測試 | | 2 | MySQL vs Solr | | 3 | Solr 的全文檢索 | | 4 | ES 的全文檢索 | | 5 | 我是無辜的 | +----+-----------------------------+ 5 rows in set (0.00 sec) mysql\u0026gt; SELECT * -\u0026gt; FROM small_test -\u0026gt; WHERE MATCH(`content`) -\u0026gt; AGAINST (\u0026#39;MySQL\u0026#39; WITH QUERY EXPANSION); +----+-----------------------------+ | id | content | +----+-----------------------------+ | 1 | MySQL 的全文檢索測試 | | 2 | MySQL vs Solr | | 3 | Solr 的全文檢索 | | 4 | ES 的全文檢索 | +----+-----------------------------+ 4 rows in set (0.00 sec) 限制 有切 partition 的表不支援 FullText index\n參考 MySQL :: MySQL 8.0 Reference Manual :: 15.6.2.4 InnoDB Full-Text Indexes\nMySQL :: MySQL 8.0 Reference Manual :: 12.10 Full-Text Search Functions\nhttp://mysql.taobao.org/monthly/2015/10/01/\nhttps://iter01.com/523515.html\nhttps://database.51cto.com/art/202010/630055.htm\nmysql中文全文检索从入门到放弃_弹指天下-CSDN博客\n","date":"2024-12-01T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-fulltext-index/","title":"MySQL FullText Index(全文檢索)"},{"content":"analyzer 分詞器 什麼是分詞？為什麼需要分詞器？ 搜尋引擎的目的是用來文本搜尋，為了更高效率的搜尋需要建立倒排索引，而建立倒排索引就需要分詞這個動作，將文本切分成一個一個的單詞並進行一些額外加工來建立高效的索引。\nAnalyzer 分詞器 一個 analyzer 由以下三部分組成：\n0\u0026hellip;N 個 Character Filters：對輸入的 text 進行預處理。 1 個 Tokenizer：進行分詞。 0\u0026hellip;N 個 Token Filters：對分詞後的結果加工。 下圖展示了 analyzer 為一個文本建立索引的過程：\nCharacter Filters 在將 text 傳遞給 Tokenizer 之前，會先交由 Character Filter 進行預處理。例如：去除 HTML 標籤、字串替換\u0026hellip;\u0026hellip;等。\nElasticsearch 提供以下內建的 Character Filter：\nHTML Strip Character Filter：去除 text 中的 HTML 標籤，並使用解碼值取代 HTML 實體。\n1 2 3 4 5 6 7 8 9 10 11 GET /_analyze { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;char_filter\u0026#34;: [ \u0026#34;html_strip\u0026#34; ], \u0026#34;text\u0026#34;: \u0026#34;\u0026lt;p\u0026gt;I\u0026amp;apos;m so \u0026lt;b\u0026gt;happy\u0026lt;/b\u0026gt;!\u0026lt;/p\u0026gt;\u0026#34; } result： [ \\nI\u0026#39;m so happy!\\n ] Mapping Character Filter：將符合設定的字串替換成別的字串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 GET /_analyze { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;char_filter\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;mapping\u0026#34;, \u0026#34;mappings\u0026#34;: [ \u0026#34;:) =\u0026gt; _happy_\u0026#34;, \u0026#34;:( =\u0026gt; _sad_\u0026#34; ] } ], \u0026#34;text\u0026#34;: \u0026#34;I\u0026#39;m delighted about it :(\u0026#34; } result： [ I\u0026#39;m delighted about it _sad_ ] Pattern Replace Character Filter：透過正則表達式進行替換。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 GET /_analyze { \u0026#34;tokenizer\u0026#34;: \u0026#34;keyword\u0026#34;, \u0026#34;char_filter\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;pattern_replace\u0026#34;, \u0026#34;pattern\u0026#34;: \u0026#34;(\\\\d+)-(?=\\\\d)\u0026#34;, \u0026#34;replacement\u0026#34;: \u0026#34;$1_\u0026#34; } , \u0026#34;text\u0026#34;: \u0026#34;My credit card is 123-456-789\u0026#34; } result： [ My credit card is 123_456_789 ] Tokenizer 接收來自 Character Filter 處理後的結果，並將其切分為一個一個 terms/tokens (通常是一個單詞)。例如：Time is money 會被切分為 [ Time, is, money ]。\nTokenizer 除了進行切分，同時還會記錄以下資訊：\nposition：紀錄 terms/tokens 所在的位置順序，用於 phrase 和 word proximity Query。 start_offset、end_offset：紀錄 terms/tokens 的開始和結束位置，用於 highlight 搜尋結果。 type：紀錄 token type 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;金钱只是一堆数字。\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34; } result： { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;金钱\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 2, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;只是\u0026#34;, \u0026#34;start_offset\u0026#34; : 2, \u0026#34;end_offset\u0026#34; : 4, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;一堆\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;数字\u0026#34;, \u0026#34;start_offset\u0026#34; : 6, \u0026#34;end_offset\u0026#34; : 8, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 3 } ] } Token Filters 接收來自 Tokenizer 的產出的 terms/tokens 並進行調整，例如：轉小寫、刪除 stopwords (停用詞)、添加 synonyms (同義詞)。\n以下範例為轉小寫的 Token filter：\n1 2 3 4 5 6 7 8 9 GET _analyze { \u0026#34;tokenizer\u0026#34; : \u0026#34;standard\u0026#34;, \u0026#34;filter\u0026#34; : [\u0026#34;lowercase\u0026#34;], \u0026#34;text\u0026#34; : \u0026#34;THE Quick FoX JUMPs\u0026#34; } result： [ the, quick, fox, jumps ] 中文分詞 難點 英文本身以單詞為單位，單詞與單詞之間通常是空格、逗號和句號分隔，因此對與英文來說可以很簡單的進行分詞，例如以下例子：\n可以看到分出了 time、is、money 這三個分詞來建立實用的索引。\n但不同的是中文是以字為單位，再由多個字組成一個單詞，單詞則會連貫在一起組成句子，因此並不適用於英文的分詞方式，也因為這樣如果不使用為中文設計的分詞器，則會使用 一元切分法 也就是一個字單獨做為一個索引，例如以下例子：\n上述例子中一個字做為一個單獨的索引，但使用者很可能是用 時間 這個單詞去搜尋，因此上述的例子查詢效率並不是很好（但適用於各種語言），因此還有一種是固定將多個字視為一個單詞－\nLucene 提供的 CJKAnalyzer：這是一個 二元切分法 的分詞器，例如：時間就是金錢，這個例子會被切分為 時間、間就、就是、是金、金錢。\nMySQL 全文檢索中的 N-gram：透過 ngram_token_size 參數來決定將幾個字視為一個單詞，因此預設值 2 就等同於上方介紹的 二元切分法，假設將其設為 3 則時間就是金錢，這個例子會被切分為 時間就、間就是、就是金、是金錢。\n雖然相較於 一元切分法 好了點，但還是會有許多不適用的索引，因此就有了其他專門針對中文處理的分詞器被設計出來，而我們使用搜尋引擎的時候就會需要這些中文分詞器的幫助。\nLucene 核心 analyzer 插件 SmartCN 中英混合的分詞器，該分詞器針對簡體中文有較好的分詞結果，對繁體中文支援不好。\n1 2 ➜ ~ bin/elasticsearch-plugin install analysis-smartcn ➜ ~ systemctl restart elasticsearch 測試(展開查看)\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;smartcn_tokenizer\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;稟\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 3, \u0026#34;end_offset\u0026#34; : 4, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;小人\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;本\u0026#34;, \u0026#34;start_offset\u0026#34; : 6, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;住\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 8, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;在\u0026#34;, \u0026#34;start_offset\u0026#34; : 8, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;蘇\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 10, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;州\u0026#34;, \u0026#34;start_offset\u0026#34; : 10, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;城\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 13, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 13, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 14, \u0026#34;end_offset\u0026#34; : 15, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 17, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;又\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 20, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 20, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 22, \u0026#34;end_offset\u0026#34; : 23, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;樂\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 26, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;無\u0026#34;, \u0026#34;start_offset\u0026#34; : 26, \u0026#34;end_offset\u0026#34; : 27, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 27, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 28, \u0026#34;end_offset\u0026#34; : 29, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;誰\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 30, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;知\u0026#34;, \u0026#34;start_offset\u0026#34; : 30, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;唐\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 33, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;伯\u0026#34;, \u0026#34;start_offset\u0026#34; : 33, \u0026#34;end_offset\u0026#34; : 34, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 34, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 35, \u0026#34;end_offset\u0026#34; : 36, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;蠻\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 38, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;橫\u0026#34;, \u0026#34;start_offset\u0026#34; : 38, \u0026#34;end_offset\u0026#34; : 39, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 34 }, { \u0026#34;token\u0026#34; : \u0026#34;不\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 40, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 35 }, { \u0026#34;token\u0026#34; : \u0026#34;留\u0026#34;, \u0026#34;start_offset\u0026#34; : 40, \u0026#34;end_offset\u0026#34; : 41, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 36 }, { \u0026#34;token\u0026#34; : \u0026#34;情\u0026#34;, \u0026#34;start_offset\u0026#34; : 41, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 37 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 42, \u0026#34;end_offset\u0026#34; : 43, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 38 }, { \u0026#34;token\u0026#34; : \u0026#34;勾\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 44, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 39 }, { \u0026#34;token\u0026#34; : \u0026#34;結\u0026#34;, \u0026#34;start_offset\u0026#34; : 44, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 40 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 41 }, { \u0026#34;token\u0026#34; : \u0026#34;目\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 48, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 42 }, { \u0026#34;token\u0026#34; : \u0026#34;無\u0026#34;, \u0026#34;start_offset\u0026#34; : 48, \u0026#34;end_offset\u0026#34; : 49, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 43 }, { \u0026#34;token\u0026#34; : \u0026#34;天\u0026#34;, \u0026#34;start_offset\u0026#34; : 49, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 44 }, { \u0026#34;token\u0026#34; : \u0026#34;,\u0026#34;, \u0026#34;start_offset\u0026#34; : 50, \u0026#34;end_offset\u0026#34; : 51, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 45 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 46 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 47 }, { \u0026#34;token\u0026#34; : \u0026#34;大\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 54, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 48 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 54, \u0026#34;end_offset\u0026#34; : 55, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 49 }, { \u0026#34;token\u0026#34; : \u0026#34;奪\u0026#34;, \u0026#34;start_offset\u0026#34; : 55, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 50 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 51 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 52 } ] } ICU 添加 ICU libraries 擴展對 unicode 支持，並能更好的分析亞洲語言，對於繁體中文分詞來說效果比 SmartCN 好很多。\n1 2 ➜ ~ bin/elasticsearch-plugin install analysis-icu ➜ ~ systemctl restart elasticsearch 測試\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;icu_tokenizer\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;稟\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;小人\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;本\u0026#34;, \u0026#34;start_offset\u0026#34; : 6, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;住在\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;蘇州\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;城\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 13, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 13, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 17, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;又有\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;樂\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 26, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;無邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 26, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;誰\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 30, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;知\u0026#34;, \u0026#34;start_offset\u0026#34; : 30, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;蠻橫\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 39, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;不留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;勾結\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;目\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 48, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;無\u0026#34;, \u0026#34;start_offset\u0026#34; : 48, \u0026#34;end_offset\u0026#34; : 49, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;天\u0026#34;, \u0026#34;start_offset\u0026#34; : 49, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;大屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 55, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;奪\u0026#34;, \u0026#34;start_offset\u0026#34; : 55, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 34 } ] } 社群貢獻 analyzer 插件 ik https://github.com/medcl/elasticsearch-analysis-ik\nIK 是社群非常活躍的中文分詞，基本上搜尋中文分詞大部分都會推薦 IK。\n不過測試發現 ik 主要也是針對簡體中文的，例如：繁體 金錢 使用 IK 會被拆分為 金、錢，只有簡體的 金钱 會被視為一個 token。\n不過這方面 ik-analyzer-solr 因為還擴充了其他詞庫，所以效果是優於 elasticsearch-analysis-ik。\n1 2 3 4 5 6 7 8 9 10 11 ➜ ~ cd /usr/share/elasticsearch/plugins ➜ ~ mkdir analysis-ik ➜ ~ cd analysis-ik # 安裝 unzip 用來解壓縮 zip ➜ ~ yum install -y unzip # 下載並解壓縮 ➜ ~ wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.15.2/elasticsearch-analysis-ik-7.15.2.zip ➜ ~ unzip elasticsearch-analysis-ik-7.15.2.zip ➜ ~ rm elasticsearch-analysis-ik-7.15.2.zip # 重啟 elastic ➜ ~ systemctl restart elasticsearch 測試\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_max_word\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;稟\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;小人\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;人本\u0026#34;, \u0026#34;start_offset\u0026#34; : 5, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;住在\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;蘇\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 10, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;州\u0026#34;, \u0026#34;start_offset\u0026#34; : 10, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;城\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 13, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 13, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;中有\u0026#34;, \u0026#34;start_offset\u0026#34; : 16, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;又有\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;樂\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 26, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;無\u0026#34;, \u0026#34;start_offset\u0026#34; : 26, \u0026#34;end_offset\u0026#34; : 27, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 27, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;誰\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 30, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;知\u0026#34;, \u0026#34;start_offset\u0026#34; : 30, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;蠻\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 38, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;橫\u0026#34;, \u0026#34;start_offset\u0026#34; : 38, \u0026#34;end_offset\u0026#34; : 39, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;不留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;不留\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 41, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 40, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;勾\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 44, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;結\u0026#34;, \u0026#34;start_offset\u0026#34; : 44, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;目\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 48, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;無\u0026#34;, \u0026#34;start_offset\u0026#34; : 48, \u0026#34;end_offset\u0026#34; : 49, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;天\u0026#34;, \u0026#34;start_offset\u0026#34; : 49, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 34 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 35 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 36 }, { \u0026#34;token\u0026#34; : \u0026#34;大屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 55, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 37 }, { \u0026#34;token\u0026#34; : \u0026#34;奪\u0026#34;, \u0026#34;start_offset\u0026#34; : 55, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 38 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 39 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 40 } ] } stconvert https://github.com/medcl/elasticsearch-analysis-stconvert\n嚴格來說這只是一個 filter，因為 stconvert 不會進行分詞的動作，他只會將字進行繁簡轉換。\n1 2 3 4 5 6 ➜ ~ cd /usr/share/elasticsearch/plugins ➜ ~ mkdir analysis-stconvert ➜ ~ cd analysis-stconvert ➜ ~ wget https://github.com/medcl/elasticsearch-analysis-stconvert/releases/download/v7.15.2/elasticsearch-analysis-stconvert-7.15.2.zip ➜ ~ unzip elasticsearch-analysis-stconvert-7.15.2.zip ➜ ~ systemctl restart elasticsearch 測試\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 PUT /stconvert/ { \u0026#34;settings\u0026#34; : { \u0026#34;analysis\u0026#34; : { \u0026#34;analyzer\u0026#34; : { \u0026#34;tsconvert\u0026#34; : { \u0026#34;tokenizer\u0026#34; : \u0026#34;tsconvert\u0026#34; } }, \u0026#34;tokenizer\u0026#34; : { \u0026#34;tsconvert\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;stconvert\u0026#34;, \u0026#34;delimiter\u0026#34; : \u0026#34;#\u0026#34;, \u0026#34;keep_both\u0026#34; : false, \u0026#34;convert_type\u0026#34; : \u0026#34;t2s\u0026#34; } }, \u0026#34;filter\u0026#34;: { \u0026#34;tsconvert\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;stconvert\u0026#34;, \u0026#34;delimiter\u0026#34; : \u0026#34;#\u0026#34;, \u0026#34;keep_both\u0026#34; : false, \u0026#34;convert_type\u0026#34; : \u0026#34;t2s\u0026#34; } }, \u0026#34;char_filter\u0026#34; : { \u0026#34;tsconvert\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;stconvert\u0026#34;, \u0026#34;convert_type\u0026#34; : \u0026#34;t2s\u0026#34; } } } } } GET /stconvert/_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊， 家中有屋又有田，生活樂無邊。\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;tsconvert\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;禀夫人，小人本住在苏州的城边， 家中有屋又有田，生活乐无边。\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 30, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 0 } ] } jieba https://github.com/sing1ee/elasticsearch-jieba-plugin\n支援繁體中文，但文檔不友善。\n在 github https://github.com/fxsjy/jieba 上也有提供對繁體分詞更好的字典。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # 安裝 gradle wget https://services.gradle.org/distributions/gradle-7.3.1-bin.zip mkdir /opt/gradle unzip ./gradle-7.3.1-bin.zip -d /opt/gradle export PATH=$PATH:/opt/gradle/gradle-7.3.1/bin # clone 此步驟需要配置 github sshkey ➜ ~ git clone https://github.com/sing1ee/elasticsearch-jieba-plugin.git --recursive ➜ ~ cd elasticsearch-jieba-plugin ➜ ~ git submodule foreach --recursive git checkout master # 根據 elasticsearch 版本調整設定檔內的版本號 ➜ ~ vim build.gradle version = \u0026#39;7.15.2\u0026#39; // 适配不通版本的ES，可以修改这里。 implementation \u0026#39;org.elasticsearch:elasticsearch:7.15.2\u0026#39; // 适配不通版本的ES，可以修改这里。 ➜ ~ vim ./src/main/resources/plugin-descriptor.properties # \u0026#39;version\u0026#39;: plugin\u0026#39;s version version=7.15.2 # \u0026#39;elasticsearch.version\u0026#39; version of elasticsearch compiled against elasticsearch.version=7.15.2 # 使用 gradle 打包 ➜ ~ gradle wrapper BUILD SUCCESSFUL in 1s 1 actionable task: 1 executed ➜ ~ ./gradlew pz BUILD SUCCESSFUL in 32s 7 actionable tasks: 7 executed # 解壓縮打包檔 ➜ ~ ls ./build/distributions/ elasticsearch-jieba-plugin-7.15.2.zip ➜ ~ unzip ./build/distributions/elasticsearch-jieba-plugin-7.15.2.zip -d /usr/share/elasticsearch/plugins/ # 重啟 elasticserach ➜ ~ systemctl restart elasticsearch 測試\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;時間就是金錢，金錢只是一堆數字\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;jieba_index\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;時間\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 2, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;就是\u0026#34;, \u0026#34;start_offset\u0026#34; : 2, \u0026#34;end_offset\u0026#34; : 4, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;金錢\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 6, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;金錢\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;只是\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;一堆\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 13, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;數字\u0026#34;, \u0026#34;start_offset\u0026#34; : 13, \u0026#34;end_offset\u0026#34; : 15, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 7 } ] } THULAC https://github.com/microbun/elasticsearch-thulac-plugin\n由清華大學自然語言處理與社會人文計算實驗室研製的一套中文詞法分析工具包。\n到官方 demo 試用了一下，可以發現就算是繁體中文效果也非常好：\n不過看了一下 PRO 版本是需要提交申請書的，所以只能用 Lite 版本將就一下了\nElasticsearch Lite 版本測試結果，雖然沒有 PRO 那麼厲害，但是效果還可以。(展開查看)\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊， 家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田。我爺爺跟他來翻臉，慘被他一棍來打扁， 我奶奶罵他欺騙善民，反被他捉進了唐府， 強姦了一百遍，一百遍，最後她懸樑自盡遺恨人間。 他還將我父子，逐出了家園，流落到江邊。我為求養老爹，只有獨自行乞在廟前。誰知那唐伯虎，他實在太陰險 知道此情形，竟派人來暗算，把我父子狂毆在市前，小人身壯健，殘命得留存，可憐老父他魂歸天!此恨更難填。為求葬老爹，唯有賣身為奴自作賤， 一面勤賺錢，一面讀書篇， 發誓把功名顯，手刃仇人意志堅! 從此唐寅詩集伴身邊，我銘記此仇不共戴天!!!\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;thulac\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;稟\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 3, \u0026#34;end_offset\u0026#34; : 4, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;小人本\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;住\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 8, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;在\u0026#34;, \u0026#34;start_offset\u0026#34; : 8, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;蘇州\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;城邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 14, \u0026#34;end_offset\u0026#34; : 15, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 17, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;又\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 20, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 20, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 22, \u0026#34;end_offset\u0026#34; : 23, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;樂無邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 28, \u0026#34;end_offset\u0026#34; : 29, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;誰知\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 35, \u0026#34;end_offset\u0026#34; : 36, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;蠻橫不留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 42, \u0026#34;end_offset\u0026#34; : 43, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;勾結\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;目無天\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 50, \u0026#34;end_offset\u0026#34; : 51, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;大\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 54, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;屋奪\u0026#34;, \u0026#34;start_offset\u0026#34; : 54, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 34 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 35 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 36 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 58, \u0026#34;end_offset\u0026#34; : 59, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 37 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 59, \u0026#34;end_offset\u0026#34; : 60, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 38 }, { \u0026#34;token\u0026#34; : \u0026#34;爺爺\u0026#34;, \u0026#34;start_offset\u0026#34; : 60, \u0026#34;end_offset\u0026#34; : 62, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 39 }, { \u0026#34;token\u0026#34; : \u0026#34;跟\u0026#34;, \u0026#34;start_offset\u0026#34; : 62, \u0026#34;end_offset\u0026#34; : 63, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 40 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 63, \u0026#34;end_offset\u0026#34; : 64, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 41 }, { \u0026#34;token\u0026#34; : \u0026#34;來\u0026#34;, \u0026#34;start_offset\u0026#34; : 64, \u0026#34;end_offset\u0026#34; : 65, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 42 }, { \u0026#34;token\u0026#34; : \u0026#34;翻臉\u0026#34;, \u0026#34;start_offset\u0026#34; : 65, \u0026#34;end_offset\u0026#34; : 67, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 43 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 67, \u0026#34;end_offset\u0026#34; : 68, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 44 }, { \u0026#34;token\u0026#34; : \u0026#34;慘\u0026#34;, \u0026#34;start_offset\u0026#34; : 68, \u0026#34;end_offset\u0026#34; : 69, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 45 }, { \u0026#34;token\u0026#34; : \u0026#34;被\u0026#34;, \u0026#34;start_offset\u0026#34; : 69, \u0026#34;end_offset\u0026#34; : 70, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 46 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 70, \u0026#34;end_offset\u0026#34; : 71, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 47 }, { \u0026#34;token\u0026#34; : \u0026#34;一棍來\u0026#34;, \u0026#34;start_offset\u0026#34; : 71, \u0026#34;end_offset\u0026#34; : 74, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 48 }, { \u0026#34;token\u0026#34; : \u0026#34;打扁\u0026#34;, \u0026#34;start_offset\u0026#34; : 74, \u0026#34;end_offset\u0026#34; : 76, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 49 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 76, \u0026#34;end_offset\u0026#34; : 77, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 50 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 77, \u0026#34;end_offset\u0026#34; : 78, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 51 }, { \u0026#34;token\u0026#34; : \u0026#34;奶奶\u0026#34;, \u0026#34;start_offset\u0026#34; : 78, \u0026#34;end_offset\u0026#34; : 80, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 52 }, { \u0026#34;token\u0026#34; : \u0026#34;罵\u0026#34;, \u0026#34;start_offset\u0026#34; : 80, \u0026#34;end_offset\u0026#34; : 81, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 53 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 81, \u0026#34;end_offset\u0026#34; : 82, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 54 }, { \u0026#34;token\u0026#34; : \u0026#34;欺騙善民\u0026#34;, \u0026#34;start_offset\u0026#34; : 82, \u0026#34;end_offset\u0026#34; : 86, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 55 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 86, \u0026#34;end_offset\u0026#34; : 87, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 56 }, { \u0026#34;token\u0026#34; : \u0026#34;反\u0026#34;, \u0026#34;start_offset\u0026#34; : 87, \u0026#34;end_offset\u0026#34; : 88, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 57 }, { \u0026#34;token\u0026#34; : \u0026#34;被\u0026#34;, \u0026#34;start_offset\u0026#34; : 88, \u0026#34;end_offset\u0026#34; : 89, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 58 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 89, \u0026#34;end_offset\u0026#34; : 90, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 59 }, { \u0026#34;token\u0026#34; : \u0026#34;捉進\u0026#34;, \u0026#34;start_offset\u0026#34; : 90, \u0026#34;end_offset\u0026#34; : 92, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 60 }, { \u0026#34;token\u0026#34; : \u0026#34;了\u0026#34;, \u0026#34;start_offset\u0026#34; : 92, \u0026#34;end_offset\u0026#34; : 93, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 61 }, { \u0026#34;token\u0026#34; : \u0026#34;唐府\u0026#34;, \u0026#34;start_offset\u0026#34; : 93, \u0026#34;end_offset\u0026#34; : 95, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 62 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 95, \u0026#34;end_offset\u0026#34; : 96, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 63 }, { \u0026#34;token\u0026#34; : \u0026#34;強姦\u0026#34;, \u0026#34;start_offset\u0026#34; : 96, \u0026#34;end_offset\u0026#34; : 98, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 64 }, { \u0026#34;token\u0026#34; : \u0026#34;了\u0026#34;, \u0026#34;start_offset\u0026#34; : 98, \u0026#34;end_offset\u0026#34; : 99, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 65 }, { \u0026#34;token\u0026#34; : \u0026#34;一百\u0026#34;, \u0026#34;start_offset\u0026#34; : 99, \u0026#34;end_offset\u0026#34; : 101, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 66 }, { \u0026#34;token\u0026#34; : \u0026#34;遍\u0026#34;, \u0026#34;start_offset\u0026#34; : 101, \u0026#34;end_offset\u0026#34; : 102, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 67 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 102, \u0026#34;end_offset\u0026#34; : 103, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 68 }, { \u0026#34;token\u0026#34; : \u0026#34;一百\u0026#34;, \u0026#34;start_offset\u0026#34; : 103, \u0026#34;end_offset\u0026#34; : 105, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 69 }, { \u0026#34;token\u0026#34; : \u0026#34;遍\u0026#34;, \u0026#34;start_offset\u0026#34; : 105, \u0026#34;end_offset\u0026#34; : 106, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 70 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 106, \u0026#34;end_offset\u0026#34; : 107, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 71 }, { \u0026#34;token\u0026#34; : \u0026#34;最\u0026#34;, \u0026#34;start_offset\u0026#34; : 107, \u0026#34;end_offset\u0026#34; : 108, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 72 }, { \u0026#34;token\u0026#34; : \u0026#34;後\u0026#34;, \u0026#34;start_offset\u0026#34; : 108, \u0026#34;end_offset\u0026#34; : 109, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 73 }, { \u0026#34;token\u0026#34; : \u0026#34;她\u0026#34;, \u0026#34;start_offset\u0026#34; : 109, \u0026#34;end_offset\u0026#34; : 110, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 74 }, { \u0026#34;token\u0026#34; : \u0026#34;懸樑\u0026#34;, \u0026#34;start_offset\u0026#34; : 110, \u0026#34;end_offset\u0026#34; : 112, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 75 }, { \u0026#34;token\u0026#34; : \u0026#34;自盡\u0026#34;, \u0026#34;start_offset\u0026#34; : 112, \u0026#34;end_offset\u0026#34; : 114, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 76 }, { \u0026#34;token\u0026#34; : \u0026#34;遺恨\u0026#34;, \u0026#34;start_offset\u0026#34; : 114, \u0026#34;end_offset\u0026#34; : 116, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 77 }, { \u0026#34;token\u0026#34; : \u0026#34;人\u0026#34;, \u0026#34;start_offset\u0026#34; : 116, \u0026#34;end_offset\u0026#34; : 117, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 78 }, { \u0026#34;token\u0026#34; : \u0026#34;間\u0026#34;, \u0026#34;start_offset\u0026#34; : 117, \u0026#34;end_offset\u0026#34; : 118, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 79 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 118, \u0026#34;end_offset\u0026#34; : 119, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 80 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 119, \u0026#34;end_offset\u0026#34; : 120, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 81 }, { \u0026#34;token\u0026#34; : \u0026#34;還將\u0026#34;, \u0026#34;start_offset\u0026#34; : 120, \u0026#34;end_offset\u0026#34; : 122, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 82 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 122, \u0026#34;end_offset\u0026#34; : 123, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 83 }, { \u0026#34;token\u0026#34; : \u0026#34;父子\u0026#34;, \u0026#34;start_offset\u0026#34; : 123, \u0026#34;end_offset\u0026#34; : 125, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 84 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 125, \u0026#34;end_offset\u0026#34; : 126, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 85 }, { \u0026#34;token\u0026#34; : \u0026#34;逐出\u0026#34;, \u0026#34;start_offset\u0026#34; : 126, \u0026#34;end_offset\u0026#34; : 128, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 86 }, { \u0026#34;token\u0026#34; : \u0026#34;了\u0026#34;, \u0026#34;start_offset\u0026#34; : 128, \u0026#34;end_offset\u0026#34; : 129, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 87 }, { \u0026#34;token\u0026#34; : \u0026#34;家園\u0026#34;, \u0026#34;start_offset\u0026#34; : 129, \u0026#34;end_offset\u0026#34; : 131, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 88 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 131, \u0026#34;end_offset\u0026#34; : 132, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 89 }, { \u0026#34;token\u0026#34; : \u0026#34;流落\u0026#34;, \u0026#34;start_offset\u0026#34; : 132, \u0026#34;end_offset\u0026#34; : 134, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 90 }, { \u0026#34;token\u0026#34; : \u0026#34;到\u0026#34;, \u0026#34;start_offset\u0026#34; : 134, \u0026#34;end_offset\u0026#34; : 135, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 91 }, { \u0026#34;token\u0026#34; : \u0026#34;江邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 135, \u0026#34;end_offset\u0026#34; : 137, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 92 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 137, \u0026#34;end_offset\u0026#34; : 138, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 93 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 138, \u0026#34;end_offset\u0026#34; : 139, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 94 }, { \u0026#34;token\u0026#34; : \u0026#34;為求\u0026#34;, \u0026#34;start_offset\u0026#34; : 139, \u0026#34;end_offset\u0026#34; : 141, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 95 }, { \u0026#34;token\u0026#34; : \u0026#34;養\u0026#34;, \u0026#34;start_offset\u0026#34; : 141, \u0026#34;end_offset\u0026#34; : 142, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 96 }, { \u0026#34;token\u0026#34; : \u0026#34;老爹\u0026#34;, \u0026#34;start_offset\u0026#34; : 142, \u0026#34;end_offset\u0026#34; : 144, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 97 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 144, \u0026#34;end_offset\u0026#34; : 145, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 98 }, { \u0026#34;token\u0026#34; : \u0026#34;只有\u0026#34;, \u0026#34;start_offset\u0026#34; : 145, \u0026#34;end_offset\u0026#34; : 147, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 99 }, { \u0026#34;token\u0026#34; : \u0026#34;獨\u0026#34;, \u0026#34;start_offset\u0026#34; : 147, \u0026#34;end_offset\u0026#34; : 148, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 100 }, { \u0026#34;token\u0026#34; : \u0026#34;自行乞\u0026#34;, \u0026#34;start_offset\u0026#34; : 148, \u0026#34;end_offset\u0026#34; : 151, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 101 }, { \u0026#34;token\u0026#34; : \u0026#34;在\u0026#34;, \u0026#34;start_offset\u0026#34; : 151, \u0026#34;end_offset\u0026#34; : 152, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 102 }, { \u0026#34;token\u0026#34; : \u0026#34;廟前\u0026#34;, \u0026#34;start_offset\u0026#34; : 152, \u0026#34;end_offset\u0026#34; : 154, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 103 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 154, \u0026#34;end_offset\u0026#34; : 155, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 104 }, { \u0026#34;token\u0026#34; : \u0026#34;誰知\u0026#34;, \u0026#34;start_offset\u0026#34; : 155, \u0026#34;end_offset\u0026#34; : 157, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 105 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 157, \u0026#34;end_offset\u0026#34; : 158, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 106 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 158, \u0026#34;end_offset\u0026#34; : 161, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 107 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 161, \u0026#34;end_offset\u0026#34; : 162, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 108 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 162, \u0026#34;end_offset\u0026#34; : 163, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 109 }, { \u0026#34;token\u0026#34; : \u0026#34;實\u0026#34;, \u0026#34;start_offset\u0026#34; : 163, \u0026#34;end_offset\u0026#34; : 164, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 110 }, { \u0026#34;token\u0026#34; : \u0026#34;在\u0026#34;, \u0026#34;start_offset\u0026#34; : 164, \u0026#34;end_offset\u0026#34; : 165, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 111 }, { \u0026#34;token\u0026#34; : \u0026#34;太\u0026#34;, \u0026#34;start_offset\u0026#34; : 165, \u0026#34;end_offset\u0026#34; : 166, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 112 }, { \u0026#34;token\u0026#34; : \u0026#34;陰險\u0026#34;, \u0026#34;start_offset\u0026#34; : 166, \u0026#34;end_offset\u0026#34; : 168, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 113 }, { \u0026#34;token\u0026#34; : \u0026#34;知道\u0026#34;, \u0026#34;start_offset\u0026#34; : 168, \u0026#34;end_offset\u0026#34; : 170, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 114 }, { \u0026#34;token\u0026#34; : \u0026#34;此情形\u0026#34;, \u0026#34;start_offset\u0026#34; : 170, \u0026#34;end_offset\u0026#34; : 173, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 115 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 173, \u0026#34;end_offset\u0026#34; : 174, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 116 }, { \u0026#34;token\u0026#34; : \u0026#34;竟\u0026#34;, \u0026#34;start_offset\u0026#34; : 174, \u0026#34;end_offset\u0026#34; : 175, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 117 }, { \u0026#34;token\u0026#34; : \u0026#34;派\u0026#34;, \u0026#34;start_offset\u0026#34; : 175, \u0026#34;end_offset\u0026#34; : 176, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 118 }, { \u0026#34;token\u0026#34; : \u0026#34;人\u0026#34;, \u0026#34;start_offset\u0026#34; : 176, \u0026#34;end_offset\u0026#34; : 177, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 119 }, { \u0026#34;token\u0026#34; : \u0026#34;來\u0026#34;, \u0026#34;start_offset\u0026#34; : 177, \u0026#34;end_offset\u0026#34; : 178, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 120 }, { \u0026#34;token\u0026#34; : \u0026#34;暗算\u0026#34;, \u0026#34;start_offset\u0026#34; : 178, \u0026#34;end_offset\u0026#34; : 180, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 121 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 180, \u0026#34;end_offset\u0026#34; : 181, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 122 }, { \u0026#34;token\u0026#34; : \u0026#34;把\u0026#34;, \u0026#34;start_offset\u0026#34; : 181, \u0026#34;end_offset\u0026#34; : 182, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 123 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 182, \u0026#34;end_offset\u0026#34; : 183, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 124 }, { \u0026#34;token\u0026#34; : \u0026#34;父子\u0026#34;, \u0026#34;start_offset\u0026#34; : 183, \u0026#34;end_offset\u0026#34; : 185, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 125 }, { \u0026#34;token\u0026#34; : \u0026#34;狂毆\u0026#34;, \u0026#34;start_offset\u0026#34; : 185, \u0026#34;end_offset\u0026#34; : 187, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 126 }, { \u0026#34;token\u0026#34; : \u0026#34;在\u0026#34;, \u0026#34;start_offset\u0026#34; : 187, \u0026#34;end_offset\u0026#34; : 188, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 127 }, { \u0026#34;token\u0026#34; : \u0026#34;市前\u0026#34;, \u0026#34;start_offset\u0026#34; : 188, \u0026#34;end_offset\u0026#34; : 190, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 128 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 190, \u0026#34;end_offset\u0026#34; : 191, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 129 }, { \u0026#34;token\u0026#34; : \u0026#34;小人身\u0026#34;, \u0026#34;start_offset\u0026#34; : 191, \u0026#34;end_offset\u0026#34; : 194, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 130 }, { \u0026#34;token\u0026#34; : \u0026#34;壯健\u0026#34;, \u0026#34;start_offset\u0026#34; : 194, \u0026#34;end_offset\u0026#34; : 196, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 131 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 196, \u0026#34;end_offset\u0026#34; : 197, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 132 }, { \u0026#34;token\u0026#34; : \u0026#34;殘命\u0026#34;, \u0026#34;start_offset\u0026#34; : 197, \u0026#34;end_offset\u0026#34; : 199, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 133 }, { \u0026#34;token\u0026#34; : \u0026#34;得\u0026#34;, \u0026#34;start_offset\u0026#34; : 199, \u0026#34;end_offset\u0026#34; : 200, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 134 }, { \u0026#34;token\u0026#34; : \u0026#34;留存\u0026#34;, \u0026#34;start_offset\u0026#34; : 200, \u0026#34;end_offset\u0026#34; : 202, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 135 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 202, \u0026#34;end_offset\u0026#34; : 203, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 136 }, { \u0026#34;token\u0026#34; : \u0026#34;可\u0026#34;, \u0026#34;start_offset\u0026#34; : 203, \u0026#34;end_offset\u0026#34; : 204, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 137 }, { \u0026#34;token\u0026#34; : \u0026#34;憐\u0026#34;, \u0026#34;start_offset\u0026#34; : 204, \u0026#34;end_offset\u0026#34; : 205, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 138 }, { \u0026#34;token\u0026#34; : \u0026#34;老父\u0026#34;, \u0026#34;start_offset\u0026#34; : 205, \u0026#34;end_offset\u0026#34; : 207, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 139 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 207, \u0026#34;end_offset\u0026#34; : 208, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 140 }, { \u0026#34;token\u0026#34; : \u0026#34;魂\u0026#34;, \u0026#34;start_offset\u0026#34; : 208, \u0026#34;end_offset\u0026#34; : 209, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 141 }, { \u0026#34;token\u0026#34; : \u0026#34;歸天\u0026#34;, \u0026#34;start_offset\u0026#34; : 209, \u0026#34;end_offset\u0026#34; : 211, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 142 }, { \u0026#34;token\u0026#34; : \u0026#34;!\u0026#34;, \u0026#34;start_offset\u0026#34; : 211, \u0026#34;end_offset\u0026#34; : 212, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 143 }, { \u0026#34;token\u0026#34; : \u0026#34;此\u0026#34;, \u0026#34;start_offset\u0026#34; : 212, \u0026#34;end_offset\u0026#34; : 213, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 144 }, { \u0026#34;token\u0026#34; : \u0026#34;恨\u0026#34;, \u0026#34;start_offset\u0026#34; : 213, \u0026#34;end_offset\u0026#34; : 214, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 145 }, { \u0026#34;token\u0026#34; : \u0026#34;更\u0026#34;, \u0026#34;start_offset\u0026#34; : 214, \u0026#34;end_offset\u0026#34; : 215, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 146 }, { \u0026#34;token\u0026#34; : \u0026#34;難\u0026#34;, \u0026#34;start_offset\u0026#34; : 215, \u0026#34;end_offset\u0026#34; : 216, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 147 }, { \u0026#34;token\u0026#34; : \u0026#34;填\u0026#34;, \u0026#34;start_offset\u0026#34; : 216, \u0026#34;end_offset\u0026#34; : 217, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 148 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 217, \u0026#34;end_offset\u0026#34; : 218, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 149 }, { \u0026#34;token\u0026#34; : \u0026#34;為\u0026#34;, \u0026#34;start_offset\u0026#34; : 218, \u0026#34;end_offset\u0026#34; : 219, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 150 }, { \u0026#34;token\u0026#34; : \u0026#34;求葬\u0026#34;, \u0026#34;start_offset\u0026#34; : 219, \u0026#34;end_offset\u0026#34; : 221, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 151 }, { \u0026#34;token\u0026#34; : \u0026#34;老爹\u0026#34;, \u0026#34;start_offset\u0026#34; : 221, \u0026#34;end_offset\u0026#34; : 223, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 152 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 223, \u0026#34;end_offset\u0026#34; : 224, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 153 }, { \u0026#34;token\u0026#34; : \u0026#34;唯有\u0026#34;, \u0026#34;start_offset\u0026#34; : 224, \u0026#34;end_offset\u0026#34; : 226, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 154 }, { \u0026#34;token\u0026#34; : \u0026#34;賣身\u0026#34;, \u0026#34;start_offset\u0026#34; : 226, \u0026#34;end_offset\u0026#34; : 228, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 155 }, { \u0026#34;token\u0026#34; : \u0026#34;為奴\u0026#34;, \u0026#34;start_offset\u0026#34; : 228, \u0026#34;end_offset\u0026#34; : 230, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 156 }, { \u0026#34;token\u0026#34; : \u0026#34;自作賤\u0026#34;, \u0026#34;start_offset\u0026#34; : 230, \u0026#34;end_offset\u0026#34; : 233, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 157 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 233, \u0026#34;end_offset\u0026#34; : 234, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 158 }, { \u0026#34;token\u0026#34; : \u0026#34;一面勤\u0026#34;, \u0026#34;start_offset\u0026#34; : 234, \u0026#34;end_offset\u0026#34; : 237, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 159 }, { \u0026#34;token\u0026#34; : \u0026#34;賺錢\u0026#34;, \u0026#34;start_offset\u0026#34; : 237, \u0026#34;end_offset\u0026#34; : 239, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 160 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 239, \u0026#34;end_offset\u0026#34; : 240, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 161 }, { \u0026#34;token\u0026#34; : \u0026#34;一面\u0026#34;, \u0026#34;start_offset\u0026#34; : 240, \u0026#34;end_offset\u0026#34; : 242, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 162 }, { \u0026#34;token\u0026#34; : \u0026#34;讀書篇\u0026#34;, \u0026#34;start_offset\u0026#34; : 242, \u0026#34;end_offset\u0026#34; : 245, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 163 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 245, \u0026#34;end_offset\u0026#34; : 246, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 164 }, { \u0026#34;token\u0026#34; : \u0026#34;發誓\u0026#34;, \u0026#34;start_offset\u0026#34; : 246, \u0026#34;end_offset\u0026#34; : 248, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 165 }, { \u0026#34;token\u0026#34; : \u0026#34;把\u0026#34;, \u0026#34;start_offset\u0026#34; : 248, \u0026#34;end_offset\u0026#34; : 249, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 166 }, { \u0026#34;token\u0026#34; : \u0026#34;功名顯\u0026#34;, \u0026#34;start_offset\u0026#34; : 249, \u0026#34;end_offset\u0026#34; : 252, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 167 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 252, \u0026#34;end_offset\u0026#34; : 253, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 168 }, { \u0026#34;token\u0026#34; : \u0026#34;手刃仇人\u0026#34;, \u0026#34;start_offset\u0026#34; : 253, \u0026#34;end_offset\u0026#34; : 257, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 169 }, { \u0026#34;token\u0026#34; : \u0026#34;意志\u0026#34;, \u0026#34;start_offset\u0026#34; : 257, \u0026#34;end_offset\u0026#34; : 259, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 170 }, { \u0026#34;token\u0026#34; : \u0026#34;堅\u0026#34;, \u0026#34;start_offset\u0026#34; : 259, \u0026#34;end_offset\u0026#34; : 260, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 171 }, { \u0026#34;token\u0026#34; : \u0026#34;!\u0026#34;, \u0026#34;start_offset\u0026#34; : 260, \u0026#34;end_offset\u0026#34; : 261, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 172 }, { \u0026#34;token\u0026#34; : \u0026#34;從\u0026#34;, \u0026#34;start_offset\u0026#34; : 261, \u0026#34;end_offset\u0026#34; : 262, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 173 }, { \u0026#34;token\u0026#34; : \u0026#34;此\u0026#34;, \u0026#34;start_offset\u0026#34; : 262, \u0026#34;end_offset\u0026#34; : 263, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 174 }, { \u0026#34;token\u0026#34; : \u0026#34;唐寅詩\u0026#34;, \u0026#34;start_offset\u0026#34; : 263, \u0026#34;end_offset\u0026#34; : 266, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 175 }, { \u0026#34;token\u0026#34; : \u0026#34;集伴\u0026#34;, \u0026#34;start_offset\u0026#34; : 266, \u0026#34;end_offset\u0026#34; : 268, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 176 }, { \u0026#34;token\u0026#34; : \u0026#34;身邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 268, \u0026#34;end_offset\u0026#34; : 270, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 177 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 270, \u0026#34;end_offset\u0026#34; : 271, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 178 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 271, \u0026#34;end_offset\u0026#34; : 272, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 179 }, { \u0026#34;token\u0026#34; : \u0026#34;銘記\u0026#34;, \u0026#34;start_offset\u0026#34; : 272, \u0026#34;end_offset\u0026#34; : 274, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 180 }, { \u0026#34;token\u0026#34; : \u0026#34;此\u0026#34;, \u0026#34;start_offset\u0026#34; : 274, \u0026#34;end_offset\u0026#34; : 275, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 181 }, { \u0026#34;token\u0026#34; : \u0026#34;仇\u0026#34;, \u0026#34;start_offset\u0026#34; : 275, \u0026#34;end_offset\u0026#34; : 276, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 182 }, { \u0026#34;token\u0026#34; : \u0026#34;不共戴天\u0026#34;, \u0026#34;start_offset\u0026#34; : 276, \u0026#34;end_offset\u0026#34; : 280, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 183 }, { \u0026#34;token\u0026#34; : \u0026#34;!\u0026#34;, \u0026#34;start_offset\u0026#34; : 280, \u0026#34;end_offset\u0026#34; : 281, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 184 }, { \u0026#34;token\u0026#34; : \u0026#34;!\u0026#34;, \u0026#34;start_offset\u0026#34; : 281, \u0026#34;end_offset\u0026#34; : 282, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 185 }, { \u0026#34;token\u0026#34; : \u0026#34;!\u0026#34;, \u0026#34;start_offset\u0026#34; : 282, \u0026#34;end_offset\u0026#34; : 283, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 186 } ] } 安裝步驟如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 下載並解壓縮 ➜ ~ cd /usr/share/elasticsearch/plugins ➜ ~ wget https://github.com/microbun/elasticsearch-thulac-plugin/releases/download/7.9.1/elasticsearch-thulac-plugin-7.9.1.zip ➜ ~ unzip elasticsearch-thulac-plugin-7.9.1.zip ➜ ~ rm ./elasticsearch-thulac-plugin-7.9.1.zip # 根據 ES 版本調整設定檔 ➜ ~ cd analysis-thulac ➜ ~ mv elasticsearch-thulac-plugin-7.9.1.jar elasticsearch-thulac-plugin-7.15.2.jar ➜ ~ vim plugin-descriptor.properties version=7.15.2 elasticsearch.version=7.15.2 # 下載模型 ➜ ~ cd /usr/share/elasticsearch/plugins/analysis-thulac/models ➜ ~ wget http://thulac.thunlp.org/source/Models_v1_v2.zip ➜ ~ unzip Models_v1_v2.zip ➜ ~ mv ./models/* ./ ➜ ~ rm -r models __MACOSX Models_v1_v2.zip # 重啟 elastic ➜ ~ systemctl restart elasticsearch 中文方案推薦 簡體中文 基本上推薦直接使用 IK 就可以了，方便使用社群活躍。\n繁體中文 因為 IK 對於繁體中文支持不夠，因此需要另尋方案：\njieba：雖然一樣是中國開發的，但是是有支持繁體分詞的。\nSTConvert + IK：先在 char_filter 透過 STConvert 將繁體轉為簡體，再交給 tokenizer IK 來進行分詞，透過這種方式解決 IK 在繁體分詞的不足。\n範例(展開查看)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 PUT /my-index-000002 { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;analyzer\u0026#34;: { \u0026#34;my_custom_analyzer\u0026#34;: { \u0026#34;char_filter\u0026#34;: [ \u0026#34;tsconvert\u0026#34; ], \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_max_word\u0026#34; } }, \u0026#34;char_filter\u0026#34;: { \u0026#34;tsconvert\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stconvert\u0026#34;, \u0026#34;convert_type\u0026#34; : \u0026#34;t2s\u0026#34; } }, \u0026#34;filter\u0026#34;: { \u0026#34;stconvert\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stconvert\u0026#34;, \u0026#34;convert_type\u0026#34; : \u0026#34;s2t\u0026#34; } } } }, \u0026#34;mappings\u0026#34;:{ \u0026#34;properties\u0026#34;:{ \u0026#34;id\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;integer\u0026#34; }, \u0026#34;content\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_custom_analyzer\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;my_custom_analyzer\u0026#34; }, \u0026#34;create_time\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;date\u0026#34; } } } } PUT /my-index-000002/_doc/1 { \u0026#34;id\u0026#34;:1, \u0026#34;content\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田。\u0026#34;, \u0026#34;create_time\u0026#34;:\u0026#34;2021-12-09\u0026#34; } GET /my-index-000002/_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田。\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_custom_analyzer\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;禀\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;小人\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;人本\u0026#34;, \u0026#34;start_offset\u0026#34; : 5, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;住在\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;苏州\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;城\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 13, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;边\u0026#34;, \u0026#34;start_offset\u0026#34; : 13, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;中有\u0026#34;, \u0026#34;start_offset\u0026#34; : 16, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;又有\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;乐\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 26, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;无边\u0026#34;, \u0026#34;start_offset\u0026#34; : 26, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;谁知\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;蛮横\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 39, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;不留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;不留\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 41, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 40, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;勾结\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;目无\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 49, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;天\u0026#34;, \u0026#34;start_offset\u0026#34; : 49, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;大屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 55, \u0026#34;type\u0026#34; : \u0026#34;CN_WORD\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;夺\u0026#34;, \u0026#34;start_offset\u0026#34; : 55, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;CN_CHAR\u0026#34;, \u0026#34;position\u0026#34; : 34 } ] } THULAC：雖然不能使用 PRO 版本，但 Lite 版本也非常不錯了，而且同樣有自訂辭典的功能。\n範例(展開查看)\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;thulac\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;稟\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 3, \u0026#34;end_offset\u0026#34; : 4, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;小人本\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;住\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 8, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;在\u0026#34;, \u0026#34;start_offset\u0026#34; : 8, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;蘇州\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;城邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 14, \u0026#34;end_offset\u0026#34; : 15, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 17, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;又\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 20, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 20, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 22, \u0026#34;end_offset\u0026#34; : 23, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;樂無邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;。\u0026#34;, \u0026#34;start_offset\u0026#34; : 28, \u0026#34;end_offset\u0026#34; : 29, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;誰知\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 35, \u0026#34;end_offset\u0026#34; : 36, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;蠻橫不留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 42, \u0026#34;end_offset\u0026#34; : 43, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;勾結\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;目無天\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;，\u0026#34;, \u0026#34;start_offset\u0026#34; : 50, \u0026#34;end_offset\u0026#34; : 51, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;大\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 54, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;屋奪\u0026#34;, \u0026#34;start_offset\u0026#34; : 54, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 34 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 35 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;word\u0026#34;, \u0026#34;position\u0026#34; : 36 } ] } IK + 自訂繁體辭典：透過 IK 的自訂辭典導入繁體中文詞庫來改善。\nICU：Lucene 自帶的，對於繁體字來說效果還不錯。\n範例(展開查看)\n1 2 3 4 5 GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田\u0026#34;, \u0026#34;tokenizer\u0026#34;: \u0026#34;icu_tokenizer\u0026#34; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 { \u0026#34;tokens\u0026#34; : [ { \u0026#34;token\u0026#34; : \u0026#34;稟\u0026#34;, \u0026#34;start_offset\u0026#34; : 0, \u0026#34;end_offset\u0026#34; : 1, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 0 }, { \u0026#34;token\u0026#34; : \u0026#34;夫人\u0026#34;, \u0026#34;start_offset\u0026#34; : 1, \u0026#34;end_offset\u0026#34; : 3, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 1 }, { \u0026#34;token\u0026#34; : \u0026#34;小人\u0026#34;, \u0026#34;start_offset\u0026#34; : 4, \u0026#34;end_offset\u0026#34; : 6, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 2 }, { \u0026#34;token\u0026#34; : \u0026#34;本\u0026#34;, \u0026#34;start_offset\u0026#34; : 6, \u0026#34;end_offset\u0026#34; : 7, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 3 }, { \u0026#34;token\u0026#34; : \u0026#34;住在\u0026#34;, \u0026#34;start_offset\u0026#34; : 7, \u0026#34;end_offset\u0026#34; : 9, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 4 }, { \u0026#34;token\u0026#34; : \u0026#34;蘇州\u0026#34;, \u0026#34;start_offset\u0026#34; : 9, \u0026#34;end_offset\u0026#34; : 11, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 5 }, { \u0026#34;token\u0026#34; : \u0026#34;的\u0026#34;, \u0026#34;start_offset\u0026#34; : 11, \u0026#34;end_offset\u0026#34; : 12, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 6 }, { \u0026#34;token\u0026#34; : \u0026#34;城\u0026#34;, \u0026#34;start_offset\u0026#34; : 12, \u0026#34;end_offset\u0026#34; : 13, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 7 }, { \u0026#34;token\u0026#34; : \u0026#34;邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 13, \u0026#34;end_offset\u0026#34; : 14, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 8 }, { \u0026#34;token\u0026#34; : \u0026#34;家中\u0026#34;, \u0026#34;start_offset\u0026#34; : 15, \u0026#34;end_offset\u0026#34; : 17, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 9 }, { \u0026#34;token\u0026#34; : \u0026#34;有\u0026#34;, \u0026#34;start_offset\u0026#34; : 17, \u0026#34;end_offset\u0026#34; : 18, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 10 }, { \u0026#34;token\u0026#34; : \u0026#34;屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 18, \u0026#34;end_offset\u0026#34; : 19, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 11 }, { \u0026#34;token\u0026#34; : \u0026#34;又有\u0026#34;, \u0026#34;start_offset\u0026#34; : 19, \u0026#34;end_offset\u0026#34; : 21, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 12 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 21, \u0026#34;end_offset\u0026#34; : 22, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 13 }, { \u0026#34;token\u0026#34; : \u0026#34;生活\u0026#34;, \u0026#34;start_offset\u0026#34; : 23, \u0026#34;end_offset\u0026#34; : 25, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 14 }, { \u0026#34;token\u0026#34; : \u0026#34;樂\u0026#34;, \u0026#34;start_offset\u0026#34; : 25, \u0026#34;end_offset\u0026#34; : 26, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 15 }, { \u0026#34;token\u0026#34; : \u0026#34;無邊\u0026#34;, \u0026#34;start_offset\u0026#34; : 26, \u0026#34;end_offset\u0026#34; : 28, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 16 }, { \u0026#34;token\u0026#34; : \u0026#34;誰\u0026#34;, \u0026#34;start_offset\u0026#34; : 29, \u0026#34;end_offset\u0026#34; : 30, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 17 }, { \u0026#34;token\u0026#34; : \u0026#34;知\u0026#34;, \u0026#34;start_offset\u0026#34; : 30, \u0026#34;end_offset\u0026#34; : 31, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 18 }, { \u0026#34;token\u0026#34; : \u0026#34;那\u0026#34;, \u0026#34;start_offset\u0026#34; : 31, \u0026#34;end_offset\u0026#34; : 32, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 19 }, { \u0026#34;token\u0026#34; : \u0026#34;唐伯虎\u0026#34;, \u0026#34;start_offset\u0026#34; : 32, \u0026#34;end_offset\u0026#34; : 35, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 20 }, { \u0026#34;token\u0026#34; : \u0026#34;他\u0026#34;, \u0026#34;start_offset\u0026#34; : 36, \u0026#34;end_offset\u0026#34; : 37, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 21 }, { \u0026#34;token\u0026#34; : \u0026#34;蠻橫\u0026#34;, \u0026#34;start_offset\u0026#34; : 37, \u0026#34;end_offset\u0026#34; : 39, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 22 }, { \u0026#34;token\u0026#34; : \u0026#34;不留情\u0026#34;, \u0026#34;start_offset\u0026#34; : 39, \u0026#34;end_offset\u0026#34; : 42, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 23 }, { \u0026#34;token\u0026#34; : \u0026#34;勾結\u0026#34;, \u0026#34;start_offset\u0026#34; : 43, \u0026#34;end_offset\u0026#34; : 45, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 24 }, { \u0026#34;token\u0026#34; : \u0026#34;官府\u0026#34;, \u0026#34;start_offset\u0026#34; : 45, \u0026#34;end_offset\u0026#34; : 47, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 25 }, { \u0026#34;token\u0026#34; : \u0026#34;目\u0026#34;, \u0026#34;start_offset\u0026#34; : 47, \u0026#34;end_offset\u0026#34; : 48, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 26 }, { \u0026#34;token\u0026#34; : \u0026#34;無\u0026#34;, \u0026#34;start_offset\u0026#34; : 48, \u0026#34;end_offset\u0026#34; : 49, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 27 }, { \u0026#34;token\u0026#34; : \u0026#34;天\u0026#34;, \u0026#34;start_offset\u0026#34; : 49, \u0026#34;end_offset\u0026#34; : 50, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 28 }, { \u0026#34;token\u0026#34; : \u0026#34;占\u0026#34;, \u0026#34;start_offset\u0026#34; : 51, \u0026#34;end_offset\u0026#34; : 52, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 29 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 52, \u0026#34;end_offset\u0026#34; : 53, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 30 }, { \u0026#34;token\u0026#34; : \u0026#34;大屋\u0026#34;, \u0026#34;start_offset\u0026#34; : 53, \u0026#34;end_offset\u0026#34; : 55, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 31 }, { \u0026#34;token\u0026#34; : \u0026#34;奪\u0026#34;, \u0026#34;start_offset\u0026#34; : 55, \u0026#34;end_offset\u0026#34; : 56, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 32 }, { \u0026#34;token\u0026#34; : \u0026#34;我\u0026#34;, \u0026#34;start_offset\u0026#34; : 56, \u0026#34;end_offset\u0026#34; : 57, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 33 }, { \u0026#34;token\u0026#34; : \u0026#34;田\u0026#34;, \u0026#34;start_offset\u0026#34; : 57, \u0026#34;end_offset\u0026#34; : 58, \u0026#34;type\u0026#34; : \u0026#34;\u0026lt;IDEOGRAPHIC\u0026gt;\u0026#34;, \u0026#34;position\u0026#34; : 34 } ] } CJKAnalyzer：直接使用二元切分法，也比使用預設、smartCN 有更好的效果，但會有很多無意義佔用空間的 token。\n課外知識 中研院 CKIP Lab 中文詞知識庫小組在 2019/09 的時候開源了專屬於台灣的繁體中文斷詞 ckiptagger ，對於繁體中文斷詞是我目前看到效果最好的，在官方提供的測試數據中準確率也比 jieba-zh_TW 效果更好，可惜的是目前沒有其他人將其變成搜尋引擎的 plugin。\nhttps://github.com/ckiplab/ckiptagger\nCKIP Lab 中文詞知識庫小組 | 中文斷詞 (sinica.edu.tw)\n參考 ES+Solr 文檔：\nAnalyzers | Apache Solr Reference Guide 6.6\nText analysis overview | Elasticsearch Guide [7.15] | Elastic\nCreate a custom analyzer | Elasticsearch Guide [7.15] | Elastic\nCharacter filters reference | Elasticsearch Guide [7.15] | Elastic\nTokenizer reference | Elasticsearch Guide [7.15] | Elastic\nToken filter reference | Elasticsearch Guide [7.15] | Elastic\nAnalysis Plugins | Elasticsearch Plugins and Integrations [7.15] | Elastic\n分詞器：\nElasticsearch中文分词之Thulac和IK_zDREAM_UTOPIA的专栏-CSDN博客\nElasticsearch (五) - Analyzer 分析器 | Tienyu Note (tienyulin.com)\nElasticSearch 分词器，了解一下 - 知乎 (zhihu.com)\n使用Elasticsearch进行高效的中文搜索_culh2177的博客-CSDN博客\nstconvert 相關：\n简繁处理 :: Elastic 搜索开发实战 (medcl.com)\nTHULAC 相關：\nTHULAC：一个高效的中文词法分析工具包 (thunlp.org)\n測試文本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 # http://10.17.117.203:5601/app/dev_tools#/console GET /_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田。我爺爺跟他來翻臉，慘被他一棍來打扁，我奶奶罵他欺騙善民，反被他捉進了唐府， 強姦了一百遍，一百遍，最後她懸樑自盡遺恨人間。 他還將我父子，逐出了家園，流落到江邊。我為求養老爹，只有獨自行乞在廟前。誰知那唐伯虎，他實在太陰險 知道此情形，竟派人來暗算，把我父子狂毆在市前，小人身壯健，殘命得留存，可憐老父他魂歸天!此恨更難填。為求葬老爹，唯有賣身為奴自作賤， 一面勤賺錢，一面讀書篇， 發誓把功名顯，手刃仇人意志堅! 從此唐寅詩集伴身邊，我銘記此仇不共戴天!!!\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;standard\u0026#34; } #\u0026#34;analyzer\u0026#34;: \u0026#34;cjk\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;thulac\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;smartcn_tokenizer\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;icu_tokenizer\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;ik_smart\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;thulac\u0026#34; #\u0026#34;analyzer\u0026#34;: \u0026#34;jieba_index\u0026#34; # stconvert + ik PUT /stconvert-ik { \u0026#34;settings\u0026#34;: { \u0026#34;analysis\u0026#34;: { \u0026#34;analyzer\u0026#34;: { \u0026#34;my_custom_analyzer\u0026#34;: { \u0026#34;char_filter\u0026#34;: [ \u0026#34;tsconvert\u0026#34; ], \u0026#34;tokenizer\u0026#34;: \u0026#34;ik_max_word\u0026#34; } }, \u0026#34;char_filter\u0026#34;: { \u0026#34;tsconvert\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stconvert\u0026#34;, \u0026#34;convert_type\u0026#34; : \u0026#34;t2s\u0026#34; } }, \u0026#34;filter\u0026#34;: { \u0026#34;stconvert\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stconvert\u0026#34;, \u0026#34;convert_type\u0026#34; : \u0026#34;s2t\u0026#34; } } } }, \u0026#34;mappings\u0026#34;:{ \u0026#34;properties\u0026#34;:{ \u0026#34;id\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;integer\u0026#34; }, \u0026#34;content\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_custom_analyzer\u0026#34;, \u0026#34;search_analyzer\u0026#34;: \u0026#34;my_custom_analyzer\u0026#34; }, \u0026#34;create_time\u0026#34;:{ \u0026#34;type\u0026#34;:\u0026#34;date\u0026#34; } } } } GET /stconvert-ik/_analyze { \u0026#34;text\u0026#34;: \u0026#34;稟夫人，小人本住在蘇州的城邊，家中有屋又有田，生活樂無邊。誰知那唐伯虎，他蠻橫不留情，勾結官府目無天，占我大屋奪我田。我爺爺跟他來翻臉，慘被他一棍來打扁，我奶奶罵他欺騙善民，反被他捉進了唐府， 強姦了一百遍，一百遍，最後她懸樑自盡遺恨人間。 他還將我父子，逐出了家園，流落到江邊。我為求養老爹，只有獨自行乞在廟前。誰知那唐伯虎，他實在太陰險 知道此情形，竟派人來暗算，把我父子狂毆在市前，小人身壯健，殘命得留存，可憐老父他魂歸天!此恨更難填。為求葬老爹，唯有賣身為奴自作賤， 一面勤賺錢，一面讀書篇， 發誓把功名顯，手刃仇人意志堅! 從此唐寅詩集伴身邊，我銘記此仇不共戴天!!!\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;my_custom_analyzer\u0026#34; } # 清除 index DELETE /stconvert-ik ","date":"2024-11-25T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/elasticsearch-analyzer/","title":"analyzer 分詞器"},{"content":"Inverted index 反向索引 前言 索引的目的是為了快速檢索數據。\n每一種 DB 都有其適用的情境，所以會需要不同的數據結構和索引來解決問題。\n對 MySQL 來說是 B+tree 結構的索引，而在 Lucene 來說是 inverted index。\nInverted index 是什麼? 有反向索引(inverted index) 那當然就有正向索引(forward index)。\n正向索引(forward index) 就像一本書開頭的目錄一樣，我們可以依照章節名稱直接找到頁數。\n這個時候如果你想找到包含某個關鍵字的頁數要怎麼辦呢？有些書的後面就會列出某些關鍵字出現的頁數，這就是反向索引(inverted index)的一種。\n讓我們看一下例子，假設在搜尋引擎中存有以下紀錄：\ndoc_id content 1 時間就是金錢 2 金錢只是一堆數字 3 這是數字 以上範例 doc_id 是唯一值，透過唯一值去尋找整個文檔的值就是運用了正向索引(forward index)。\n如果我想找到 content 中包含 金錢 兩個字的文檔時， 就需要一個一個查看文檔的 content。\n這時候我們對 content 做反向索引(inverted index)：\n單詞(Token) doc_id count doc_id + position 時間 [1] 1 [1:0] 金錢 [1,2] 2 [1:3,2:0] 數字 [2,3] 2 [2:3,3:0] 如上表，可以看到這樣就能快速找到我們想要的文檔，這也是搜尋引擎的解決方案。\n參考 搜索引擎之倒排索引浅析【附源码】_武培轩_51CTO博客\n聊聊 Elasticsearch 的倒排索引 - 知乎 (zhihu.com)\nElasticsearch 倒排索引原理 - Silverming (xiaoming.net.cn)\nElasticSearch 索引 VS MySQL 索引 | crossoverJie\u0026rsquo;s Blog\n","date":"2024-11-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/inverted-index/","title":"inverted-index 反向索引"},{"content":"全文檢索 假設今天在 MySQL 下有一張叫 article 的表，我們想要找出 content(內文) 中包含 金錢 兩個字的所有文章，就需要使用以下模糊查詢：\n1 SELECT * FROM article WHERE content LIKE \u0026#39;%莎士比亞%\u0026#39;; 在這種情況下 MySQL 需要全表掃描整張表的 content 才能找出結果，因此搜尋效率非常的不好。\n這個時候我們就去要透過建立 FullText Index 或者是使用搜尋引擎(solr、elasticsearch\u0026hellip;)來優化查詢。\n精確匹配和相關性匹配 還有什麼原因需要搜尋引擎呢？\n假設我們有一下資料：\nid content 1 莎士比亞的故事 2 哈姆雷特作者的故事 3 羅密歐與茱麗葉作者的故事 當使用者輸入 沙士比壓，如果我們使用 MySQL 進行一般的模糊查詢：\n1 SELECT * FROM article WHERE content LIKE \u0026#39;%沙士比壓%\u0026#39;; 很顯然這樣我們不會得到任何結果，因為這是一個要求「精確匹配」的「模糊查詢」。\n1 GET /article/_doc/_search?q=content:沙士比壓 在使用資料庫搜索時，我們更多的是基於「精確匹配」的搜索。\n什麼是「精確匹配」？\n比如搜訂單，根據訂單狀態，準確搜索。 搜「已完成」，就要「精確匹配」「已完成」的訂單，搜「待支付」，就要「精確匹配」「待支付」的訂單。\n這種「精確匹配」的搜索能力，傳統關係型資料庫是非常勝任的。\n和「精確匹配」相比，「相關性匹配」更貼近人的思維方式。\n比如我要搜一門講過「莎士比亞」的課程，我需要在課程的文稿里進行「相關性匹配」，找到對應的文稿，你可能覺得一條 sql 語句就可以解決這個問題：\n1 select * from course where content like \u0026#34;%莎士比亚%\u0026#34; 然而，這隻能算是「模糊查詢」，用你要搜索的字串，去「精確」的「模糊查詢」，其實還是「精確匹配」，機械思維。\n那麼到底什麼是「相關性匹配」，什麼才是「人的思維」呢？\n比如我搜「莎士比亞」，我要的肯定不只是精精確確包含「莎士比亞」的文稿，我可能還要搜「莎翁」、「Shakespeare」、「哈姆雷特」、「羅密歐和朱麗葉」、「威尼斯的商人」\u0026hellip;\n又比如我輸錯了，輸成「莎士筆亞」，「相關性匹配」可以智慧的幫我優化為「莎士比亞」，返回對應的搜尋結果。\n這就是搜尋引擎的強大之處，它似乎可以理解你的真實意圖。\n原理 Inverted index 反向索引\nanalyzer 分詞器\n工具 FullText Index(全文檢索)\nelastic\nSolr\n參考 为什么需要 Elasticsearch - 知乎 (zhihu.com)\n","date":"2024-11-20T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/fulltext-search/","title":"全文檢索"},{"content":"Materialized MySQL (實驗性) ClickHouse 提供了 MaterializedMySQL 的 database engine 允許 ClickHouse 作為 MySQL 的 replica，透過讀取 MySQL 的 binlog 來執行 DDL、DML 到 ClickHouse 上\nMySQL server 在建立 MySQL 和 ClickHouse 的同步之前，在 MySQL Server 這邊需要有以下設定：\nMySQL 需要開啟 gtid 模式：\n1 2 gtid-mode = ON enforce-gtid-consistency = ON 建立 ClickHouse 連線所需的權限，需注意 ClickHouse 只能使用 mysql_native_password 的 plugin 來連線 MySQL 進行驗證：\n1 2 CREATE USER clickhouse@\u0026#39;%\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;ClickHouse\u0026#39;; GRANT RELOAD, REPLICATION SLAVE, REPLICATION CLIENT,SELECT ON *.* TO clickhouse@\u0026#39;%\u0026#39;; ClickHouse 設定 設置以下設定\n1 set allow_experimental_database_materialized_mysql = 1; 1 2 3 CREATE DATABASE [IF NOT EXISTS] db_name [ON CLUSTER cluster] ENGINE = MaterializedMySQL(\u0026#39;host:port\u0026#39;, [\u0026#39;database\u0026#39; | database], \u0026#39;user\u0026#39;, \u0026#39;password\u0026#39;) [SETTINGS ...] [TABLE OVERRIDE table1 (...), TABLE OVERRIDE table2 (...)] SETTINGS 提供的參數 max_rows_in_buffer：允許數據在內存中最大的行數，當超過此設定時數據將被 materialized，預設值為 65505 max_bytes_in_buffer max_flush_data_time max_wait_time_when_mysql_unavailable allows_query_when_mysql_lost materialized_mysql_tables_list 1 2 3 4 5 6 7 8 CREATE DATABASE db1_mysql ENGINE = MaterializedMySQL( \u0026#39;mysql-host.domain.com:3306\u0026#39;, \u0026#39;db1\u0026#39;, \u0026#39;clickhouse_user\u0026#39;, \u0026#39;ClickHouse_123\u0026#39; ); ","date":"2024-10-17T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-materialized-mysql/","title":"ClickHouse Materialized MySQL"},{"content":"TPC-H 測試 安裝 到 TPC 官方下載 TPC-H 工具\n這個步驟需填寫 email，下載連結會寄到 email\n解壓縮檔案，並建立 Makefile 檔案\n1 2 3 4 unzip 025654ff-3a66-4e25-9f7c-ee2f2e6bbf18-tpc-h-tool.zip mv \u0026#39;TPC-H V3.0.1\u0026#39; \u0026#39;TPC-H_Tools_v3.0.1\u0026#39; cd ./TPC-H_Tools_v3.0.1/dbgen cp makefile.suite Makefile MySQL 修改 Makefile 中的 CC、DATABASE、MACHINE、WORKLOAD 等參數設定\n1 2 3 4 5 6 7 8 9 10 -\u0026gt; ~ vim Makefile CC = gcc # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata) # SQLSERVER, SYBASE, ORACLE, VECTORWISE # Current values for MACHINE are: ATT, DOS, HP, IBM, ICL, MVS, # SGI, SUN, U2200, VMS, LINUX, WIN32 # Current values for WORKLOAD are: TPCH DATABASE= MYSQL MACHINE = LINUX WORKLOAD = TPCH 修改 tpcd.h 文件，新增 mysql 相關定義\n1 2 3 4 5 6 7 8 9 -\u0026gt; ~ vim tpcd.h #ifdef MYSQL #define GEN_QUERY_PLAN \u0026#34;\u0026#34; #define START_TRAN \u0026#34;START TRANSACTION\u0026#34; #define END_TRAN \u0026#34;COMMIT\u0026#34; #define SET_OUTPUT \u0026#34;\u0026#34; #define SET_ROWCOUNT \u0026#34;limit %d;\\n\u0026#34; #define SET_DBASE \u0026#34;use %s;\\n\u0026#34; #endif 編譯\n1 make 編譯後該目錄會多出 2 個可執行檔：\ndbgen：產生測試數據的工具 qgen：產生 SQL 語句的工具 透過 dbgen 產生測試數據\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 產生 5G 數據 ./dbgen -s 5 # 將數據文件放到資料夾方便處理 mkdir test mv *.tbl test/ -\u0026gt; ~ ll -h tpch5/ 總計 5.3G -rw-r--r-- 1 root root 117M 12月 23 16:36 customer.tbl -rw-r--r-- 1 root root 3.6G 12月 23 16:36 lineitem.tbl -rw-r--r-- 1 root root 2.2K 12月 23 16:36 nation.tbl -rw-r--r-- 1 root root 830M 12月 23 16:36 orders.tbl -rw-r--r-- 1 root root 573M 12月 23 16:36 partsupp.tbl -rw-r--r-- 1 root root 116M 12月 23 16:36 part.tbl -rw-r--r-- 1 root root 389 12月 23 16:36 region.tbl -rw-r--r-- 1 root root 6.8M 12月 23 16:36 supplier.tbl 說明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 数据量的大小对查询速度有直接的影响，TPC-H中使用SF描述数据量，1SF对应1 GB单位。1000SF，即1 TB。1SF对应的数据量只是8个表的总数据量不包括索引等空间占用，准备数据时需预留更多空间。 -s表示sf值，如-s 1表示生成1G数据： -s 0.16最大表lineitem约96万条数据 -s 1.6最大表lineitem约960万条数据 -s 16最大表lineitem约0.96亿条数据 -s 20最大表lineitem约1.2亿条数据 -S表示当前命令生成第几个 chunk。 -C表示一共分成几个chunk。一条语句只能生成一个 chunk。 -f表示强制生成，会替换之前生成的.tbl文件 更多dbgen命令说明请使用./dbgen --help查看： -C \u0026lt;n\u0026gt; – separate data set into \u0026lt;n\u0026gt; chunks (requires -S, default: 1) -f – force. Overwrite existing files -h – display this message -q – enable QUIET mode -s \u0026lt;n\u0026gt; – set Scale Factor (SF) to \u0026lt;n\u0026gt; (default: 1) -S \u0026lt;n\u0026gt; – build the \u0026lt;n\u0026gt;th step of the data/update set (used with -C or -U) -U \u0026lt;n\u0026gt; – generate \u0026lt;n\u0026gt; update sets -v – enable VERBOSE mode -b \u0026lt;s\u0026gt; – load distributions for \u0026lt;s\u0026gt; (default: dists.dss) -d \u0026lt;n\u0026gt; – split deletes between \u0026lt;n\u0026gt; files (requires -U) -i \u0026lt;n\u0026gt; – split inserts between \u0026lt;n\u0026gt; files (requires -U) -T c – generate cutomers ONLY -T l – generate nation/region ONLY -T L – generate lineitem ONLY -T n – generate nation ONLY -T o – generate orders/lineitem ONLY -T O – generate orders ONLY -T p – generate parts/partsupp ONLY -T P – generate parts ONLY -T r – generate region ONLY -T s – generate suppliers ONLY -T S – generate partsupp ONLY To generate the SF=1 (1GB), validation database population, use: dbgen -vf -s 1 To generate updates for a SF=1 (1GB), use: dbgen -v -U 1 -s 1 建立 schema\nschema\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 create table part ( p_partkey bigint not null, p_name varchar(55) not null, p_mfgr char(25) not null, p_brand char(10) not null, p_type varchar(25) not null, p_size bigint not null, p_container char(10) not null, p_retailprice decimal(15,2) not null, p_comment varchar(23) not null, primary key (p_partkey) ) engine = innodb; create table supplier ( s_suppkey bigint not null, s_name char(25) not null, s_address varchar(40) not null, s_nationkey bigint not null, s_phone char(15) not null, s_acctbal decimal(15,2) not null, s_comment varchar(101) not null, primary key (s_suppkey) ) engine = innodb; create table partsupp ( ps_partkey bigint not null, ps_suppkey bigint not null, ps_availqty bigint not null, ps_supplycost decimal(15,2) not null, ps_comment varchar(199) not null, primary key (ps_partkey, ps_suppkey) ) engine = innodb; create table customer ( c_custkey bigint not null, c_name varchar(25) not null, c_address varchar(40) not null, c_nationkey bigint not null, c_phone char(15) not null, c_acctbal decimal(15,2) not null, c_mktsegment char(10) not null, c_comment varchar(117) not null, primary key (c_custkey) ) engine = innodb; create table orders ( o_orderkey bigint not null, o_custkey bigint not null, o_orderstatus char(1) not null, o_totalprice decimal(15,2) not null, o_orderdate date not null, o_orderpriority char(15) not null, o_clerk char(15) not null, o_shippriority bigint not null, o_comment varchar(79) not null, primary key (o_orderkey) ) engine = innodb; create table lineitem ( l_orderkey bigint not null, l_partkey bigint not null, l_suppkey bigint not null, l_linenumber bigint not null, l_quantity decimal(15,2) not null, l_extendedprice decimal(15,2) not null, l_discount decimal(15,2) not null, l_tax decimal(15,2) not null, l_returnflag char(1) not null, l_linestatus char(1) not null, l_shipdate date not null, l_commitdate date not null, l_receiptdate date not null, l_shipinstruct char(25) not null, l_shipmode char(10) not null, l_comment varchar(44) not null, primary key (l_orderkey, l_linenumber) ) engine = innodb; create table nation ( n_nationkey bigint not null, n_name char(25) not null, n_regionkey bigint not null, n_comment varchar(152), primary key (n_nationkey) ) engine = innodb; create table region ( r_regionkey bigint not null, r_name char(25) not null, r_comment varchar(152), primary key (r_regionkey) ) engine = innodb; 1 2 mysql -uroot -S/var/lib/mysql-replica01/mysql.sock -e\u0026#34;CREATE DATABASE test\u0026#34; mysql -uroot -S/var/lib/mysql-replica01/mysql.sock -Dtest \u0026lt; tpch_mysql_schema.sql 匯數據\n1 2 # client 端需加上 --local-infile=1 才能 LOAD DATA mysql -uroot -S/var/lib/mysql-replica01/mysql.sock --local-infile=1 -Dtest 1 2 3 4 5 6 7 8 9 10 11 # local_infile = ON 才能 LOAD DATA SET GLOBAL local_infile = \u0026#39;ON\u0026#39;; # LOAD DATA LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/customer.tbl\u0026#39; INTO TABLE customer FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/lineitem.tbl\u0026#39; INTO TABLE lineitem FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/nation.tbl\u0026#39; INTO TABLE nation FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/orders.tbl\u0026#39; INTO TABLE orders FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/part.tbl\u0026#39; INTO TABLE part FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/partsupp.tbl\u0026#39; INTO TABLE partsupp FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/region.tbl\u0026#39; INTO TABLE region FIELDS TERMINATED BY \u0026#39;|\u0026#39;; LOAD DATA LOCAL INFILE \u0026#39;/root/TPC-H_Tools_v3.0.1/dbgen-clickhouse/test_data/supplier.tbl\u0026#39; INTO TABLE supplier FIELDS TERMINATED BY \u0026#39;|\u0026#39;; ClickHouse 修改 Makefile 中的 CC、DATABASE、MACHINE、WORKLOAD 等參數設定\n1 2 3 4 5 6 7 8 9 10 -\u0026gt; ~ vim Makefile CC = gcc # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata) # SQLSERVER, SYBASE, ORACLE, VECTORWISE # Current values for MACHINE are: ATT, DOS, HP, IBM, ICL, MVS, # SGI, SUN, U2200, VMS, LINUX, WIN32 # Current values for WORKLOAD are: TPCH DATABASE= CLICKHOUSE MACHINE = LINUX WORKLOAD = TPCH 修改 tpcd.h 文件，新增 mysql 相關定義\n1 2 3 4 5 6 7 8 9 -\u0026gt; ~ vim tpcd.h #ifdef CLICKHOUSE #define GEN_QUERY_PLAN \u0026#34;\u0026#34; #define START_TRAN \u0026#34;\u0026#34; #define END_TRAN \u0026#34;\u0026#34; #define SET_OUTPUT \u0026#34;\u0026#34; #define SET_ROWCOUNT \u0026#34;limit %d;\\n\u0026#34; #define SET_DBASE \u0026#34;use %s;\\n\u0026#34; #endif 編譯\n1 make 編譯後該目錄會多出 2 個可執行檔：\ndbgen：產生測試數據的工具 qgen：產生 SQL 語句的工具 產生測試數據\n1 2 3 ./dbgen -s 5 mkdir test_data mv *.tbl test_data 匯入數據\nCH schema\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 create table part ( p_partkey bigint not null, p_name varchar(55) not null, p_mfgr char(25) not null, p_brand char(10) not null, p_type varchar(25) not null, p_size bigint not null, p_container char(10) not null, p_retailprice decimal(15,2) not null, p_comment varchar(23) not null ) engine = MergeTree order by (p_partkey); create table supplier ( s_suppkey bigint not null, s_name char(25) not null, s_address varchar(40) not null, s_nationkey bigint not null, s_phone char(15) not null, s_acctbal decimal(15,2) not null, s_comment varchar(101) not null ) engine = MergeTree order by (s_suppkey); create table partsupp ( ps_partkey bigint not null, ps_suppkey bigint not null, ps_availqty bigint not null, ps_supplycost decimal(15,2) not null, ps_comment varchar(199) not null ) engine = MergeTree order by (ps_partkey, ps_suppkey); create table customer ( c_custkey bigint not null, c_name varchar(25) not null, c_address varchar(40) not null, c_nationkey bigint not null, c_phone char(15) not null, c_acctbal decimal(15,2) not null, c_mktsegment char(10) not null, c_comment varchar(117) not null ) engine = MergeTree order by (c_custkey); create table orders ( o_orderkey bigint not null, o_custkey bigint not null, o_orderstatus char(1) not null, o_totalprice decimal(15,2) not null, o_orderdate date not null, o_orderpriority char(15) not null, o_clerk char(15) not null, o_shippriority bigint not null, o_comment varchar(79) not null ) engine = MergeTree order by (o_orderkey); create table lineitem ( l_orderkey bigint not null, l_partkey bigint not null, l_suppkey bigint not null, l_linenumber bigint not null, l_quantity decimal(15,2) not null, l_extendedprice decimal(15,2) not null, l_discount decimal(15,2) not null, l_tax decimal(15,2) not null, l_returnflag char(1) not null, l_linestatus char(1) not null, l_shipdate date not null, l_commitdate date not null, l_receiptdate date not null, l_shipinstruct char(25) not null, l_shipmode char(10) not null, l_comment varchar(44) not null ) engine = MergeTree order by (l_orderkey, l_linenumber); create table nation ( n_nationkey bigint not null, n_name char(25) not null, n_regionkey bigint not null, n_comment varchar(152) ) engine = MergeTree order by (n_nationkey); create table region ( r_regionkey bigint not null, r_name char(25) not null, r_comment varchar(152) ) engine = MergeTree order by (r_regionkey); 1 2 3 4 5 6 7 8 9 10 11 clickhouse client -q \u0026#34;CREATE DATABASE IF NOT EXISTS test\u0026#34; clickhouse client -n --queries-file tpch_ch_schema.sql -d test clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.customer format CSV\u0026#34; \u0026lt; customer.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.lineitem format CSV\u0026#34; \u0026lt; lineitem.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.nation format CSV\u0026#34; \u0026lt; nation.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.orders format CSV\u0026#34; \u0026lt; orders.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.partsupp format CSV\u0026#34; \u0026lt; partsupp.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.part format CSV\u0026#34; \u0026lt; part.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.region format CSV\u0026#34; \u0026lt; region.tbl clickhouse client -m --format_csv_delimiter=\u0026#34;|\u0026#34; --query=\u0026#34;insert into test.supplier format CSV\u0026#34; \u0026lt; supplier.tbl MySQL \u0026amp; ClickHouse 測試 規格 機器規格（個人 Citrix Linux 機器）： CPU：2 Core Memory：8 GB DB 皆使用 7GB memory DB 皆為單 node 各個 Table 資料量： lineitem：59,986,052 customer：1,500,000 nation：25 orders：15,000,000 part：2,000,000 partsupp：8,000,000 region：5 supplier：100,000 測試結果 寫入後佔用空間量 (MySQL 約為 ClickHouse 的 4 倍)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 localhost :) SELECT table, formatReadableSize(sum(bytes)) AS size FROM system.parts WHERE active AND database = \u0026#39;test\u0026#39; GROUP BY table; ┌─table────┬─size───────┐ │ lineitem │ 2.70 GiB │ │ orders │ 614.02 MiB │ │ partsupp │ 447.38 MiB │ │ customer │ 121.90 MiB │ │ part │ 89.70 MiB │ │ supplier │ 7.55 MiB │ │ nation │ 1.66 KiB │ │ region │ 523.00 B │ └──────────┴────────────┘ 8 rows in set. Elapsed: 0.008 sec. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 SELECT TABLE_NAME, CASE WHEN floor(( DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 / 1024) \u0026gt; 0 THEN CONCAT(ROUND((( DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 / 1024),2), \u0026#34;GB\u0026#34;) WHEN floor(( DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 ) \u0026gt; 0 THEN CONCAT(ROUND((( DATA_LENGTH + INDEX_LENGTH) / 1024 / 1024 ),2), \u0026#34;MB\u0026#34;) WHEN floor(( DATA_LENGTH + INDEX_LENGTH) / 1024) \u0026gt; 0 THEN CONCAT(ROUND((( DATA_LENGTH + INDEX_LENGTH) / 1024),2), \u0026#34;KB\u0026#34;) ELSE CONCAT((( DATA_LENGTH + INDEX_LENGTH)), \u0026#34;Byte\u0026#34;) END AS `size` FROM information_schema.TABLES WHERE TABLE_SCHEMA = \u0026#39;test\u0026#39; ORDER BY DATA_LENGTH DESC; +------------+----------+ | TABLE_NAME | size | +------------+----------+ | lineitem | 8.05GB | | orders | 2.06GB | | partsupp | 2.03GB | | part | 329.89MB | | customer | 290.84MB | | supplier | 18.55MB | | nation | 16.00KB | | region | 16.00KB | +------------+----------+ 8 rows in set (0.01 sec) 無任何優化\nTPC-H 語法 語法類型 MySQL ClickHouse 1.sql lineitem GROUP BY 1m17.663s 0m1.780s 2.sql part, supplier, partsupp, nation, region 五表 JOIN 0m22.257s 2m17.674s 3.sql customer, orders, lineitem 三表 JOIN 0m29.132s 0m3.624s 4.sql 0m26.961s 0m1.760s 5.sql 0m35.477s 0m5.084s 6.sql 0m0.012s 0m0.571s 7.sql 0m57.946s 0m17.775s 8.sql 0m57.167s 0m48.609s 9.sql 4m13.980s 4m48.043s 10.sql 0m59.013s 0m3.348s 11.sql 0m0.010s 0m4.750s 12.sql 0m33.102s 0m1.271s 13.sql 0m20.790s 0m3.518s 14.sql 0m0.013s 0m0.925s 15.sql 0m26.780s 0m1.196s 16.sql 0m10.672s 0m1.082s 17.sql 0m0.010s 0m2.975s 18.sql 0m28.808s 0m7.432s 19.sql 0m40.692s 超過 30 m 20.sql 0m47.100s 0m3.690s 21.sql 1m47.974s 0m36.074s 22.sql 0m0.011s 0m0.371s TPC-H 語法 語法類型 MySQL ClickHouse 1.sql lineitem GROUP BY 2m35.400s 0m4.737s 2.sql part, supplier, partsupp, nation, region 五表 JOIN 0m44.018s 9m12.907s 3.sql customer, orders, lineitem 三表 JOIN 1m3.439s 0m8.025s 4.sql 1m3.102s 0m3.722s 5.sql 1m15.256s 0m11.686s 6.sql 0m0.059s 0m1.156s 7.sql 1m44.087s 0m39.855s 8.sql 1m50.143s 3m37.400s 9.sql 6m31.232s 24m26.138s 10.sql 1m57.491s 0m6.302s 11.sql 0m0.065s 0m8.977s 12.sql 0m58.876s 0m2.719s 13.sql 0m41.079s 0m7.431s 14.sql 0m0.050s 0m1.613s 15.sql 0m45.950s 0m2.278s 16.sql 0m30.624s 0m1.245s 17.sql 0m0.060s 0m5.937s 18.sql 0m46.592s 0m15.944s 19.sql 1m4.889s 超過 30 m 20.sql 4m0.176s 0m4.841s 21.sql 8m58.563s 1m18.094s 22.sql 0m0.061s 0m1.139s Query 內容 Q1：單張大表 GROUP BY 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 select l_returnflag, l_linestatus, sum(l_quantity) as sum_qty, sum(l_extendedprice) as sum_base_price, sum(l_extendedprice*(1-l_discount)) as sum_disc_price, sum(l_extendedprice*(1-l_discount)*(1+l_tax)) as sum_charge, avg(l_quantity) as avg_qty, avg(l_extendedprice) as avg_price, avg(l_discount) as avg_disc, count(*) as count_order from lineitem where l_shipdate \u0026lt;= date \u0026#39;1998-12-01\u0026#39; - interval \u0026#39;[DELTA]\u0026#39; day (3) //DELTA是60~120内的值 group by l_returnflag, l_linestatus order by l_returnflag, l_linestatus; Q2：五張表 JOIN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 select s_acctbal, s_name, n_name, p_partkey, p_mfgr, s_address, s_phone, s_comment /*查询供应者的帐户余额、名字、国家、零件的号码、生产者、供应者的地址、电话号码、备注信息 */ from part, supplier, partsupp, nation, region //五表连接 where p_partkey = ps_partkey and s_suppkey = ps_suppkey and p_size = [SIZE] //指定大小，在区间[1, 50]内随机选择 and p_type like \u0026#39;%[TYPE]\u0026#39; //指定类型，在TPC-H标准指定的范围内随机选择 and s_nationkey = n_nationkey and n_regionkey = r_regionkey and r_name = \u0026#39;[REGION]\u0026#39; //指定地区，在TPC-H标准指定的范围内随机选择 and ps_supplycost = ( //子查询 select min(ps_supplycost) //聚集函数 from partsupp, supplier, nation, region //与父查询的表有重叠 where p_partkey = ps_partkey and s_suppkey = ps_suppkey and s_nationkey = n_nationkey and n_regionkey = r_regionkey and r_name = \u0026#39;[REGION]\u0026#39; ) order by //排序 總結 可以看出來 ClickHouse 擅長的是單張大表聚合查詢，不擅長於多表 JOIN 查詢。\n","date":"2024-10-16T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-tpch-test/","title":"ClickHouse TPC-H Test"},{"content":"本文較長建議搭配右側目錄點擊查看。\nHOW? 建立一張和原表結構相同的 ghost 表 ALTER ghost 表 gh-ost 偽裝成 SLAVE 從 Master/Slave 拉取 binlog 將資料寫入 ghost 表 將 binlog event 應用到 ghost 表 從原表複製 rows 到 ghost 表 切換 ghost 表和原表 上述的步驟中可以看出 gh-ost 的大部分和其他online DDL 工具大體相同，唯一的不同處就是 gh-ost 不是基於 trigger 。 gh-ost 的開發團隊認為使用 trigger 有許多的限制與風險，有興趣可以參考官方文檔 Why triggerless 這篇說明。\n取而代之的是 gh-ost 透過 binlog 來獲取原表資料的改動，並將之異步應用到 ghost 表。 gh-ost 承擔了其他工具留給 DATABASE 執行的任務(trigger)，等於是完全分離了遷移資料時的寫Loading和 DATABASE 服務本身的 Loading，因此 gh-ost 可能更好的控制整個遷移的過程，可以做到真正的暫停。\n特點 No trigger：這是 gh-ost的特點，基於 trigger的方案會對 MySQL的性能造成較大的影響。 gh-ost 解析 binlog 後寫入數據，不僅可控對 MySQL 的性能影響也很小。 真正的暫停：當 gh-ost進入 throttle狀態時， gh-ost 真正停止了對 MASTER 的寫入(除了必要的低負載的心跳紀錄)，讓 MASTER 可以回到原始的 Loading 狀態。 動態控制：即使已經開始運行 gh-ost，也可以透過 交互式命令 隨時重新配置 gh-ost 部分參數，甚至你可以強制讓 gh-ost 進入 throttle 狀態。 可審核：可以透過 unix socket、 TCP 或 table _ghc 查詢 gh-ost 狀態。 可測試： gh-ost 可以在 SLAVE 進行遷移，用以觀察 Loading 和 正確性後再投入使用。 控制切換階段： cut over 是 gh-ost 最關鍵的一個步驟，你可以隨時決定 cut over 的時間。 外部 hook： gh-ost 提供 hook 功能，例如：可以用於推送到 SLACK 群組告知進度。 執行步驟 初始步驟檢查一下參數，並新增兩張表 ghost table(_gho)、 log\u0026amp;heartbeat table(_ghc)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 -- SLAVE SET autocommit=true SET NAMES utf8mb4 select @@global.version select @@global.port select @@global.hostname, @@global.port show /* gh-ost */ grants for current_user() select @@global.log_bin, @@global.binlog_format select @@global.binlog_row_image show /* gh-ost */ table status from `ghost_test` like \u0026#39;event_1\u0026#39; -- Master SET autocommit=true SET NAMES utf8mb4 select @@global.version select @@global.port select @@global.time_zone select @@global.hostname, @@global.port show columns from `ghost_test`.`event_1` show /* gh-ost */ table status from `ghost_test` like \u0026#39;_event_1_gho\u0026#39; show /* gh-ost */ table status from `ghost_test` like \u0026#39;_event_1_del\u0026#39; drop /* gh-ost */ table if exists `ghost_test`.`_event_1_ghc` create /* gh-ost */ table `ghost_test`.`_event_1_ghc` ( id bigint auto_increment, last_update timestamp not null DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, hint varchar(64) charset ascii not null, value varchar(4096) charset ascii not null, primary key(id), unique key hint_uidx(hint) ) auto_increment=256 create /* gh-ost */ table `ghost_test`.`_event_1_gho` like `ghost_test`.`event_1` alter /* gh-ost */ table `ghost_test`.`_event_1_gho` ADD COLUMN test varchar(20) AFTER remark 根據 exact-rowcount 的設定來決定計算行數的方式，在 Slave 執行\n1 2 3 4 --no exact-rowcount：透過explian取得估算值 explain select /* gh-ost */ * from `ghost_test`.`event_1` where 1=1; --exact-rowcount：透過count(*)取得精準值 select /* gh-ost */ count(*) as rows from `ghost_test`.`event_1`; 通過 order by 來取得 shared key 最小值和最大值範圍\n1 2 3 4 5 6 7 8 -- Master select /* gh-ost `ghost_test`.`event_1` */ `order_id` from `ghost_test`.`event_1` order by `order_id` asc limit 1 select /* gh-ost `ghost_test`.`event_1` */ `order_id` from `ghost_test`.`event_1` order by `order_id` desc limit 1 透過以下語法判斷是否還有未複製的資料\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -- Master -- 假設每次批次為1000筆 -- 取得每次批次的第1000、2000...筆order_id select /* gh-ost `ghost_test`.`event_1` iteration:0 */ `order_id` from `ghost_test`.`event_1` where ((`order_id` \u0026gt; _binary\u0026#39;00AD4267F1A3467\u0026#39;) or ((`order_id` = _binary\u0026#39;00AD4267F1A3467\u0026#39;))) and ((`order_id` \u0026lt; _binary\u0026#39;FEB556F8553843A\u0026#39;) or ((`order_id` = _binary\u0026#39;FEB556F8553843A\u0026#39;))) order by `order_id` asc limit 1 offset 999 -- 若上述sql返回空值，則使用此語法撈取最後一筆order_id select /* gh-ost `ghost_test`.`event_1` iteration:1 */ `order_id` from ( select `order_id` from `ghost_test`.`event_1` where ((`order_id` \u0026gt; _binary\u0026#39;FE01373BB55A45F\u0026#39;)) and ((`order_id` \u0026lt; _binary\u0026#39;FEB556F8553843A\u0026#39;) or ((`order_id` = _binary\u0026#39;FEB556F8553843A\u0026#39;))) order by `order_id` asc limit 1000 ) select_osc_chunk order by `order_id` desc limit 1 當有未複製的資料，透過下面的方式從原表複製資料到 ghost table\n1 2 3 4 5 6 7 -- Master insert /* gh-ost `ghost_test`.`event_1` */ ignore into `ghost_test`.`_event_1_gho` (`site_id`, `order_id`, `game_hall`, `user_id`, `op_id`, `txn_id`, `amount`, `event_time`, `remark`, `create_time`, `update_time`) (select `site_id`, `order_id`, `game_hall`, `user_id`, `op_id`, `txn_id`, `amount`, `event_time`, `remark`, `create_time`, `update_time` from `ghost_test`.`event_1` force index (`PRIMARY`) where (((`order_id` \u0026gt; _binary\u0026#39;2B94A39A501247D\u0026#39;) or ((`order_id` = _binary\u0026#39;2B94A39A501247D\u0026#39;))) and ((`order_id` \u0026lt; _binary\u0026#39;2B94A39A501247D\u0026#39;) or ((`order_id` = _binary\u0026#39;2B94A39A501247D\u0026#39;)))) lock in share mode) 最後一步cut-over 階段\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- Master create /* gh-ost */ table `ghost_test`.`_event_1_del` ( id int auto_increment primary key ) engine=InnoDB comment=\u0026#39;ghost-cut-over-sentry\u0026#39; lock /* gh-ost */ tables `ghost_test`.`event_1` write, `g host_test`.`_event_1_del` write rename /* gh-ost */ table `ghost_test`.`event_1` to `ghost_test`.`_event_1_del`, `ghost_test`.`_event_1_gho` to `ghost_test`.`event_1` drop /* gh-ost */ table if exists `ghost_test`.`_event_1_del` drop /* gh-ost */ table if exists `ghost_test`.`_event_1_ghc` unlock tables 讓我們整理一下 gh-ost 的操作：\n應用類型 原表操作 新表操作 Row Copy SELECT INSERT IGNORE INTO Binlog Apply INSERT REPLACE INTO Binlog Apply UPDATE UPDATE (所有欄位） Binlog Apply DELETE DELETE 在數據遷移的過程中，數據的變動有以下三種組合：\n從原表 RowCopy → 對 原表DML操作 → Binlog Apply 在此情況下一切都照順序運行，因此不論是 INSERT、 UPDATE、 DELETE 都沒有疑慮。 對 原表DML操作 → Binlog Apply → 從原表 RowCopy INSERT： Row Copy 被轉換為 INSERT INGNORE INTO，因此不會蓋掉 Binlog Apply 的 INSERT 操作。 UPDATE、DELETE：因為還沒從原表 Copy 過來，所以 Binlog Apply 的操作會沒有任何結果，但是最後從原表 Copy 過來時即會是最新的數據，因此也沒有問題。 對 原表DML 操作 → 從原表 RowCopy → Binlog Apply INSERT： Binlog Apply:INSERT被轉換為 REPLACE INTO，會覆蓋掉 Row Copy:INSERT 操作，但兩者的結果一樣因此不影響。 UPDATE、DELETE：從原表 Copy 過來就是最新的數據，後續的 Binlog Apply 也不會影響到數據，因此也沒有問題。 要求與限制 Requirements 要求：\ngh-ost 需要在 MySQL 5.7 以上的版本上運行 server 必須開啟 log_bin，若為 Slave 同時也必須開啟 log_slave_updates 需要一台 binlog_format 為 ROW 及 binlog_row_image 為 full 模式的 server 如果在slave上使用，必須確保要ALTER的TABLE在Master和Slave上Schema相同 權限： ALTER, CREATE, DELETE, DROP, INDEX, INSERT, LOCK TABLES, SELECT, TRIGGER, UPDATE ON database.* OR *.* SUPER, REPLICATION SLAVE on *.* 或 REPLICATION CLIENT, REPLICATION SLAVE on *.* SUPER權限用於 STOP SLAVE 和 START SLAVE，具體用途為：\n當 binlog_format不是 ROW 並且指定 --switch-to-rbr 時，將切換 binlog_format 並重啟 replication。如果是 ROW 模式可以指定 --assume-rbr 避免 STOP SLAVE 和 START SLAVE ，在此情況下，不需要提供 SUPER 權限。 (提醒！若自行切換 binlog_format 須記得重啟replication！) 運行 --test-on-replica 時，gh-ost切換表後會停止 replication ，讓使用者比較兩張表。 Limitations 限制：\n目前不支持外鍵。未來可能會提供一定程度的支持 目前不支持trigger。未來可能會提供支持 支持MySQL 5.7的 JSON ，但前提是不能是 PRIMARY KEY 的一部分 新表和舊表必須使用相同的 PRIMARY KEY 或 UNIQUE KEY 。因為複製時會 gh-ost 會利用該 KEY遍歷所有行。遷移鍵必須為 NOT NULL (可以為空值)。或是有 NULL屬性 並使用 --allow-nullable-unique-key 但必須確保實際上沒有 NULL 值，否則可能導致數據不完整。 當存在名稱相同僅大小寫不同的table時無法進行 阿里雲RDS能正常運作，僅需要添加 --aliyun-rds Google Cloud SQL可使用，僅需添加 --gcp Amazon RDS可以使用，但有些限制，請參閱官方文檔 當 SLAVE 的來源為multi時，無法支持在 SLAVE 上執行，建議直接在 MASTER上進行，需添加 --allow-on-master 目前當在 master-master 運行 gh-ost 時，沒有辦法支援兩邊都有寫入的情況。將來可能支援 若將 enum 型態的欄位作為 PRIMARY KEY 將使性能降低 不支援 federated Table ，並且與 gh-ost 想要解決的方案無關 不支持 ALTER TABLE ... RENAME TO some_other_name ，這樣的操作不應該是用 gh-ost 並發遷移(Concurrent migrations) 絕對不要運行在同一個 Table 上。 如果運行在不同的 SLAVE 上，不需要其他調整。例如：table1 on slave1 和 table2 on slave2。 如果在同一個機器運行 gh-ost 確保 -server-socket-file 設置不同名稱（或由 gh-ost 命名）。 透過 -throttle-additional-flag-file 控制所有 gh-ost，另外透過 throttle-flag-file 控制單一 gh-ost 。 如果 -host 相同，則必須對每個 gh-ost 設定唯一的 replica-server-id 避免衝突。 Throttle 介紹 在遷移的過中， gh-ost 的狀態除了持續的複製原表和應用binlog外，還有另一個狀態是 throttling\n當 throttled(限制) 的時候， gh-ost 會暫停所有寫操作，包含複製原表的資料和檢查binlog，但仍會做 low-volume changlog status writes 和 heartbeat writes 。\n當 gh-ost 被限制時，對主機的 Loading 將徹底消失，和基於 trigger 原理的工具相比這是 gh-ost 的優勢，因為 trigger 無法暫停會持續的寫入新資料，相反的 gh-ost 包含複製原表資料和寫入新資料（透過應用 binlog event）都是由 gh-ost 進行控制。\ngh-ost 支持各種限制的方法，並且他能允許使用者動態的調整。\n參數和因素 Replication lag 推薦將 gh-ost 連結到 Slave， gh-ost 會自行找出 Master 開始進行遷移的同時， gh-ost 有自己的心跳機制去檢查他所連接的 Slave 是否有 replication lag 的狀況。或者也可以自行指定要檢查 replication lag 的清單。\n--throttle-control-replicas ：明確列出需要 gh-ost 檢查 replication lag 的 Slave 清單 範例：\u0026ndash;throttle-control-replicas=myhost1.com:3306,myhost2.com,myhost3.com:3307\n--max-lag-millis：允許 replication lag 的最大值，任何在檢查清單中的 replication lag 超過此值都將導致 throttling，除非清單中的所有 replication lag 都小於此值才會恢復。\n以上設定可以透過 Interaction commands 來隨時動態調整。\nStatus thresholds --max-load ：當指定的指標超過設定的閾值時，將導致 throttling 發生。\n範例：\u0026ndash;max-load=\u0026lsquo;Threads_running=100,Threads_connected=500\u0026rsquo;\n指標必須是有效且為數字的 status variables (可參考mysql 官網)\nThrottle query 當提供 --throttle-query 時，必須確保返回整數，每秒會執行該查詢(因此應確保此查詢為輕量的)，當返回值 \u0026gt; 0 時 gh-ost 將進入 throttling 狀態；反之當返回值 \u0026lt;= 0 時且沒有其他限制因素時，則 gh-ost 正常運作\n範例：\u0026ndash;throttle-query=\u0026ldquo;select hour(now()) between 8 and 17\u0026rdquo; 表示 8:00am 開始進入 throttling 狀態，直到 18:00pm 解除。\nHTTP Throttle The --throttle-http flag allows for throttling via HTTP. Every 100ms gh-ost issues a HEAD request to the provided URL. If the response status code is not 200 throttling will kick in until a 200 response status code is returned.\nIf no URL is provided or the URL provided doesn\u0026rsquo;t contain the scheme then the HTTP check will be disabled. For example --throttle-http=\u0026quot;http://1.2.3.4:6789/throttle\u0026quot; will enable the HTTP check/throttling, but --throttle-http=\u0026quot;1.2.3.4:6789/throttle\u0026quot; will not.\nThe URL can be queried and updated dynamically via interactive interface.\n手動控制 除了以上的自動控制，還可以隨時手動讓 gh-ost 進入 throttling 狀態。\n--throttle-flag-file ：當該文件存在時，進入 throttling 狀態。可以使用 touch 建立即可\n--throttle-additional-flag-file ：與上述類似，當該文件存在時，進入 throttling 狀態。\n默認值為： /tmp/gh-ost.throttle\n有兩種參數的原因是可以運行多個 gh-ost ，--throttle-flag-file 為單個 gh-ost 所使用，--throttle-additional-flag-file 則是同時控制所有 gh-ost ，因此我們可以透過 touch 不同的文件來限制單個或多個 gh-ost\n透過 Interactive commands 對 gh-ost 下達 throttle\n範例：\n1 2 echo throttle | nc -U /tmp/gh-ost.test.sample_data_0.sock echo no-throttle | nc -U /tmp/gh-ost.test.sample_data_0.sock Throttle precedence 上述提到的任何因素都將導致 gh-ost 進入 throttling 狀態，因此一旦其中一個因素引發 throttling 你都無法強制繼續執行遷移。\ngh-ost 會在不同的時間點獨立收集不同的指標，並異步檢查不同的指標是否有達到閾值，因此 gh-ost 只會返回第一個超過閾值的指標作為 throttling 原因。\nThrottle status throttle 狀態會作為 status message 定期的 print 出來：\n1 2 Copy: 0/2915 0.0%; Applied: 0; Backlog: 0/100; Elapsed: 41s(copy), 41s(total); streamer: mysql-bin.000551:47983; ETA: throttled, flag-file Copy: 0/2915 0.0%; Applied: 0; Backlog: 0/100; Elapsed: 42s(copy), 42s(total); streamer: mysql-bin.000551:49370; ETA: throttled, commanded by user 可以 throttle 多久 最長可以維持 throttle 狀態的時間依賴於 binlog 保留的時間，因為當進入 throttling 狀態時， gh-ost 將暫停讀取 binlog ，之後恢復會從同一個 binlog 開始。\nbinlog 保留時間通常透過 expire_logs_days 設定，或者是其他外部腳本，因此必須先確認機器上的部屬，另外雖然 binlog 保留多久 gh-ost 就能 throttle 多久，但是在此期間 gh-ost 必須一直運行，並且相應的當恢復之後需要應用相當大量的 binlog event 。\n互動指令 gh-ost 允許用戶在運行時控制其行為\nInteractive interfaces gh-ost 可以透過以下方式進行監聽：\nUNIX socket file： gh-ost 運行時會產生 socket file 也可以透過 --server-socket-file 指定位置。 TCP：需要帶入 --server-tcp-port 參數 Known commands help：提示可以使用的命令 status：返回遷移的進度，和詳細的狀態 sup：返回遷移進度的簡要狀態 coordinates：返回被檢查 binlog 的 server，最新的position位置 chunk-size=\u0026lt;newsize\u0026gt;：修改 chunk-size，將在下一次 copy-iteration 生效 dml-batch-size=\u0026lt;newsize\u0026gt;：修改 dml-batch-size，將在下一次應用 binlog event 生效 max-lag-millis=\u0026lt;max-lag\u0026gt;：調整 max-lag-millis 的配置 max-load=\u0026lt;max-load-thresholds\u0026gt;：修改 max-load 的配置，將在下一次 copy-iteration 生效 critical-load=\u0026lt;critical-load-thresholds\u0026gt;：修改 critical-load 的配置 nice-ratio=\u0026lt;ratio\u0026gt;：修改 nice-ratio 比例 throttle-http：change throttle HTTP endpoint throttle-query：修改 throttle query throttle-control-replicas='replica1,replica2'：修改 throttle control replicas throttle：強制進入 throttle 狀態 no-throttle：取消強制進入 throttle 狀態，但仍會受其他因素暫停 unpostpone：在 gh-ost 推遲 cut-over 階段時，只是 gh-ost 停止推遲並立刻 cut-over panic：立即 panic 並停止操作 Querying for data 對於上述命令在傳遞參數時，設置為 ? 時，可以查詢數據\n範例 1 2 3 4 5 6 7 8 $ echo status | nc -U /tmp/gh-ost.test.sample_data_0.sock # Migrating `test`.`sample_data_0`; Ghost table is `test`.`_sample_data_0_gst` # Migration started at Tue Jun 07 11:45:16 +0200 2016 # chunk-size: 200; max lag: 1500ms; dml-batch-size: 10; max-load: map[Threads_connected:20] # Throttle additional flag file: /tmp/gh-ost.throttle # Serving on unix socket: /tmp/gh-ost.test.sample_data_0.sock # Serving on TCP port: 10001 Copy: 0/2915 0.0%; Applied: 0; Backlog: 0/100; Elapsed: 40s(copy), 41s(total); streamer: mysql-bin.000550:49942; ETA: throttled, flag-file 1 2 3 4 5 6 7 $ echo \u0026#34;chunk-size=250\u0026#34; | nc -U /tmp/gh-ost.test.sample_data_0.sock # Migrating `test`.`sample_data_0`; Ghost table is `test`.`_sample_data_0_gst` # Migration started at Tue Jun 07 11:56:03 +0200 2016 # chunk-size: 250; max lag: 1500ms; dml-batch-size: 10; max-load: map[Threads_connected:20] # Throttle additional flag file: /tmp/gh-ost.throttle # Serving on unix socket: /tmp/gh-ost.test.sample_data_0.sock # Serving on TCP port: 10001 1 2 $ echo \u0026#34;chunk-size=?\u0026#34; | nc -U /tmp/gh-ost.test.sample_data_0.sock 250 1 2 3 4 5 6 7 8 9 10 $ echo throttle | nc -U /tmp/gh-ost.test.sample_data_0.sock $ echo status | nc -U /tmp/gh-ost.test.sample_data_0.sock # Migrating `test`.`sample_data_0`; Ghost table is `test`.`_sample_data_0_gst` # Migration started at Tue Jun 07 11:56:03 +0200 2016 # chunk-size: 250; max lag: 1500ms; max-load: map[Threads_connected:20] # Throttle additional flag file: /tmp/gh-ost.throttle # Serving on unix socket: /tmp/gh-ost.test.sample_data_0.sock # Serving on TCP port: 10001 Copy: 0/2915 0.0%; Applied: 0; Backlog: 0/100; Elapsed: 59s(copy), 59s(total); streamer: mysql-bin.000551:68067; ETA: throttled, commanded by user Cut over 解析 情境 假設 C10、C20 為 gh-ost 所使用的連結， C1..C9、 C11..C19、 C21..C29 為其他連線。\nC1..C9：對 原表(tb1) 進行 INSERT、UPDATE、DELETE 等DML操作 C10： CREATE TABLE tb1_old(id int primary key) COMMENT='magic-be-here' C10： LOCK TABLES tb1 WRITE, tb1_old WRITE C11..C19：新的連線對 tb1進行DML操作，但由於 tb1被 LOCK住而阻塞 C20： RENAME TABLE tbl TO tbl_old, ghost TO tbl，雖然因為 LOCK 此操作會被阻塞，但在阻塞的對列中優先級會高於 C1..C9 和 C11..C19 C21..C29：新的連線對 tb1進行DML操作，但由於 tb1被 LOCK住而阻塞 C10：透過 show processlist 確認是否有 C20的RENAME 操作 C10： DROP TABLE tbl_old，什麼事都沒有發生 tb1 仍舊被 LOCK C10： UNLOCK TABLES 最後，阻塞的對列中 RENAME 優先被執行，接下來是 C1..C9 C11..C19 C21..C29 都直接應用到更新後的 tb1。\n解析 在 MySQL 中有兩種方式可以 RENAME TABLE： RENAME TABLE：能夠同時 rename多張表，這表示 rename多張表是原子的操作。但在 8.0.13 之前無法在同一個 session 同時 LOCK和 RENAME。 ALTER TABLE RENAME：能夠在 LOCK TABLE 的 session 進行，但卻無法一次 RENAME多張表。 tb1_old的存在，避免 Lock連線死掉後的影響。 Lock Table 避免 RENAME 過早執行。 在阻塞的對列中， RENAME總是優先於 INSERT、UPDATE、DELETE。 失敗的影響 如果在 C10 Create table 或 Lock table失敗，則不會繼續執行後續步驟。 如果在 C20 Rename時 C10 Lock連線死亡，因為 tb1_old的存在 Rename失敗，同時 Lock 解除， C1..C9和 C11..C19正常執行，唯一的影響只有查詢被阻塞了一段時間。 如果 C20 Rename在 C10 Drop 或 Unlock之前死亡， gh-ost會正常執行 Drop、UnLock，因此唯一的影響一樣只是查詢被阻塞一段時間。 hook 用途範例 希望遷移完成/失敗時，能夠收到通知 希望當 gh-ost 開始推遲 cut-over 時收到通知 希望 gh-ost 定期回報進度 使用hook 所有的hook都應該放在 --hooks-path 指定的目錄裡，如果沒有提供則不執行 hook。\nhook的命名必須為以下前綴：\ngh-ost-on-startup gh-ost-on-validated gh-ost-on-rowcount-complete gh-ost-on-before-row-copy gh-ost-on-status gh-ost-on-interactive-command gh-ost-on-row-copy-complete gh-ost-on-stop-replication gh-ost-on-start-replication gh-ost-on-begin-postponed gh-ost-on-before-cut-over gh-ost-on-success gh-ost-on-failure 環境變量 GH_OST_DATABASE_NAME GH_OST_TABLE_NAME GH_OST_GHOST_TABLE_NAME GH_OST_OLD_TABLE_NAME：原始表在 cut-over 之後的名稱 GH_OST_DDL：DDL 語句 GH_OST_ELAPSED_SECONDS：總運行時間 GH_OST_ELAPSED_COPY_SECONDS：Row copy 花費的時間 GH_OST_ESTIMATED_ROWS：估計的行數 GH_OST_COPIED_ROWS：gh-ost 複製的行數 GH_OST_INSPECTED_LAG：replication lag (second) GH_OST_PROGRESS：遷移的進度 [0\u0026hellip;100] % GH_OST_MIGRATED_HOST GH_OST_INSPECTED_HOST GH_OST_EXECUTING_HOST GH_OST_HOOKS_HINT： --hooks-hint的值 GH_OST_HOOKS_HINT_OWNER： --hooks-hint-owner的值 GH_OST_HOOKS_HINT_TOKEN：--hooks-hint-token的值 GH_OST_DRY_RUN： gh-ost 是否是 dry run GH_OST_COMMAND：only available in gh-ost-on-interactive-command GH_OST_STATUS：only available in gh-ost-on-status 範例 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # 當gh-ost啟動時推送到slack slack_hook=`cat /var/lib/DBA/gh-ost/gh-ost_hooks/slack-webhook` show_time=$(date +\u0026#34;(%:z)%Y-%m-%d %H:%M:%S\u0026#34;) show_day=$(date +\u0026#34;%b %-d\u0026#34;) GH_OST_MIGRATED_HOST=$GH_OST_MIGRATED_HOST GH_OST_DATABASE_NAME=$GH_OST_DATABASE_NAME GH_OST_TABLE_NAME=$GH_OST_TABLE_NAME GH_OST_DDL=$GH_OST_DDL # 推送到slack curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data \u0026#39;{\u0026#34;blocks\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*\u0026lt;gh-ost.com|[Start] - gh-ost 已開始熱更新 :gh-ost:\u0026gt;*\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*Start_Time:* \u0026#39;\u0026#34;${show_time}\u0026#34;\u0026#39;\\n*Host:* \u0026#39;\u0026#34;${GH_OST_MIGRATED_HOST}\u0026#34;\u0026#39;\\n*Table:* `\u0026#39;\u0026#34;${GH_OST_DATABASE_NAME}\u0026#34;\u0026#39;`.`\u0026#39;\u0026#34;${GH_OST_TABLE_NAME}\u0026#34;\u0026#39;`\\n*DDL:* \u0026#39;\u0026#34;${GH_OST_DDL}\u0026#34;\u0026#39;\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;,\u0026#34;elements\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;:gh-ost: *gh-ost* | \u0026#39;\u0026#34;${show_day}\u0026#34;\u0026#39; \u0026#34;}]}]}\u0026#39; ${slack_hook} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #!/bin/bash # Sample hook file for gh-ost-on-status # gh-ost 推送狀態到 slack slack_hook=`cat /var/lib/DBA/gh-ost/gh-ost_hooks/slack-webhook` show_time=$(date +\u0026#34;(%:z)%Y-%m-%d %H:%M:%S\u0026#34;) show_day=$(date +\u0026#34;%b %-d\u0026#34;) GH_OST_MIGRATED_HOST=$GH_OST_MIGRATED_HOST GH_OST_DATABASE_NAME=$GH_OST_DATABASE_NAME GH_OST_TABLE_NAME=$GH_OST_TABLE_NAME GH_OST_DDL=$GH_OST_DDL GH_OST_ELAPSED_SECONDS=$GH_OST_ELAPSED_SECONDS GH_OST_STATUS=$GH_OST_STATUS GH_OST_PROGRESS=$GH_OST_PROGRESS # 計算每分鐘平均進度 cycle_calc=`echo | awk \u0026#34;{print $GH_OST_PROGRESS/$GH_OST_ELAPSED_SECONDS*60}\u0026#34;` # 計算上一分鐘的進度 last_progress=`echo | awk \u0026#34;{print $GH_OST_PROGRESS-$cycle_calc}\u0026#34;` # 進度超過80%以上時推送一次即可。當本分鐘進度 \u0026gt; 80 且 上一分鐘進度小於80時印出 if [ `echo $GH_OST_PROGRESS | cut -d . -f 1` -eq 100 ] \u0026amp;\u0026amp; [ `echo $GH_OST_PROGRESS | cut -d . -f 1` -ge 80 ] \u0026amp;\u0026amp; [ `echo $last_progress | cut -d . -f 1` -lt 80 ]; then curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data \u0026#39;{\u0026#34;blocks\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*\u0026lt;gh-ost.com|[Report] - gh-ost 回報目前狀態 :busy:\u0026gt;*\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*Report_Time:* \u0026#39;\u0026#34;${show_time}\u0026#34;\u0026#39;\\n*Host:* \u0026#39;\u0026#34;${GH_OST_MIGRATED_HOST}\u0026#34;\u0026#39;\\n*Table:* `\u0026#39;\u0026#34;${GH_OST_DATABASE_NAME}\u0026#34;\u0026#39;`.`\u0026#39;\u0026#34;${GH_OST_TABLE_NAME}\u0026#34;\u0026#39;`\\n*DDL:* \u0026#39;\u0026#34;${GH_OST_DDL}\u0026#34;\u0026#39;\\n*Time elapsed(sec):* \u0026#39;\u0026#34;${GH_OST_ELAPSED_SECONDS}\u0026#34;\u0026#39;\\n*Status:*\\n ```\u0026#39;\u0026#34;${GH_OST_STATUS}\u0026#34;\u0026#39;```\\n*當前進度:* \u0026#39;\u0026#34;${GH_OST_PROGRESS}\u0026#34;\u0026#39;%\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;,\u0026#34;elements\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;:gh-ost: *gh-ost* | \u0026#39;\u0026#34;${show_day}\u0026#34;\u0026#39;\u0026#34;}]}]}\u0026#39; ${slack_hook} fi 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # Sample hook file for gh-ost-on-failure # 當gh-ost失敗時推送到slack slack_hook=`cat /var/lib/DBA/gh-ost/gh-ost_hooks/slack-webhook` show_time=$(date +\u0026#34;(%:z)%Y-%m-%d %H:%M:%S\u0026#34;) show_day=$(date +\u0026#34;%b %-d\u0026#34;) GH_OST_MIGRATED_HOST=$GH_OST_MIGRATED_HOST GH_OST_DATABASE_NAME=$GH_OST_DATABASE_NAME GH_OST_TABLE_NAME=$GH_OST_TABLE_NAME GH_OST_DDL=$GH_OST_DDL curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data \u0026#39;{\u0026#34;blocks\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*\u0026lt;gh-ost.com|[`Warning`] - gh-ost 熱更新失敗:alert:\u0026gt;*\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*Failed_Time:* \u0026#39;\u0026#34;${show_time}\u0026#34;\u0026#39;\\n*Host:* \u0026#39;\u0026#34;${GH_OST_MIGRATED_HOST}\u0026#34;\u0026#39;\\n*Table:* `\u0026#39;\u0026#34;${GH_OST_DATABASE_NAME}\u0026#34;\u0026#39;`.`\u0026#39;\u0026#34;${GH_OST_TABLE_NAME}\u0026#34;\u0026#39;`\\n*DDL:* \u0026#39;\u0026#34;${GH_OST_DDL}\u0026#34;\u0026#39;\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;,\u0026#34;elements\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;:gh-ost: *gh-ost* | \u0026#39;\u0026#34;${show_day}\u0026#34;\u0026#39;\u0026#34;}]}]}\u0026#39; ${slack_hook} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/bin/bash # Sample hook file for gh-ost-on-begin-postponed # 當gh-ost 開始推遲cut over時推送slack slack_hook=`cat /var/lib/DBA/gh-ost/gh-ost_hooks/slack-webhook` show_time=$(date +\u0026#34;(%:z)%Y-%m-%d %H:%M:%S\u0026#34;) show_day=$(date +\u0026#34;%b %-d\u0026#34;) GH_OST_MIGRATED_HOST=$GH_OST_MIGRATED_HOST GH_OST_DATABASE_NAME=$GH_OST_DATABASE_NAME GH_OST_TABLE_NAME=$GH_OST_TABLE_NAME GH_OST_DDL=$GH_OST_DDL GH_OST_ELAPSED_SECONDS=$GH_OST_ELAPSED_SECONDS curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data \u0026#39;{\u0026#34;blocks\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*\u0026lt;gh-ost.com|[Postpon] - gh-ost is ready to cut-over(rename) :gj:\u0026gt;*\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*Postponed_Time:* \u0026#39;\u0026#34;${show_time}\u0026#34;\u0026#39;\\n*Host:* \u0026#39;\u0026#34;${GH_OST_MIGRATED_HOST}\u0026#34;\u0026#39;\\n*Table:* `\u0026#39;\u0026#34;${GH_OST_DATABASE_NAME}\u0026#34;\u0026#39;`.`\u0026#39;\u0026#34;${GH_OST_TABLE_NAME}\u0026#34;\u0026#39;`\\n*DDL:* \u0026#39;\u0026#34;${GH_OST_DDL}\u0026#34;\u0026#39;\\n*Time elapsed(sec):* \u0026#39;\u0026#34;${GH_OST_ELAPSED_SECONDS}\u0026#34;\u0026#39;\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;,\u0026#34;elements\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;:gh-ost: *gh-ost* | \u0026#39;\u0026#34;${show_day}\u0026#34;\u0026#39;\u0026#34;}]}]}\u0026#39; ${slack_hook} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #!/bin/bash # Sample hook file for gh-ost-on-status # gh-ost 收到互動式命令時推送到 slack slack_hook=`cat /var/lib/DBA/gh-ost/gh-ost_hooks/slack-webhook` show_time=$(date +\u0026#34;(%:z)%Y-%m-%d %H:%M:%S\u0026#34;) show_day=$(date +\u0026#34;%b %-d\u0026#34;) GH_OST_MIGRATED_HOST=$GH_OST_MIGRATED_HOST GH_OST_DATABASE_NAME=$GH_OST_DATABASE_NAME GH_OST_TABLE_NAME=$GH_OST_TABLE_NAME GH_OST_DDL=$GH_OST_DDL GH_OST_ELAPSED_SECONDS=$GH_OST_ELAPSED_SECONDS GH_OST_STATUS=$GH_OST_STATUS GH_OST_PROGRESS=$GH_OST_PROGRESS GH_OST_COMMAND=$(echo $GH_OST_COMMAND | sed \u0026#39;s/\u0026#39;\u0026#34;\u0026#39;\u0026#34;/\u0026#39;`\u0026#39;\u0026#39;/g\u0026#39;) if [ ${GH_OST_COMMAND} = \u0026#39;`unpostpone`\u0026#39; ] || [ ${GH_OST_COMMAND} = \u0026#39;`throttle`\u0026#39; ] || [ ${GH_OST_COMMAD} = \u0026#39;`panic`\u0026#39; ] || [ ${GH_OST_COMMAND} = \u0026#39;`no-throttle`\u0026#39; ] ; then curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data \u0026#39;{\u0026#34;blocks\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*\u0026lt;gh-ost.com|[New command] - gh-ost 收到命令 :ook:\u0026gt;*\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*Report_Time:* \u0026#39;\u0026#34;${show_time}\u0026#34;\u0026#39;\\n*Host:* \u0026#39;\u0026#34;${GH_OST_MIGRATED_HOST}\u0026#34;\u0026#39;\\n*Table:* `\u0026#39;\u0026#34;${GH_OST_DATABASE_NAME}\u0026#34;\u0026#39;`.`\u0026#39;\u0026#34;${GH_OST_TABLE_NAME}\u0026#34;\u0026#39;`\\n*DDL:* \u0026#39;\u0026#34;${GH_OST_DDL}\u0026#34;\u0026#39;\\n*Time elapsed(sec):* \u0026#39;\u0026#34;${GH_OST_ELAPSED_SECONDS}\u0026#34;\u0026#39;\\n*當前進度:* \u0026#39;\u0026#34;${GH_OST_PROGRESS}\u0026#34;\u0026#39;%\\n*Command:*\u0026#39;\u0026#34;${GH_OST_COMMAND}\u0026#34;\u0026#39;\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;,\u0026#34;elements\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;:gh-ost: *gh-ost* | \u0026#39;\u0026#34;${show_day}\u0026#34;\u0026#39;\u0026#34;}]}]}\u0026#39; ${slack_hook} fi 1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # Sample hook file for gh-ost-on-success # 當gh-ost 完成時推送slack slack_hook=`cat /var/lib/DBA/gh-ost/gh-ost_hooks/slack-webhook` show_time=$(date +\u0026#34;(%:z)%Y-%m-%d %H:%M:%S\u0026#34;) show_day=$(date +\u0026#34;%b %-d\u0026#34;) GH_OST_MIGRATED_HOST=$GH_OST_MIGRATED_HOST GH_OST_DATABASE_NAME=$GH_OST_DATABASE_NAME GH_OST_TABLE_NAME=$GH_OST_TABLE_NAME GH_OST_DDL=$GH_OST_DDL curl -X POST -H \u0026#39;Content-type: application/json\u0026#39; --data \u0026#39;{\u0026#34;blocks\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*\u0026lt;gh-ost.com|[Success] - gh-ost 已完成熱更新:tada:\u0026gt;*\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;,\u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;*Success_Time:* \u0026#39;\u0026#34;${show_time}\u0026#34;\u0026#39;\\n*Host:* \u0026#39;\u0026#34;${GH_OST_MIGRATED_HOST}\u0026#34;\u0026#39;\\n*Table:* `\u0026#39;\u0026#34;${GH_OST_DATABASE_NAME}\u0026#34;\u0026#39;`.`\u0026#39;\u0026#34;${GH_OST_TABLE_NAME}\u0026#34;\u0026#39;`\\n*DDL:* \u0026#39;\u0026#34;${GH_OST_DDL}\u0026#34;\u0026#39;\u0026#34;}},{\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;,\u0026#34;elements\u0026#34;: [{\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;,\u0026#34;text\u0026#34;: \u0026#34;:gh-ost: *gh-ost* | \u0026#39;\u0026#34;${show_day}\u0026#34;\u0026#39;\u0026#34;}]}]}\u0026#39; ${slack_hook} 方案比較與選擇 ","date":"2024-10-16T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/gh-ost/","title":"gh-ost"},{"content":"決定更新方式 MySQL Online DDL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 以下更新項目可直接使用 MySQL Online DDL 更新即可 MySQL 5.7： 1. drop \u0026amp; rename index 2. rename column \u0026amp; table 3. 調整默認值 4. varchar欄位加大 (0~255) or (256~) 5. 新增 \u0026amp; 刪除虛擬列 6. auto_increment = ? MySQL 8.0.29以下 快速加列條件與限制： 1. 不能和其他不支持 INSTANT 的 DDL 語句同時使用 2. 只能加在表中的最後一列 3. 加列不能在 ROW_FORMAT = COMPRESSED 使用 4. 加列不能在包含 FULLTEXT INDEX 的表中使用 5. 加列不能添加到 temporary table 中 6. Columns cannot be added to tables that reside in the data dictionary tablespace. 7. 只在 UPDATE、INSERT 時，才檢查 ROW 是否符合 TABLE 大小限制 MySQL 8.0.29開始： 1. 快速加列不再有位置限制 2. drop column 注意：當達 64 次操作 INSTANT 算法後，需要使用 COPY 算法或 gh-ost 等方案重置此計數，不過 MySQL 9.1 開始次數增加到 225 次。 可透過以下語法確認目前次數： SELECT NAME, TOTAL_ROW_VERSIONS FROM INFORMATION_SCHEMA.INNODB_TABLES WHERE NAME LIKE \u0026#39;dbname/tablename\u0026#39;; gh-ost 方案 事前設定 1 2 3 4 5 6 7 8 9 10 // Linux 安裝 gh-ost sudo rpm -ivh gh-ost.rpm // Linux 安裝 nc sudo yum install nc // vim my.cnf，持久化 binlog_format 設定 binlog_format = ROW binlog_rows_query_log_events = ON binlog_row_image = full 執行步驟 system variables 檢查\n1 2 3 4 5 6 // 檢查 system variables SHOW GLOBAL VARIABLES LIKE \u0026#39;binlog_format\u0026#39;; # ROW SHOW GLOBAL VARIABLES LIKE \u0026#39;binlog_row_image\u0026#39;; # full SHOW GLOBAL VARIABLES LIKE \u0026#39;sql_mode\u0026#39;; # \u0026#39;\u0026#39;，若不是嚴格模式，需添加-skip-strict-mode SHOW GLOBAL VARIABLES LIKE \u0026#39;log_bin\u0026#39;; # ON SHOW GLOBAL VARIABLES LIKE \u0026#39;log_slave_updates\u0026#39;; # ON 不要帶入 --execute 進行簡易測試\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 slave_host=\u0026#34;slave_host\u0026#34; database_name=\u0026#34;ghost_test\u0026#34; table_name=\u0026#34;event_1\u0026#34; ddl_query=\u0026#34;ADD COLUMN test varchar(20) AFTER remark, ADD COLUMN test2 varchar(20) AFTER test\u0026#34; gh_ost_user=\u0026#34;OdLd\u0026#34; # 參數詳細可參考：[https://www.notion.so/eb0d22b2eea64fb7bfed176a8efab6c1?v=b9f4fd843f69483cbbe74aa04c4a1372](gh-ost%20b1e6f809c8c54a009cde6b2b7f1ab00c/%E5%8F%83%E6%95%B8%20eb0d22b2eea64fb7bfed176a8efab6c1.md) gh-ost \\ --assume-rbr \\ --exact-rowcount \\ --concurrent-rowcount \\ `# global sql_mode 不是嚴格模式需添加` \\ --skip-strict-mode \\ --host=\u0026#34;${slave_host}\u0026#34; --port=3306 --user=\u0026#34;${gh_ost_user}\u0026#34; --ask-pass \\ --database=\u0026#34;${database_name}\u0026#34; --table=\u0026#34;${table_name}\u0026#34; \\ --alter=\u0026#34;${ddl_query}\u0026#34; \\ --timestamp-old-table \\ `# gh-ost 的 server_id, 設定為 1000000000 + linux pid` \\ --replica-server-id=$((1000000000+$$)) \\ `# 進入 throttle 的 loading 門檻` \\ --max-load=Threads_running=200 \\ `# 需要監控replication lag 的slave，當gh-ost偵測不到時使用，格式：myhost1.com:3307,myhost2.com:3308` \\ `#--throttle-control-replicas=myhost1.com:3307,myhost2.com:3308` \\ --max-lag-millis=1000 \\ `# 當存在該文件時，進入throttle` \\ --throttle-flag-file=/tmp/gh-ost_${database_name}_${table_name}_throttle.flag \\ --throttle-additional-flag-file=/tmp/gh-ost_all_throttle.flag \\ `# --throttle-query string` \\ `# critical load 設定，格式:some_status=\u0026lt;numeric-threshold\u0026gt;[,some_status=\u0026lt;numeric-threshold\u0026gt;...]` \\ --critical-load=Threads_running=250 \\ --critical-load-hibernate-seconds 60 \\ `# 每次處理的行數，可以視loading調整，預設1000` \\ --chunk-size=1000 \\ `# 範圍 0.0~100.0，每複製完一個chunk的資料後， gh-ost 將休眠 複製消耗的時間 * nice-ratio` \\ `# 假設每複製一個chunk的資料需要 100ms，當 nice-ratio=0.5 時， gh-ost 將休眠 100*0.5=50ms` \\ --nice-ratio=0 \\ `# gh-ost 批次應用 binlog 事件的數量，通常不需要調整` \\ --dml-batch-size=10 \\ `# 該文件存在時，gh-ost會直接中斷，並且不處理已複製的資料` \\ --panic-flag-file=/tmp/gh-ost_${database_name}_${table_name}_panic.flag \\ --force-named-cut-over --force-named-panic \\ `#若想立刻切換新表，請取註解下方參數，但不建議` \\ --postpone-cut-over-flag-file=/tmp/gh-ost_${database_name}_${table_name}_postpone.flag \\ --verbose 若以上測試後沒有問題可以正式執行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 slave_host=\u0026#34;slave_host\u0026#34; database_name=\u0026#34;ghost_test\u0026#34; table_name=\u0026#34;event_1\u0026#34; ddl_query=\u0026#34;ADD COLUMN test varchar(20) AFTER remark, ADD COLUMN test2 varchar(20) AFTER test\u0026#34; gh_ost_user=\u0026#34;OdLd\u0026#34; gh-ost \\ --assume-rbr \\ --exact-rowcount \\ --concurrent-rowcount \\ `# global sql_mode 不是嚴格模式需添加` \\ --skip-strict-mode \\ --host=\u0026#34;${slave_host}\u0026#34; --port=3306 --user=\u0026#34;${gh_ost_user}\u0026#34; --ask-pass \\ --database=\u0026#34;${database_name}\u0026#34; --table=\u0026#34;${table_name}\u0026#34; \\ --alter=\u0026#34;${ddl_query}\u0026#34; \\ --timestamp-old-table \\ `# gh-ost 的 server_id, 設定為 1000000000 + linux pid` \\ --replica-server-id=$((1000000000+$$)) \\ `# 進入 throttle 的 loading 門檻` \\ --max-load=Threads_running=200 \\ `# 需要監控replication lag 的slave，當gh-ost偵測不到時使用，格式：myhost1.com:3307,myhost2.com:3308` \\ `#--throttle-control-replicas=myhost1.com:3307,myhost2.com:3308` \\ --max-lag-millis=1000 \\ `# 當存在該文件時，進入throttle` \\ --throttle-flag-file=/tmp/gh-ost_${database_name}_${table_name}_throttle.flag \\ --throttle-additional-flag-file=/tmp/gh-ost_all_throttle.flag \\ `# --throttle-query string` \\ `# critical load 設定，格式:some_status=\u0026lt;numeric-threshold\u0026gt;[,some_status=\u0026lt;numeric-threshold\u0026gt;...]` \\ --critical-load=Threads_running=250 \\ --critical-load-hibernate-seconds 60 \\ `# 每次處理的行數，可以視loading調整，預設1000` \\ --chunk-size=1000 \\ `# 範圍 0.0~100.0，每複製完一個chunk的資料後， gh-ost 將休眠 複製消耗的時間 * nice-ratio` \\ `# 假設每複製一個chunk的資料需要 100ms，當 nice-ratio=0.5 時， gh-ost 將休眠 100*0.5=50ms` \\ --nice-ratio=0 \\ `# gh-ost 批次應用 binlog 事件的數量，通常不需要調整` \\ --dml-batch-size=10 \\ `# 該文件存在時，gh-ost會直接中斷，並且不處理已複製的資料` \\ --panic-flag-file=/tmp/gh-ost_${database_name}_${table_name}_panic.flag \\ --force-named-cut-over --force-named-panic \\ --verbose \\ `#若想立刻切換新表，請取註解下方參數，但不建議` \\ --postpone-cut-over-flag-file=/tmp/gh-ost_${database_name}_${table_name}_postpone.flag \\ --hooks-path=/var/lib/DBA/gh-ost/gh-ost_hooks \\ --execute 2\u0026gt;\u0026amp;1 | tee /tmp/gh-ost_${database_name}_${table_name}.log 若在非正式環境，可以在切換前直接比較新舊表的部分資料；若在正式環境，可以在切換前到 備份機 stop slave 後，徹底比較新舊表的資料更安心\n確定要切換表之後，開啟另外一個視窗，刪除 postpone-cut-over-flag-file 指定的檔案\n1 2 3 4 5 6 7 8 9 10 11 #Copy: 0/0 100.0%; Applied: 0; Backlog: 0/1000; Time: 1s(total), 0s(copy); #streamer: bin.000002:104008387; Lag: 0.01s, State: postponing cut-over; ETA: due #如上例當進度中出現State: postponing cut-over表示原表皆已遷移完成，此時進度也會是100% #可以將新舊表交換了，此時可以透過以下兩種方式繼續下一步切表動作 # 第一種方式 ls -l /tmp rm -f /tmp/gh-ost_databasename_tablename_postpone.flag # 第二種方式 echo unpostpone=\u0026#39;tablename\u0026#39; | nc -U /tmp/gh-ost.dbname.tablename.sock 於 loading 較低的時段執行刪除舊表的動作\n1 DROP TABLE ... 特殊情況 _gho(或_ghc) already exists 或 sock: bind:address already in use 當發生錯誤： _gho(或_ghc) already exists 或 sock: bind:address already in use，有可能是 上一次遷移失敗 或者 已經有gh-ost在遷移該張表，如果是 上一次遷移失敗 請刪除 table OR socket 即可正常運作。\n1 2 3 4 5 6 7 8 # table 已存在 FATAL Table `_tablename_gho` already exists. Panicking. Use --initially-drop-ghost-table to force dropping it, though I really prefer that you drop it or rename it away # socket 已存在 FATAL listen unix /tmp/gh-ost.databasename.tablename.sock: bind: address already in use 如果沒有Slave，如何使用 gh-ost 呢? 1 2 3 4 5 # host 的部分填入 master，並加上 allow-on-master 的參數 slave_host=\u0026#34;master_host\u0026#34; gh-ost \\ --allow-on-master \\ [error] binlogstreamer.go:77 close sync with err: sync is been closing\u0026hellip; 成功執行完畢後出現以下錯誤，若DDL有正常執行可以忽略\n1 2 3 # gh-ost 重複關閉複製通道 [error] binlogstreamer.go:77 close sync with err: sync is been closing... # 可參考 [https://github.com/github/gh-ost/issues/597](https://github.com/github/gh-ost/issues/597) ERROR Error 1146: Table \u0026lsquo;account_proxy._sms_validate_code_ghc\u0026rsquo; doesn\u0026rsquo;t exist 成功執行完畢後出現以下錯誤，若DDL有正常執行可以忽略\n1 2 3 # gh-ost 刪除 ghc table後，binlog應用跟到此語法且被 gh-ost 捕捉到 ERROR Error 1146: Table \u0026#39;account_proxy._sms_validate_code_ghc\u0026#39; doesn\u0026#39;t exist # 可參考 [https://github.com/github/gh-ost/issues/657](https://github.com/github/gh-ost/issues/657) gh-ost 執行過程出現 ERROR 1364 當執行 gh-ost 途中出現 ERROR 1364 如下錯誤：\n1 2 3 4 5 6 7 8 Copy: 1/1 100.0%; Applied: 0; Backlog: 0/1000; Time: 22s(total), 1s(copy); streamer: binlog.000002:382415; Lag: 0.12s, State: postponing cut-over; ETA: due 2021-11-24 15:21:26 ERROR Error 1364: Field \u0026#39;test_2\u0026#39; doesn\u0026#39;t have a default value; query= replace /* gh-ost `test`.`_test_gho` */ into `test`.`_test_gho` (`id`, `test_1`) values (?, ?) ; args=[2 test2] 這個原因通常是發生在新增一個 NOT NULL 且沒有 DEFAULT 值的欄位的時候，因為 gh-ost 預設會如下在 session 加上嚴格模式：\n1 2 SET SESSION time_zone = \u0026#39;+00:00\u0026#39;, sql_mode = CONCAT(@@session.sql_mode, \u0026#39;,,NO_AUTO_VALUE_ON_ZERO,STRICT_ALL_TABLES\u0026#39;) 我們都知道當 sql_mode 在嚴格模式 (STRICT_ALL_TABLES) 之下時，對於 NOT NULL 沒有預設值的欄位如果在 insert into 和 replace into 沒有給值，就會導致噴錯 doesn't have a default value 而無法新增。\n接下來讓我們複習一下 gh-ost 是如何作資料遷移的：\n應用類型 原表操作 新表操作 Row Copy SELECT INSERT IGNORE INTO Binlog Apply INSERT REPLACE INTO 對於原表已經存在的資料 gh-ost 是採用 INSERT IGNORE INTO 來寫到 _gho 表，所以雖然一樣會發生 ERROR 1364，但是 IGNORE 操作只會 warnings 提示，而不會阻擋 INSERT，如下事例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 mysql\u0026gt; show create table test\\G *************************** 1. row *************************** Table: test Create Table: CREATE TABLE `test` ( `id` int NOT NULL AUTO_INCREMENT, `test` varchar(10) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci mysql\u0026gt; INSERT IGNORE INTO test(id) values(1); Query OK, 1 row affected, 1 warnings (0.00 sec) mysql\u0026gt; SHOW warnings\\G *************************** 1. row *************************** Level: Warning Code: 1364 Message: Field \u0026#39;test\u0026#39; doesn\u0026#39;t have a default value mysql\u0026gt; SELECT * FROM test; +----+--------+ | id | test_1 | +----+--------+ | 1 | | +----+--------+ 對於 gh-ost 執行期間 INSERT 進來的新資料是採用 REPLACE INTO 來寫到 _gho 表，會發生 ERROR 1364 並被阻擋 INSERT，如下事例：\n1 2 3 4 5 6 7 8 9 mysql\u0026gt; REPLACE INTO test(id) values(2); ERROR 1364 (HY000): Field \u0026#39;test_1\u0026#39; doesn\u0026#39;t have a default value mysql\u0026gt; SELECT * FROM test; +----+--------+ | id | test_1 | +----+--------+ | 1 | | +----+--------+ 解決方法有兩種：\nNOT NULL 欄位都加上默認的 defaults 屬性\n確保 GLOBAL sql_mode 在非嚴格模式時，可以在 gh-ost 添加 --skip-strict-mode 選項。 添加此選項後 gh-ost 的 session 連線就不會主動設定嚴格模式了，如下：\n1 2 SET SESSION time_zone = \u0026#39;+00:00\u0026#39;, sql_mode = CONCAT(@@session.sql_mode, \u0026#39;,,NO_AUTO_VALUE_ON_ZERO\u0026#39;) 手動暫時停止 gh-ost 帶來的 loading 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 暫停 gh-ost 寫入資料 echo throttle | nc -U /tmp/gh-ost.dbname.tablename.sock # 檢查目前狀況，可以發現 throttled, commanded by user $ echo status | nc -U /tmp/gh-ost.test.sample_data_0.sock # Migrating `test`.`sample_data_0`; Ghost table is `test`.`_sample_data_0_gst` # Migration started at Tue Jun 07 11:56:03 +0200 2016 # chunk-size: 250; max lag: 1500ms; max-load: map[Threads_connected:20] # Throttle additional flag file: /tmp/gh-ost.throttle # Serving on unix socket: /tmp/gh-ost.test.sample_data_0.sock # Serving on TCP port: 10001 Copy: 0/2915 0.0%; Applied: 0; Backlog: 0/100; Elapsed: 59s(copy), 59s(total); streamer: mysql-bin.000551:68067; ETA: throttled, commanded by user # gh-ost 繼續寫入資料 echo no-throttle | nc -U /tmp/gh-ost.dbname.tablename.sock 如何中斷 gh-ost 1 2 # 中斷 gh-ost echo panic=\u0026#39;tablename\u0026#39; | nc -U /tmp/gh-ost.dbname.tablename.sock 調整 gh-ost loading 相關的參數 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 查詢 echo \u0026#34;chunk-size=?\u0026#34; | nc -U /tmp/gh-ost.dbname.tablename.sock 1000 # 修改 echo \u0026#34;chunk-size=250\u0026#34; | nc -U /tmp/gh-ost.dbname.tablename.sock # Migrating `test`.`sample_data_0`; Ghost table is `test`.`_sample_data_0_gst` # Migration started at Tue Jun 07 11:56:03 +0200 2016 # chunk-size: 250; max lag: 1500ms; dml-batch-size: 10; max-load: map[Threads_connected:20] # Throttle additional flag file: /tmp/gh-ost.throttle # Serving on unix socket: /tmp/gh-ost.test.sample_data_0.sock # Serving on TCP port: 10001 # 再次查詢 echo \u0026#34;chunk-size=?\u0026#34; | nc -U /tmp/gh-ost.dbname.tablename.sock 250 如何調整 primary key 由於 gh-ost要求每次遷移新表和舊表必須共享一個 唯一且NOT NULL 的 KEY(只需要欄位相同，不需要同名)。因此如果當表中只有 primary key時，無法直接調整 primary key，而是需要先新增一個 unique key，再第二次遷移時才能調整 primark key。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 原表 CREATE TABLE tbl ( id bigint unsigned not null, data varchar(255), new_pk_column int not null, PRIMARY KEY(id) ) # gh-ost 第一次執行 # ddl_query=\u0026#34;ADD UNIQUE KEY temp_pk(new_pk_column)\u0026#34; CREATE TABLE tbl ( id bigint unsigned not null, data varchar(255), new_pk_column int not null, PRIMARY KEY(id), UNIQUE temp_pk(new_pk_column) ) # 原表和新表以 PRIMARY KEY(id) 作為 Shared key # gh-ost 第二次執行 # ddl_query=\u0026#34;DROP PRIMARY KEY, # DROP KEY temp_pk, # ADD PRIMARY KEY (new_pk_column)\u0026#34; CREATE TABLE tbl ( id bigint unsigned not null, data varchar(255), new_pk_column int not null, PRIMARY KEY(new_pk_column) ) # 原表 UNIQUE temp_pk(new_pk_column) 和新表 PRIMARY KEY(new_pk_column) # 作為 Shared key 如何解決 Unexpected database port 當對雲服務商的 rds 或者 docker， --port 指定為非 3306 時，會因為其內部確實是 3306 而導致未通過驗證，此時可以透過使用 --aliyun-rds 或 --gcp 來跳過驗證。\n參考：https://github.com/github/gh-ost/issues/631\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 對 rds 或 docker 指定 3306 以外的 port gh-ost \\ --port=3307 \\ --verbose # error 2020-10-16 16:27:09 FATAL Unexpected database port reported: 3306 # 加上 --aliyun-rds 跳過驗證 gh-ost \\ --port=3307 \\ --aliyun-rds --verbose # 正常運作 gh-ost 偷吃步 只跑一次 gh-ost 的偷吃步方法，因為 gh-ost 只有在一開始會驗證新舊表是否可以搬遷，所以可以等 gh-ost 建立完新表 gho 後，先暫停複製資料的過程，我們則可以進到 DB 手動 ALTER 新表 gho，此方法可以用來越過某些限制，但可能造成資料損毀，請明確知道自己在做什麼才能使用！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 透過建立此檔案，讓 gh-ost 建立完新表後就先暫停複製資料(注意：會暫停所有gh-ost) touch /tmp/gh-ost_all_throttle.flag # 備註：不使用 throttle-flag-file 是因為必須要 gh-ost 執行後，建立才會生效 # 執行 gh-ost gh-ost \\ --alter=\u0026#34;ADD COLUMN test VARCHAR(10) NOT NULL DEFAULT \u0026#39;\u0026#39;\u0026#34; \\ ... \\ --throttle-additional-flag-file=/tmp/gh-ost_all_throttle.flag \\ --execute # Copy: 0/1 0.0%; Applied: 0; Backlog: 0/1000; Time: 0s(total), 0s(copy); streamer: bin-log.000006:305893; Lag: 0.01s, State: migrating; ETA: N/A # Copy: 0/1 0.0%; Applied: 0; Backlog: 0/1000; Time: 1s(total), 1s(copy); streamer: bin-log.000006:311112; Lag: 0.01s, State: throttled, flag-file; ETA: N/A # ... # 進到 MySQL 調整新表 mysql \u0026gt; ALTER TABLE table_gho ADD INDEX test(`test`); # 刪除 flag rm -rf /tmp/gh-ost_all_throttle.flag # gh-ost 正常運行，新的表會同時多一個 test 欄位和 test index 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 執行 gh-ost，讓 throttle 門檻很低，一啟動就暫停 gh-ost \\ --alter=\u0026#34;ADD COLUMN test VARCHAR(10) NOT NULL DEFAULT \u0026#39;\u0026#39;\u0026#34; \\ ... \\ --max-load=Threads_running=0 \\ --execute # Copy: 0/1 0.0%; Applied: 0; Backlog: 0/1000; Time: 0s(total), 0s(copy); streamer: bin-log.000006:305893; Lag: 0.01s, State: migrating; ETA: N/A # Copy: 0/1 0.0%; Applied: 0; Backlog: 0/1000; Time: 1s(total), 1s(copy); streamer: bin-log.000006:311112; Lag: 0.01s, State: throttled, flag-file; ETA: N/A # ... # 進到 MySQL 調整新表 mysql \u0026gt; ALTER TABLE table_gho ADD INDEX test(`test`); # 調回門檻 echo \u0026#34;max-load=Threads_running=200\u0026#34; | nc -U /tmp/gh-ost.test.sample_data_0.sock # gh-ost 正常運行，新的表會同時多一個 test 欄位和 test index pt-osc 方案 執行 給予super權限\n1 2 SELECT host FROM mysql.user WHERE user = \u0026#39;OdLd\u0026#39;; GRANT PROCESS,SUPER ON *.* TO \u0026#39;OdLd\u0026#39;@\u0026#39;\u0026#39;; 基本測試\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 pt-online-schema-change \\ --host=master_host --port=3306 \\ u=OdLd,D=database_name,t=table_name \\ --ask-pass \\ `#如果新增的欄位為Not Null 則必須設定Default值,否則pt工具會失敗` \\ --alter \u0026#34;add column test varchar(50) not null default \u0026#39;\u0026#39; after remark\u0026#34; \\ --print \\ --statistics \\ `#slave延遲時間` \\ --max-lag=1500 \\ `#暫停多久後再繼續` \\ --check-interval=5 \\ `#達到 --max-load 會暫停程序` \\ --max-load Threads_running=200 \\ `#達到 --critical-load 會停止程序` \\ --critical-load Threads_running=400 \\ `#若不想立刻切換新表，請註解下方，但不建議` \\ --no-drop-trigger --no-swap-tables \\ `#執行前建議先用dry-run做基本的測試` \\ --charset=utf8 \\ --dry-run 正式執行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 pt-online-schema-change \\ --host=master_host --port=3306 \\ u=OdLd,D=database_name,t=table_name \\ --ask-pass \\ `#如果新增的欄位為Not Null 則必須設定Default值,否則pt工具會失敗` \\ --alter \u0026#34;add column test varchar(50) not null default \u0026#39;\u0026#39; after remark\u0026#34; \\ --print \\ --statistics \\ `#slave延遲時間` \\ --max-lag=1500 \\ `#暫停多久後再繼續` \\ --check-interval=5 \\ `#達到 --max-load 會暫停程序` \\ --max-load Threads_running=200 \\ `#達到 --critical-load 會停止程序` \\ --critical-load Threads_running=400 \\ `#若不想立刻切換新表，請註解下方，但不建議` \\ --no-drop-trigger --no-swap-tables \\ --charset=utf8 \\ --execute 如果要手動切換 table－\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 交換 RENAME TABLE origan_table TO origan_table_old,new_table TO origan_table; # 刪除 Trigger DROP TRIGGER IF EXISTS database_name.pt_osc_database_name_table_name_del; DROP TRIGGER IF EXISTS database_name.pt_osc_database_name_table_name_upd; DROP TRIGGER IF EXISTS database_name.pt_osc_database_name_table_name_ins; # 刪除舊表 DROP TABLE IF EXISTS origan_table_old; # 移除權限 REVOKE PROCESS,SUPER ON *.* FROM \u0026#39;OdLd\u0026#39;@\u0026#39;\u0026#39;; ","date":"2024-10-16T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-online-ddl-sop/","title":"Online DDL SOP"},{"content":"簡介 在 MergeTree 中會依照表上的 partition by 指定的分區鍵將 INSERT 的資料塞入到對應的分區中，不同分區的資料會分散在不同的實體目錄，在訪問數據時可以幫助 ClickHouse 盡可能少的掃描數據。\n大多數的情況下不需要分區鍵，即使需要通常也不需要比月份更精細的分區鍵，過於精細的分區反而會降低效率，例如：不建議將 id 設為分區鍵，而是應該透過 order by 設為稀疏索引。\n範例 建立一張包含分區設定的表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CREATE DATABASE test_db; CREATE TABLE test_db.test_table( id BIGINT NOT NULL, name String NOT NULL, date Datetime NOT NULL ) ENGINE = MergeTree PARTITION BY toYYYYMM(date) ORDER BY (id) SETTINGS index_granularity = 8192, index_granularity_bytes = 0; # 查看 test_table 的分區目錄 SELECT partition, name, active FROM system.parts WHERE table = \u0026#39;test_table\u0026#39; 0 rows in set. 因為表才建立還沒有塞入數據，因此看不到任何分區目錄：\n1 2 3 ➜ ~ ll /var/lib/clickhouse/data/test_db/test_table drwxr-x--- 2 clickhouse clickhouse 6 5月 13 10:53 detached -rw-r----- 1 clickhouse clickhouse 1 5月 13 10:53 format_version.txt 向表中插入新數據時，同一批次的新數據會被儲存在單獨的分區目錄：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 INSERT INTO test_db.test_table VALUES (1,\u0026#39;test1\u0026#39;,\u0026#39;2022-09-01 00:00:00\u0026#39;), (2,\u0026#39;test2\u0026#39;,\u0026#39;2022-10-01 00:00:00\u0026#39;), (3,\u0026#39;test3\u0026#39;,\u0026#39;2022-09-01 00:00:00\u0026#39;); # 查看 test_table 的分區目錄 SELECT partition, name, active FROM system.parts WHERE table = \u0026#39;test_table\u0026#39; ┌─partition─┬─name─────────┬─active─┐ │ 202209 │ 202209_1_1_0 │ 1 │ │ 202210 │ 202210_2_2_0 │ 1 │ └───────────┴──────────────┴────────┘ INSERT INTO test_db.test_table VALUES (4,\u0026#39;test4\u0026#39;,\u0026#39;2022-08-01 00:00:00\u0026#39;), (5,\u0026#39;test5\u0026#39;,\u0026#39;2022-09-01 00:00:00\u0026#39;), (6,\u0026#39;test6\u0026#39;,\u0026#39;2022-11-01 00:00:00\u0026#39;); # 查看 test_table 的分區目錄 ┌─partition─┬─name─────────┬─active─┐ │ 202208 │ 202208_3_3_0 │ 1 │ │ 202209 │ 202209_1_1_0 │ 1 │ │ 202209 │ 202209_4_4_0 │ 1 │ │ 202210 │ 202210_2_2_0 │ 1 │ │ 202211 │ 202211_5_5_0 │ 1 │ └───────────┴──────────────┴────────┘ 1 2 3 4 5 6 7 8 9 10 11 12 13 ➜ ~ ll /var/lib/clickhouse/data/test_db/test_table # 包含 id = 1、3 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202209_1_1_0 # 包含 id = 2 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202210_2_2_0 # 包含 id = 4 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202208_3_3_0 # 包含 id = 5 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202209_4_4_0 # 包含 id = 6 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202211_5_5_0 drwxr-x--- 2 clickhouse clickhouse 6 5月 13 10:53 detached -rw-r----- 1 clickhouse clickhouse 1 5月 13 10:53 format_version.txt 隨後經過約 10~15 分鐘後 (或者是使用 OPTIMIZE TABLE) 同一分區的資料會合併到一個新的分區目錄，並且舊的分區目錄其 active 會被設為 0 不再使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ➜ ~ ll /var/lib/clickhouse/data/test_db/test_table # 包含 id = 1、3 的資料，此目錄 active = 0 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202209_1_1_0 # 包含 id = 2 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202210_2_2_0 # 包含 id = 4 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202208_3_3_0 # 包含 id = 5 的資料，此目錄 active = 0 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202209_4_4_0 # 包含 id = 6 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202211_5_5_0 # 包含 id = 1、3、5 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202209_1_4_1 drwxr-x--- 2 clickhouse clickhouse 6 5月 13 10:53 detached -rw-r----- 1 clickhouse clickhouse 1 5月 13 10:53 format_version.txt ┌─partition─┬─name─────────┬─active─┐ │ 202208 │ 202208_3_3_0 │ 1 │ │ 202209 │ 202209_1_1_0 │ 0 │ │ 202209 │ 202209_1_4_1 │ 1 │ │ 202209 │ 202209_4_4_0 │ 0 │ │ 202210 │ 202210_2_2_0 │ 1 │ │ 202211 │ 202211_5_5_0 │ 1 │ └───────────┴──────────────┴────────┘ 隨後經過約 10 分鐘後，active = 0 的分區目錄會被刪除：\n1 2 3 4 5 6 7 8 9 10 11 ➜ ~ ll /var/lib/clickhouse/data/test_db/test_table # 包含 id = 1、3、5 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202209_1_4_1 # 包含 id = 2 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202210_2_2_0 # 包含 id = 4 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202208_3_3_0 # 包含 id = 6 的資料，此目錄 active = 1 drwxr-x--- 2 clickhouse clickhouse 4096 9月 20 14:47 202211_5_5_0 drwxr-x--- 2 clickhouse clickhouse 6 5月 13 10:53 detached -rw-r----- 1 clickhouse clickhouse 1 5月 13 10:53 format_version.txt 分區目錄的命名規則 PartitionID：分區ID，為依照分區鍵計算的結果。\nMinBlockNum、MaxBlockNum：\nBlockNum 是一個以表為單位的自增值，每當新建一個分區目錄時 BlockNum 就會增長。\n因此 Min、Max 的 BlockNum 就表示該分區目錄所包含的最小和最大 BlockNum。\n對於一個新建的分區目錄 Min、Max BlockNum 會是相等的：\n1 2 3 4 ➜ ~ ll /var/lib/clickhouse/data/test_db/test_table 20220920_1_1_0 20220921_2_2_0 20220920_3_3_0 分區合併時才會發生分區目錄的 Min、Max BlockNum 不相同：\n1 2 3 4 5 ➜ ~ ll /var/lib/clickhouse/data/test_db/test_table 20220920_1_3_1 20220921_2_2_0 # 原本的分區目錄 20220920_1_1_0、20220920_3_3_0 因為 PartitionID 相同，因此可以進行合併，合併之後 20220920 的 MinBlockNum = 1, MaxBlockNum = 3 Level：分區合併的次數，對於每一個 PartitionID 所屬的分區目錄其起始值為 0。\n分區目錄的合併過程 參考 Custom Partitioning Key | ClickHouse Docs\nClickHouse表引擎 1.MergeTree 建表方式与分区规则 | hnbian\nhttps://github.com/ClickHouse/clickhouse-presentations/blob/master/meetup32/朱凯.ppt\n","date":"2024-10-15T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-partition/","title":"ClickHouse Partition"},{"content":"儲存結構 partition dir 表內的實體檔會依照所屬的 partition 放到對應的 partition 目錄下。\nchecksums.txt 二進制格式的校驗文件，儲存了該目錄下其他文件的 size 大小及 Hash 值，用來快速校驗文件的完整性和正確性。\ncolumns.txt 紀錄 Table 的欄位資訊，為直接使用明文紀錄，如下：\n1 2 3 4 5 6 ➜ ~ cat columns.txt columns format version: 1 3 columns: `UserID` UInt32 `URL` String `EventTime` DateTime count.txt 以明文紀錄該 partition 下的資料總筆數，如下：\n1 2 3 ➜ ~ count.txt 1112526 primary.idx 二進制格式儲存 Sparse Primary Indexes 文件。\n[column].bin 二進制數據文件，儲存該欄位的所有數據，默認使用 LZ4 壓縮格式。\n由於 clickhouse 是 column-oriented 的資料庫，因此每個 column 都有一個獨立的 .bin 數據文件，各自紀錄屬於該 column 的所有數據。\n[column].mrk 二進制標記文件，紀錄 primary,idx 和 [column].bin 之間的映射關係。\n[column].mrk2 如果使用自適應大小索引顆粒 (adaptive index granularity) 則標記文件會以 .mrk2 命名，工作原理和 mrk 相同。\npartition.dat、minmax_[column].idx 如果使用了 PARTITION BY 分區鍵才會生成：\npartition.dat：二進制紀錄當前 partition 下 partition_expr 的值。 minmax_[column].idx：二進制紀錄當前 partition 下原始數據的最小和最大值。 例如：假設 table 上定義 PARTITION BY toYear(${column})，在該 table 上此 column 有以下 4 個值： 2022-01-01、2022-06-01、2022-12-20 和 2023-02-01，則在2022 年的 partition 目錄下\npartition.dat 會記錄 2022。 minmax_[column].idx 會記錄 2022-01-01、2022-12-20。 skp_idx_[column].idx、skp_idx_[column].mrk 如果在表上定義了 skipping index 才會生成：\nidx：二進制 skipping index 文件。 mrk：二進制標記文件，紀錄 skp_idx_[column].idx 和 [column].bin 之間的映射關係。 參考 ClickHouse表引擎 1.MergeTree 建表方式与分区规则 | hnbian\nClickhouse技术分享: 分区裁剪 | HuangZhaowei\u0026rsquo; Blog (saintbacchus.github.io)\n深入浅出Clickhouse: 索引结构设计 | HuangZhaowei\u0026rsquo; Blog (saintbacchus.github.io)\n","date":"2024-10-13T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-storage-file/","title":"ClickHouse 儲存結構"},{"content":"Sparse Primary Indexes 說明 傳統的 RDBMS 表中的每一行數據都有一個 primary key 並且儲存為 B+ Tree 的資料結構，這樣的設計下可以快速的找到特定 row 的資料，但相應的需要額外的 disk、memory 開銷。\nClickHouse 的 MergeTree 引擎用來優化處理大量數據，並且數據是被一批一批的寫入表中，在這種情況下 disk、memory 效率很重要，因此不是為每一行數據建立 primary key，而是要為一組數據 (稱為 granule) 建立一個 index entry (稱為 mark)，也就是說在 ClickHouse 中 primary index 是對應多筆資料而不是唯一的資料。\nsparse primery index 不像基於 B+ Tree 的索引可以直接定位到特定行，而是可以透過 binary search 的方式快速找到可能匹配查詢的 granule 並傳輸到 ClickHouse engine 來找到匹配的結果。\n這種 sparse primery index 的設計，讓 primary index 足夠小可以放到 memory 中，並且對於 OLAP 的範圍查詢能有效加快。\n事例 schema 1 2 3 4 5 6 7 8 9 10 CREATE TABLE hits_UserID_URL ( `UserID` UInt32, `URL` String, `EventTime` DateTime ) ENGINE = MergeTree PRIMARY KEY (UserID, URL) ORDER BY (UserID, URL, EventTime) SETTINGS index_granularity = 8192, index_granularity_bytes = 0; schema 說明：\nORDER BY 是排序鍵(sorting key)，決定 .bin 中的文件如何排序 PRIMARY KEY 為選填的設定，用來生成 primary.idx 的檔案，必須是 ORDER BY 的前綴，如果沒有設定會將 PRIMARY KEY 定義為排序鍵。 默認情況下 sorting key 和 primary key 相同，以 sorting key 為主，因此大多情況下不需要指定 primary key，通常只有 SummingMergeTree 和 AggregatingMergeTree 引擎時 顯式的設置 PRIMARY KEY 和 ORDER BY 不同是為了進一步優化，例如：針對 WHERE A GROUP BY A, B, C 的查詢下，可以建立一個表 PRIMARY KEY A ORDER BY A, B , C。 index_granularity 默認值為 8192，意思是每 8192 行資料為一組會有一個 primary index entry index_granularity_bytes：0 表示禁止 adaptive index granularity，如果開啟此設定當符合以下條件時會自動最一組 n 行資料創建一個 primary index entry。 n \u0026lt; 8192 (index_granularity)，但 n 行數據大小 \u0026lt;= index_granularity_bytes(預設值為 10 MB) n 達到 8192 (index_granularity) 插入的行會按照 PRIMARY KEY 按順序 (ascending 升序) 儲存在 disk 上，同時 ClickHouse 允許插入具有相同 PK 的多筆資料，當 PK 相同時則會依照排序鍵中的 EventTime 排序：\nClickHouse 將表中的資料劃分為多個 granule，granule 是 ClickHouse 進行數據處理的最小單位，也就是說 ClickHouse 不是讀取單獨行，而是總是讀取整個 granule 。此例中 index_granularity = 8192，因此每 8192 行為一個 granule：\n另外可以看到上圖中有橘色的字，這些表示該 column 在該 granule 中的最小值，不過最後一個 granule 中則是會最大值：\n第一個 index entry (下圖中的 mark 0) 儲存 granule 0 中的最小值 第二個 index entry (下圖中的 mark 1) 儲存 granule 1 中的最小值 以此類推…… 最後一個 index entry (下圖中的 mark 1082) 儲存 granule 1082 中的最大值 這些每個 column 在每個 granule 中的最小值(最後一個為最大值) 會被寫入到 primary.idx 檔案中：\n注意因為是將每個 column 在每個 granule 中的極值挑出來，所以上例中的 mark 0 的 UserID、URL 的值是來自同一個 granule 中的不同行。\n💡 primary.idx 此文件會被完全被 loading 到內存中，如果文件大於可用的內存空間，則 ClickHouse 將引發錯誤。\n查詢 1 2 3 4 5 6 7 8 9 10 SELECT URL, count(URL) AS Count FROM hits_UserID_URL WHERE UserID = 749927693 GROUP BY URL ORDER BY Count DESC LIMIT 10; 10 rows in set. Elapsed: 0.005 sec. Processed 8.19 thousand rows, 740.18 KB (1.53 million rows/s., 138.59 MB/s.) 上例查詢中我們需要找到 UserID = 749927693 的資料，首先我們透過 primary.idx 找到 UserID = 749927693 的值介於 index mark 176 的 747148242 之後 mark 177 的 751802947 之前，因此只需要取出 mark 176 對應的 granule：\n接著需要 mark 176 中對應的 granule 中的 8192 行資料讀取到 ClickHouse，因此需要知道 granule 176 物理位置，每個 granule 的物理位置被儲存在 欄位.mrk 的文件中：\n如上圖所示 欄位.mrk 文件中會記錄每個 granule 所在的物理位置，也就是在 欄位.bin 數據文件中的位置，其中有 2 個內容：\nblock_offset：記錄了所選 granule 壓縮版本所在的壓縮數據塊。\n每個壓縮塊可能包含多個 granule (壓縮過的)，該壓縮數據塊在讀取時被解壓縮到內存中。\ngranule_offset：記錄了 granule 在解壓縮後數據塊的位置。\n上圖顯示了 ClickHouse 透過 UserID.mrk 定位到 UserID.bin 數據文件中包含符合查詢條件 granule 的過程，同時 ClickHouse 也會對 URL 欄位執行相同的動作，隨後這 2 個不同的 granule 會被對齊倍加載到 ClickHouse 引擎進行進一步處理，也就是 Aggrigation 操作。\n非最左前綴欄位的查詢 上面我們看到是用複合主鍵的第一個欄位 UserID 進行過濾，但是就像 MySQL 索引有最左前綴原則一樣，PK(UserID, URL) 可以明顯加快以 UserID 為條件的過濾，但是單純以 URL 為條件的查詢卻並沒有什麼幫助，因為我們是先 UserID 排序再以 URL 排序，也就是說雖然 UserID 是所有 granule 以小排到大，但是 URL 卻只有在其 granule 內中排序。\n1 2 3 4 5 6 7 8 9 10 SELECT UserID, count(UserID) AS Count FROM hits_UserID_URL WHERE URL = \u0026#39;http://public_search\u0026#39; GROUP BY UserID ORDER BY Count DESC LIMIT 10; 10 rows in set. Elapsed: 0.086 sec. Processed 8.81 million rows, 799.69 MB (102.11 million rows/s., 9.27 GB/s.) 1 2 3 4 5 6 7 8 -- trace log ...Executor): Key condition: (column 1 in [\u0026#39;http://public_search\u0026#39;, \u0026#39;http://public_search\u0026#39;]) ...Executor): Used generic exclusion search over index for part all_1_9_2 with 1537 steps ...Executor): Selected 1/1 parts by partition key, 1 parts by primary key, 1076/1083 marks by primary key, 1076 marks to read from 5 ranges ...Executor): Reading approx. 8814592 rows with 10 streams 如上所示可以看到該查詢執行時 1083 個 granule 其中有 1076 個 granule 被選中\nGeneric exclusion search algorithm 當查詢複合主鍵的一部分的 column (但不是第一個 column)，ClickHouse 會使用 Generic exclusion search 演算法而不是用 binary search 演算法，但是此算法僅在前綴索引 cardinality 較低時才較有效果，讓我們來看看不同 cardiality 的前綴索引的情境：\n前綴主鍵低 cardinality\n假設 UserID 的 cardinality 較低時，相同的 UserID 值可能分布在多個 granule 中，相應的 primary.idx 內多個 index mark 會有多個相同的 UserID 值，這同時也意味著這些 index mark 中的 URL 也會按順序排序：\nmark 0 的 URL 最小值為 W1 小於目標 W3，接著 mark 1、2 的 UserID 都和 mark 0 一樣是 U1，且 mark 1 的 URL 最小值為 W2 小於目標 W3，因此可以直接排除 mark 0 的 granule。 mark 1 的 URL 值 W2 ≤ W3，且 mark 2 的 URL 值 W4 ≥ W3，因此選擇 mark 1 的 granule。 mark 2、3 的 UserId 也是 U1，且 URL 值 W4、W5 \u0026gt; W3，因此可以直接排除 mark 2、3 的 granule。 前綴主鍵高 cardinality\n假設 UserID 的 cardinality 較高時，相同的 UserID 值不太可能分布在多個 granule 中，這同時意味著 primary.idx 內的 URL 不會單純按順序排序：\nmark 0 的 URL 最小值為 W1 小於目標 W3，雖然 mark 1 的 UserID 和 mark 0 一樣，但是因為 mark 2 的 UserID 不一樣，因此無法保證 granule 1 只包含 U1 的數據，對應的也不能保證 mark 1 的 W2 是跟 U1 同一行的資料，也就是對無法排除 granule 0 的數據沒有包含 W3 的資料，因此必須選擇 mark 0 對應的 granule 0 。\n其中 granule 1、2、3 也因為以上的原因無法被排除，都需要被挑選並 loading 到 ClickHouse 中，因此過濾的效率非常差。\n使用多個 primary index 進行優化 如果我們想同時加快下述兩句語法：\n1 2 3 4 5 6 7 8 9 SELECT URL, count(URL) AS Count FROM hits_UserID_URL WHERE UserID = 749927693 GROUP BY URL ORDER BY Count DESC LIMIT 10; SELECT UserID, count(UserID) AS Count FROM hits_UserID_URL WHERE URL = \u0026#39;http://public_search\u0026#39; GROUP BY UserID ORDER BY Count DESC LIMIT 10; 分別針對 UserID、URL 進行過濾，就需要用多個 primary index 來進行優化，我們有以下三種方式：\n新建一個有不同主鍵的新表\n新增一個具有不同 PRIMARY KEY、ORDER BY 相同欄位的 table，之後需要自行同步兩張表的資料，並根據查詢條件自行選擇適合的 table，如下所示：\n如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 CREATE TABLE hits_URL_UserID( `UserID` UInt32, `URL` String, `EventTime` DateTime ) ENGINE = MergeTree PRIMARY KEY (URL, UserID) ORDER BY (URL, UserID, EventTime) SETTINGS index_granularity = 8192, index_granularity_bytes = 0; INSERT INTO hits_URL_UserID SELECT * from hits_UserID_URL; OPTIMIZE TABLE hits_URL_UserID FINAL; 創建一個 materialized view\n在原表上創建 materialized view，這個額外的表會被隱藏起來，數據會自動在表之間保持同步，也就是說仍只需在原表寫入資料，不需要像上一個方案自行寫入新的表，但查詢時需要自行選擇合適的表，並且不提供數據一致性保證，如下所示：\n如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 CREATE MATERIALIZED VIEW mv_hits_URL_UserID ENGINE = MergeTree() PRIMARY KEY (URL, UserID) ORDER BY (URL, UserID, EventTime) -- POPULATE 用來表示建立 view 後將原表的資料匯入 (若未添加則只會同步建立 view 之後插入的資料) POPULATE AS SELECT * FROM hits_UserID_URL; SELECT UserID, count(UserID) AS Count FROM mv_hits_URL_UserID WHERE URL = \u0026#39;http://public_search\u0026#39; GROUP BY UserID ORDER BY Count DESC LIMIT 10; 建立之後看到 view 的數據文件如下：\n對該表新增 projection\nprojection 是最透明的方案，因為除了會隱藏附加的表，ClickHouse 還會自動選擇最有效的表版本來查詢，並且還保證數據一致性：\n事例如下：\n1 2 3 4 5 6 7 8 9 10 11 -- 在原表上創建 projection ALTER TABLE hits_UserID_URL ADD PROJECTION prj_url_userid ( SELECT * ORDER BY (URL, UserID) ); -- materialize projection，立即將源表資料導入隱藏表 ALTER TABLE hits_UserID_URL MATERIALIZE PROJECTION prj_url_userid; 建立之後會看到在該 table 下多了一個目錄紀錄 prjection 的相應資訊：\n這 3 個方法都是會有效的數據複製到另一個表中，以便重新組織 table 的 primary index 和排序，區別在於對查詢和使用者的透明程度\nSkipping Indexes 在大多數情境中影響 ClickHouse 效能最關鍵的因素是 WHERE 子句的條件是否可以使用 primary index，但不管怎麼調優 primary index 還是不可避免的會出現不能有效使用的案例。\n在如 MySQL 等傳統數據庫，解決方案是添加對應的 secondary index，一個 B+Tree 結構讓時間複雜度由全表掃描的 O(n) 變成 O(logn) 的索引掃描。\n這種類型的 secondary index 不適合 ClickHouse (或其他 column-oriented 數據庫)，因為 disk 上數據的紀錄是以 granule 為單位，所以沒有單獨的行可以為其添加單獨的 index。 相應的 ClickHouse 提供了稱為 skipping index 來幫助跳過沒有匹配值的 granule。\nskipping index 有以下 4 個參數：\nindex name：index 名稱。 index expression：計算表達是 TYPE：skipping index 的類型。 GRANULARITY：每個 index block 包含了 N 個 granularity。例如： index_granularity 為 8192，GRANULARITY 為 4，則每個 indexed block 包含了 8192*4 = 32768 行資料。 當創建 Skipping index，該表的數據目錄中會產生以下 2 個檔案：\nskp*idx*{index_name}.idx：將 index expression 的 values 排序後記錄下來。 skp*idx*{index_name}.mrk2：將 index 關連到的 column 數據文件所在的偏移量。 Skipping index Type 每隔 index_granularity * GRANULARITY 是一個 block，skipping index 會依照每個 block 內 index expression 產生的結果來生成 index。\nSkipping index 的 Type 共分為以下 3 種：\nminmax：儲存每個 block 中 index expression 的 min/max 值。\nset(max_size)： 儲存每個 block 中 index expression 的不重複值。\n如果不重複值的數量 \u0026gt; max_size 時則為空，如果 max_size = 0 則表示不限制。\n此類型適合用於每個 block 中的 cardinality 低，但整個 column 的 cardinality 高的情境，該索引成本和性能取決於單個 block 的 cardinality。如果每個 block 包含大量唯一值則成本將相對高，或者是超過 max_size 而為空導致不使用此 index 。\nBloom Filter Types：是一種數據結構，以少量的偽陽性 ( false positive) 為代價能夠對 block 進行高效的 space-efficient 測試。\n原理細節\n這邊先附上一個可以線上演示的網站：Bloom Filters by Example (llimllib.github.io)\n一個空的 bloom filter 是一個 m bits 的 bit array。\n下圖是一個 14 bits 的 bloom filter，下面的數字表示索引，上面的白色區塊表示尚未有資料，也就是 false、0：\n當輸入一個數據時，會經過 k 個 hash function，產生 k 個結果並在對應的 index 上標上 true、1。\n下圖中 input 了 ee 這個值，經過 2 個 hash function：fnv、murmur，得出了 0、4 的結果，因此在 0、4 的 index 標上綠色，也就是 true、1：\n這時候當再輸入 eee 時，2 個 hash function 會得出 7、11 和原本的 0、4 沒有任何交集，因此可以判斷 eee 還不在這個結果集內：\n但如果這時候輸入 eeee 時，2 個 hash function 會得出 0、4 和原本的 0、4 一樣，因此我們會得出 eeee 可能有在結果集內，但是實際上卻沒有，這就是 bloom filter 的偽陽性：\n在 skipping index 的使用場景偽陽性 ( false positive) 不是什麼問題，因為唯一的缺點是多讀取了一些不必要的 granule，而且也總比跳過有效的 granule 好。\n因為 Bloom Filter 可以有效的處理大量離散值的測試，所以他們更適合用於可以產生多個測試值的 index expression，特別是透過 mapKeys 或 mapValues function 來產生 array、map 來進行多值的 space-efficient 測試。\n基於 Bloom Filter 的 skipping index 又細分為 3 種： 基本的bloom_filter\n支持的數據型態：Int*, UInt*, Float*, Enum, Date, DateTime, String, FixedString, Array, LowCardinality, Nullable。\n會使用到該索引的 Function：equals, notEquals, in, notin, has。\n有一個可選的參數 false_positive：該參數表示 0~1 之間允許的假陽性率，預設為 .025。\ntokenbf_v1：對字符串做 tokenization 後儲存，適合用於 LIKE、EQUALS、in、hasToke() 等等長字符串的搜索，接受 String、FixedString、Map 型態的數據。會將index expression 依照非字母數字的字符進行切割，例如：This is a full text search，會被分割為 This is a full text search 。\n需要以下 3 個參數：\nsize_of_bloom_filter_in_bytes：bloom filter 的大小，以 byte 為單位，使用的越大可以減少假陽性，但有更高的存儲成本。 number_of_hash_functions：使用的 hash function 的個數，使用的越多可以減少假陽性。 random_seed：hash function 的隨機種子 ngrambf_v1**：**和 tokenbf_v1 類似，但是是用 ngram 來切割而不是非字母數字的字符來切割，適合用於中文這類沒有用空格分隔的字符串。例如 n = 2，會將 這是測試 分割為 這是 是測 測試。\n比 tokenbf_v1 多一個參數，需要以下 4 個參數：\nn：ngram 的短語長度。 size_of_bloom_filter_in_bytes number_of_hash_functions random_seed Skipping index 支持的 function Where 子句中的條件可以包含對某個 column 進行運算的函數表達式，假如 column 是 index 的一部分，ClickHouse 會在執行 function 時嘗試使用 index。\nset type 的 skipping index 支持所有的 function，其他 index 支持的 function 如下表所列：\n如果 function 的常量參數小於 ngram 大小則不能使用 ngrambf_v1 進行查詢優化。\n💡 因為 bloom filter 有偽陽性的狀況，因此 bloom filter 的 skipping index 不能用於結果返回為 false 的 function，例如： 能優化的場景： s LIKE \u0026lsquo;%test%’ NOT s NOT LIKE \u0026lsquo;%test%’ s = 1 NOT s != 1 startsWith(s, ‘test’) 不能優化的場景： NOT s LIKE \u0026lsquo;%test%’ s NOT LIKE \u0026lsquo;%test%’ NOT s = 1 S != 1 NOT startsWith(s, ‘test’)\nSkipping index 的配置 use_skip_indexes ( 0 | 1 )：預設值為 1，對於不太可能從 Skipping index 獲益的查詢建議可以設置為 0 減少不必要的成本。 force_data_skipping_indexes (以逗號分隔 skipping index 的名稱)：強迫查詢使用指定的 skipping index，若指定後不會用到半個 skipping index 則會返回異常，避免糟糕的查詢耗費機器效能。 最佳實踐 假設有一張表的 primary index 是 timestamp，並且在 visitor_id 有一個 index，並有以查詢：\nSELECT timestamp, url FROM table WHERE visitor_id = 1001\n對於這種數據分布與相應的查詢，傳統 RDBMS 的 secondary index 非常有效，透過 secondary index 能夠直接讀取這 5 行數據。\n對於 ClickHouse 的 Skipping index 情況卻不同，無法是哪一種 Type 的 Skipping index 都需要從 8192*4=32678 的值都需要測試。\n可以看到在以上例子中 Skipping index 並沒有有效的效果，要有效的使用 Skipping index 有以下情境：\n每個 granule 多數的資料符合條件，也就是需要在該 granule 有低 cardinality。 範例：如果 primary key 是一天中的時間，另外有一個 column 是電視觀眾年齡，很明顯兩者是有相關性的，此時 minmax type 的 Skipping index 可能就很有效，因為只有少數的 granule 會被選中。 在插入數據時可以增加這種相關性，方法如下： 在排序鍵 (order by) 中添加此列 Insert 時先將 Primary key 與該列分組後在批次插入 盡可能減少 granule 被選到，也就是需要在整個 table 有高 cardinality。 範例：一個 API 中很少見的 error code，但卻特別重要需要經常搜尋，此時 set(max_size) type 的 Skipping index 就很有效，因為大多 granule 會被跳過。 因此意圖透過簡單添加 Skipping index 來加速查詢的效能是不正確的，建議先研究其他方法，例如：修改 primary index、使用 projections、使用 materialized views，研究這些方法之後才考慮 Skipping index，而且和 secondary index 不同，Skipping index 的行為是不容易預測，因為和數據的真實分布情況息息相關，並且將他們添加到表中對於無法使用索引的查詢會產生很大的成本，因此建議在真實數據上進行測試。\n參考 ClickHouse主键索引最佳实践 | ClickHouse Docs\nClickHouse Index Design | ClickHouse Docs\n【ClickHouse 极简教程-图文详解原理系列】ClickHouse 主键索引的存储结构与查询性能优化 - 简书 (jianshu.com)\nhttps://github.com/ClickHouse/ClickHouse/issues/5125\n","date":"2024-10-12T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-index/","title":"ClickHouse 索引"},{"content":"MergeTree 表引擎\nSparse Primary Index Partition Data Replication Data Sampling Replacing MergeTree 特色：在 merge 時會刪除具有相同 sorting key 的資料。\n注意事項：\n重複的判斷是依照 ORDER BY 而不是 Primary key 因為只有在 merge 時會觸發，因此不保證任何時刻都沒有重複資料。 因為只有在 merge 時會觸發，因此不同 partition 的資料不會去重。 缺點：\n想要得到正確的結果只能透過 FINAL 修飾符，或者手動執行 OPTIMIZE 來讓 TABLE 觸發 Merge，不論哪一種都是昂貴的操作。 以下為建立一個 ReplacingMergeTree 的語法：\n1 2 3 4 5 6 7 8 9 10 11 CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2], ... ) ENGINE = ReplacingMergeTree([ver]) [PARTITION BY expr] [ORDER BY expr] [PRIMARY KEY expr] [SAMPLE BY expr] [SETTINGS name=value, ...] 相關參數：\nver - 帶有版本號的欄位，允許 UInt*、Date、DateTime、DateTime64 的欄位，可選參數。 若未指定 ver 在 merge 時，同樣 sorting key 的資料會保留最後插入的一筆。\n當指定 ver 在 merge 時，同樣 sorting key 的資料會保留 ver 指定的欄位最高的一筆，如果相同則同樣是保留最後插入的一筆。\n範例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 -- without ver - the last inserted \u0026#39;wins\u0026#39; CREATE TABLE replacing_test ( `key` Int64, `someCol` String, `eventTime` DateTime ) ENGINE = ReplacingMergeTree ORDER BY key; INSERT INTO replacing_test Values (1, \u0026#39;first\u0026#39;, \u0026#39;2020-01-01 01:01:01\u0026#39;); INSERT INTO replacing_test Values (1, \u0026#39;second\u0026#39;, \u0026#39;2020-01-01 00:00:00\u0026#39;); SELECT * FROM replacing_testFINAL; ┌─key─┬─someCol─┬───────────eventTime─┐ │ 1 │ second │ 2020-01-01 00:00:00 │ └─────┴─────────┴─────────────────────┘ -- with ver - the row with the biggest ver \u0026#39;wins\u0026#39; DROP TABLE replacing_test; CREATE TABLE replacing_test ( `key` Int64, `someCol` String, `eventTime` DateTime ) ENGINE = ReplacingMergeTree(eventTime) ORDER BY key; INSERT INTO replacing_test Values (1, \u0026#39;first\u0026#39;, \u0026#39;2020-01-01 01:01:01\u0026#39;); INSERT INTO replacing_test Values (1, \u0026#39;second\u0026#39;, \u0026#39;2020-01-01 00:00:00\u0026#39;); # 還沒觸發 merge，因此沒有發生刪除 SELECT * FROM replacing_test; ┌─key─┬─someCol─┬───────────eventTime─┐ │ 1 │ second │ 2020-01-01 00:00:00 │ │ 1 │ first │ 2020-01-01 01:01:01 │ └─────┴─────────┴─────────────────────┘ # 使用 FINAL 修飾符直接查到最後結果 SELECT * FROM replacing_test FINAL; ┌─key─┬─someCol─┬───────────eventTime─┐ │ 1 │ first │ 2020-01-01 01:01:01 │ └─────┴─────────┴─────────────────────┘ # 使用 optimize table 觸發合併後查詢 OPTIMIZE TABLE replacing_test; SELECT * FROM replacing_test; ┌─key─┬─someCol─┬───────────eventTime─┐ │ 1 │ first │ 2020-01-01 01:01:01 │ └─────┴─────────┴─────────────────────┘ Summing MergeTree 特色：在 merge 時有相同 sorting key 的資料會進行合併，並依設定將指定或全部的數值欄位進行相加，非彙總的欄位則只會保留最早插入的數據。\n注意事項：\n判斷是依照 ORDER BY 而不是 Primary key 因為只有在 merge 時會觸發，因此不保證任何時刻資料都已彙整完畢，因此建議查詢時仍舊顯示指定 SUM()、GROUP BY。 因為只有在 merge 時觸發，因此不同 partition 的資料不會合併。 以下為建立一個 SummingMergeTree 的語法：\n1 2 3 4 5 6 7 8 9 10 CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2], ... ) ENGINE = SummingMergeTree([columns]) [PARTITION BY expr] [ORDER BY expr] [SAMPLE BY expr] [SETTINGS name=value, ...] 相關參數：\ncolumns - 指定要彙總的欄位名稱，所選的欄位必須為數值型態，並且不可在 ORDER BY 中。為可選的參數，如果未指定則會加總所有的非 ORDER BY 的數值型態欄位。 非彙總的欄位只會保留最早插入的數據。 範例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 CREATE TABLE summtt ( key UInt32, value UInt32 ) ENGINE = SummingMergeTree() ORDER BY key INSERT INTO summtt Values(1,1),(1,2),(2,1) SELECT key, value FROM summtt ┌─key─┬─sum(value)─┐ │ 2 │ 1 │ │ 1 │ 3 │ └─────┴────────────┘ # 避免有還未 merge 的資料，因此應該總是使用 sum、group by 進行查詢 SELECT key, sum(value) FROM summtt GROUP BY key ┌─key─┬─sum(value)─┐ │ 2 │ 1 │ │ 1 │ 3 │ └─────┴────────────┘ Aggregating MergeTree 特色：在 merge 時有相同 sorting key 的資料會進行合併，並按照預先定義的條件聚合資料。\n注意事項：\n判斷是依照 ORDER BY 而不是 Primary key 因為只有在 merge 時會觸發，因此不保證任何時刻資料都已彙整完畢，因此建議查詢時仍舊顯示指定 SUM()、GROUP BY。 因為只有在 merge 時觸發，因此不同 partition 的資料不會合併。 以下為建立一個 AggregatingMergeTree 的語法：\n1 2 3 4 5 6 7 8 9 10 11 CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2], ... ) ENGINE = AggregatingMergeTree() [PARTITION BY expr] [ORDER BY expr] [SAMPLE BY expr] [TTL expr] [SETTINGS name=value, ...] 範例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 -- 建表 CREATE TABLE db_merge.t_merge_agg ( `id` String, `city` String, `code` AggregateFunction(uniq,String), -- 聚合字段 等同於 UNIQ(code) `value` AggregateFunction(sum,UInt32), -- 聚合字段 等同於 SUM(value) `create_time` DateTime ) ENGINE = AggregatingMergeTree() partition by toYYYYMM(create_time) ORDER BY (id,city) -- 可以視為 group by id,city primary key id; -- 插入数据 -- 需要使用 UNIQ() 對應的 uniqState 方法 和 sum 對應的 sumState 方法，並使用 INSERT INTO SELECT 來插入 insert into table db_merge.t_merge_agg select \u0026#39;A01\u0026#39;,\u0026#39;shenzhen\u0026#39;,uniqState(\u0026#39;code1\u0026#39;),sumState(toUInt32(100)),\u0026#39;2021-06-04 15:27:22\u0026#39; union all select \u0026#39;A01\u0026#39;,\u0026#39;shenzhen\u0026#39;,uniqState(\u0026#39;code2\u0026#39;),sumState(toUInt32(200)),\u0026#39;2021-06-04 15:28:22\u0026#39;; -- 查询数据 -- 需要调用 UNIQ对应的 uniqMrege 方法 和 sum 对应的 sumMerge 方法 select id,city,uniqMerge(code),sumMerge(value) from db_merge.t_merge_agg group by id,city; ┌─id──┬─city─────┬─uniqMerge(code)─┬─sumMerge(value)─┐ │ A01 │ shenzhen │ 2 │ 300 │ └─────┴──────────┴─────────────────┴─────────────────┘ Collapsing MergeTree 包含 collapsing(摺疊) 邏輯的 MergeTree，這在 merge 時會將 sorting key 相同的資料依照摺疊算法將數據折疊，以此減少資料量提升後續的查詢效率。\n以下為建立一個 CollapsingMergeTree\n1 2 3 4 5 6 7 8 9 10 CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2], ... ) ENGINE = CollapsingMergeTree(sign) [PARTITION BY expr] [ORDER BY expr] [SAMPLE BY expr] [SETTINGS name=value, ...] 相關參數：\nsign - 型態為 Int8，用來表示該 row 的狀態： 1：表示該 row ，稱其為 state row。 -1：表示該 row ，稱其為 cancel row。 摺疊算法 當 CH 合併數據時，會將具有相同 sorting key 的行減少到不超過 2 行，一個 state 一個 cancle，具體如何保留如下：\n如果 state = cancel 且最後一行是 state，則保留第一筆 cancel 和最後一筆 state 行。 如果 state \u0026gt; cancel ，則只保留最後一個 state 行。 如果 state \u0026lt; cancel ，則只保留第一個 cancel 行。 其他情況，則不保留任何行。 範例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # 建立一個 CollapsingMergeTree table CREATE TABLE test_db.UAct ( UserID UInt64, PageViews UInt8, Duration UInt8, Sign Int8 ) ENGINE = CollapsingMergeTree(Sign) ORDER BY UserID # 塞入數據 INSERT INTO test_db.UAct VALUES (4324182021466249494, 5, 146, 1); INSERT INTO test_db.UAct VALUES (4324182021466249494, 5, 146, -1),(4324182021466249494, 6, 185, 1); # 查詢，因為還沒觸發 merge SELECT * FROM test_db.UAct ┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┐ │ 4324182021466249494 │ 5 │ 146 │ -1 │ │ 4324182021466249494 │ 6 │ 185 │ 1 │ │ 4324182021466249494 │ 5 │ 146 │ 1 │ └─────────────────────┴───────────┴──────────┴──────┘ # 建議使用以下查詢來確保查出來的數據經過摺疊 SELECT UserID, sum(PageViews * Sign) AS PageViews, sum(Duration * Sign) AS Duration FROM test_db.UAct GROUP BY UserID HAVING sum(Sign) \u0026gt; 0 ┌──────────────UserID─┬─PageViews─┬─Duration─┐ │ 4324182021466249494 │ 6 │ 185 │ └─────────────────────┴───────────┴──────────┘ # 使用 Final 修飾符，查看 merge 後的結果 # 注意：不建議使用，非常消耗性能 SELECT * FROM test_db.UAct FINAL ┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┐ │ 4324182021466249494 │ 6 │ 185 │ 1 │ └─────────────────────┴───────────┴──────────┴──────┘ # 強迫 merge 後查詢 optimize table test_db.UAct; SELECT * FROM test_db.UAct ┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┐ │ 4324182021466249494 │ 6 │ 185 │ 1 │ └─────────────────────┴───────────┴──────────┴──────┘ 注意事項 同樣只有相同分區的資料才會在 merge 時摺疊\nCollapsing MergeTree 嚴格要求數據按照先寫入 sign = 1 再寫入 sign = -1 的順序，否則數據無法摺疊：\n1 2 3 4 5 6 7 8 9 10 INSERT INTO test_db.UAct VALUES (4324182021466249494, 5, 146, -1); INSERT INTO test_db.UAct VALUES (4324182021466249494, 5, 146, 1); optimize table test_db.UAct; SELECT * FROM test_db.UAct ┌──────────────UserID─┬─PageViews─┬─Duration─┬─Sign─┐ │ 4324182021466249494 │ 5 │ 146 │ -1 │ │ 4324182021466249494 │ 5 │ 146 │ 1 │ └─────────────────────┴───────────┴──────────┴──────┘ 如果數據是多線程寫入則不太容易控制順序，因此 Collapsing MergeTree 的摺疊機致無法順利運作，此時可以使用 CH 提供的 Versioned Collapsing MergeTree 來解決。\nVersioned Collapsing MergeTree 用途和 Collapsing MergeTree 相同，但使用不同的折疊算法，透過自定義的版本號來摺疊，因此不像 Collapsing MergeTree 受插入順序的影響。\n以下為建立一個 Versioned Collapsing MergeTree 的語法：\n1 2 3 4 5 6 7 8 9 10 CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2], ... ) ENGINE = VersionedCollapsingMergeTree(sign, version) [PARTITION BY expr] [ORDER BY expr] [SAMPLE BY expr] [SETTINGS name=value, ...] 相關參數：\nsign - 型態為 Int8，用來表示該 row 的狀態： 1：表示該 row ，稱其為 state row。 -1：表示該 row ，稱其為 cancel row。 version - 型態為 UInt* ，用來指定為版本號的欄位。 範例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 CREATE TABLE versioned_collapsing_test ( `key` Int64, `someCol` String, `sign` Int8, `version` UInt8 ) ENGINE = VersionedCollapsingMergeTree(sign,version) ORDER BY key; INSERT INTO versioned_collapsing_test VALUES (1, \u0026#39;first\u0026#39;, 1, 1); INSERT INTO versioned_collapsing_test VALUES (1, \u0026#39;second\u0026#39;, 1, 2); INSERT INTO versioned_collapsing_test VALUES (1, \u0026#39;first\u0026#39;, -1, 1); SELECT * FROM versioned_collapsing_test; ┌─key─┬─someCol─┬─sign─┬─version─┐ │ 1 │ first │ 1 │ 1 │ │ 1 │ second │ 1 │ 2 │ │ 1 │ first │ -1 │ 1 │ └─────┴─────────┴──────┴─────────┘ # 建議使用以下查詢來確保查出來的數據經過摺疊 SELECT key, sum(someCol * Sign) AS someCol FROM versioned_collapsing_test GROUP BY key HAVING sum(Sign) \u0026gt; 0 ┌─key─┬─someCol─┐ │ 1 │ second │ └─────┴─────────┘ # 使用 Final 修飾符，查看 merge 後的結果 # 注意：不建議使用，非常消耗性能 SELECT * FROM versioned_collapsing_test FINAL ┌─key─┬─someCol─┬─sign─┬─version─┐ │ 1 │ second │ 1 │ 2 │ └─────┴─────────┴──────┴─────────┘ # 強迫 merge 後查詢 optimize table versioned_collapsing_test; SELECT * FROM versioned_collapsing_test ┌─key─┬─someCol─┬─sign─┬─version─┐ │ 1 │ second │ 1 │ 2 │ └─────┴─────────┴──────┴─────────┘ 注意事項\nClickhouse 合併數據時會刪除每一對具有相同 primary key、version 以及不同 sign 的數據。 Clickhouse 會隱式的將 version 欄位添加到 primary key。 Graphite MergeTree 用於 aggregating/averaging (rollup) Graphite 數據而設計。\n參考 MergeTree Engine Family | ClickHouse Docs\nClickHouse 中最重要的表引擎：MergeTree 的深度原理解析 - 古明地盆 - 博客园 (cnblogs.com)\nClickHouse表引擎 1.MergeTree 建表方式与分区规则 | hnbian\nClickHouse表引擎 2.MergeTree 索引与数据存储方式 | hnbian\nClickHouse表引擎 5.MergeTree 家族其它引擎 | hnbian\nMySQL到ClickHouse的高速公路-MaterializeMySQL引擎-云社区-华为云 (huaweicloud.com)\n","date":"2024-10-11T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-mergetree/","title":"ClickHouse MergeTree 引擎"},{"content":"ClickHouse 是一個用於 OLAP 的列式 (column-oriented) 資料庫。\nrow-oriented 與 column-oriented 資料庫的比較 以 MySQL、Postgress 這類傳統行式 (row-oriented) 資料庫會用以下方式儲存資料：\n在同一行中 (Row 編號相同) 的資料在物理上是儲存在一起的。\nClickHouse 這類列式 (column-oriented) 資料庫則是以如下的方式儲存資料：\n在不同列的值是分開儲存的，來自同一列 ( column 名稱相同) 的數據則是被儲存再一起\n常見的列式數據庫有： Vertica、 Paraccel (Actian Matrix，Amazon Redshift)、 Sybase IQ、 Exasol、 Infobright、 InfiniDB、 MonetDB (VectorWise， Actian Vector)、 LucidDB、 SAP HANA、 Google Dremel、 Google PowerDrill、 Druid、 kdb+。\nOLAP 場景特性 以讀請求為主 數據不太會一次只新增單個 row，通常都是大批次 (\u0026gt; 1000 row) 的寫入 新增到資料庫的數據不會再修改 每個 TABLE 包含大量的 column (寬表)，但查詢通常只取少數 column 查詢相對較少，通常單個 server 的 qps 僅數百次或更少 對於簡單的查詢，允許延遲大約 50 ms 列中的數據相對較小：數字和短字符串 處理個查詢時需要高吞吐量，單個 server 每秒可能須讀取數十億行資料 事務不是必需的 對數據一致性要求低 查詢結果經過過濾和聚合會明顯小於源數據，因此結果適合放在單個 server 的 RAM 中 column-oriented 資料庫更適合 OLAP 場景的原因 以下稍微演示 OLAP 查詢較為快速的原因：\nrow-oriented： column-oriented： 安裝\n索引\nPartition\nMaterialized MySQL (實驗性)\nProjection\n儲存結構\nMergeTree 表引擎\nTPC-H 測試\n","date":"2024-10-11T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/clickhouse-introduction/","title":"ClickHouse 簡介"},{"content":"MySQL 8.4 更新 從 MySQL 8.4 開始，UNIX 預設值改為 O_DIRECT if supported, otherwise fsync 所以未來不太需要調整此參數了\n原文 (MySQL 8.0) 設定 flush data 到 InnoDB data files 和 log files 使用的方法，此參數會影響到 IO 吞吐量\nfsync(or 0)：InnoDB use fsync() system call to flush data，這在 5.7、8.0 為默認設定。 O_DSYNC(or 1)：InnoDB use O_SYNC to open and flush the log files, and fsync() to flush the data file。 InnoDB不直接使用 O_DSYNC 因為在許多 Unix 版本上都存在問題。 littlesync(or 2)：此選項用於內部性能測試，目前版本不支持。使用後風險自負。(5.7、8.0) nosync(or 3)：此選項用於內部性能測試，目前版本不支持。使用後風險自負。(5.7、8.0) O_DIRECT(or 4)：InnoDB use O_DIRECT (or directio() on Solaris) to open the date files , and use fsync() to flush both the data and log files. 此選項在某些 GNU/Linux 版本、 FreeBSD 和 Solaris 上可以使用。 O_DIRECT_NO_FSYNC：InnoDB use O_DIRECT during flushing I/O, but skips the fsync() system call after each write operation. 在 5.7.25、8.0.14 之前，此設定不適用於 XFS、 EXT4 等 file system，因這類 file sysetm需要調用 fsync() 來同步 file system metadata的變更，如果不確定是否需要請調整為 O_DIRECT。 在 5.7.25、8.0.14 開始，在建立新的文件、增加文件大小、關閉文件後這些變更到 file system metadata 的情況才會調用 fsync()，其餘情寫入操作會跳過 fsync()。 如果 data files 和 log files 儲存在不同的設備，且 data files 的儲存設備沒有後備電池，則可能導致數據丟失建議改為使用 O_DIRECT。 在 MySQL 8.0.14 開始，若 innodb_dedicated_server 啟用時，則會將 innodb_flush_method 設定為 O_DIRECT_NO_FSYNC\n設定值 Open log files Flush log Open dataFile Flush data fsync fsync() fsync() O_DSYNC O_SYNC O_SYNC fsync() O_DIRECT fsync() O_DIRECT fsync() O_DIRECT_NO_FSYNC 參考 Adjusting MySQL 8.0 Memory Parameters - Percona\n使用O_DIRECT_NO_FSYNC来提升MySQL性能 - 溫正湖(網易數據庫內核開發)\n","date":"2024-04-30T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-innodb-flush-method/","title":"innodb_flush_method"},{"content":"在 MySQL 8.0 之前只能從 SHOW SLAVE STATUS 中的 Second_Behind_Master 來確認 replication delay，但是這對於複雜的 replication topologies (拓撲) 不適用，例如：\n如上圖，在 8.0 之前我們在 C 的機器只能知道 B、C 之間的 replication delay，無法知道 A、C 之間的 replication delay，而 MySQL 8.0 進行了一些改善。\nReplication Delay Timestamps MySQL 8.0 開始提供了新的方式來測量 replication delay，方法是在 binlog 中為 Transaction 添加以下兩個時間戳：\noriginal_commit_timestamp：紀錄 Transaction 在最原本的 Master commit 的時間戳 immediate_commit_timestamp：紀錄 Transaction 在 Slave 連線的 Master 上 commit 的時間戳 透過 mysqlbinlog 指令查看 MySQL 8.0 之後的 binlog：\n1 2 3 4 5 6 7 8 9 #221202 18:02:25 server id 1 end_log_pos 707 CRC32 0xf8ff712d Anonymous_GTID last_committed=2 sequence_number=3 rbr_only=yes original_committed_timestamp=1669975345432917 immediate_commit_timestamp=1669975527438008 transaction_length=357 /*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/; # original_commit_timestamp=1669975345432917 (2022-12-02 18:02:25.432917 CST) # immediate_commit_timestamp=1669975527438008 (2022-12-02 18:05:27.438008 CST) /*!80001 SET @@session.original_commit_timestamp=1669975345432917*//*!*/; /*!80014 SET @@session.original_server_version=80031*//*!*/; /*!80014 SET @@session.immediate_server_version=80031*//*!*/; SET @@SESSION.GTID_NEXT= \u0026#39;ANONYMOUS\u0026#39;/*!*/; # at 707 在所有的 Replica 中，所有被回放的 Transaction 其 original_commit_timestamp 始終相同，都是最源頭的 Source 執行該 Query 時 commit 的時間。 在源頭的 Source binlog 中 original_commit_timestamp 等於 immediate_commit_timestamp。 在 Replica 的 relay log 中其 original_commit_timestamp 、immediate_commit_timestamp 會等於其連線 Source 上的 binlog 紀錄。 在 Replica 的 binlog 中，immediate_commit_timestamp 是自己 commit 的時間戳。 Monitoring Replication Delay 除了添加了新的 replication delay timestamp，8.0 也在 performance_schema 中新增以下三張表方便觀察 replication delay：\nreplication_connection_status：紀錄 IO_THREAD 在寫入 relay log 的工作狀態。 LAST_QUEUED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP\n最後一個已寫入 relay log 的 Transaction 其 original_commit_timestamp。\nLAST_QUEUED_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP 最後一個已寫入 relay log 的 Transaction 其 immediate_commit_timestamp。\nLAST_QUEUED_TRANSACTION_START_QUEUE_TIMESTAMP 最後一個已寫入 relay log 的 Transaction 的開始時間。\nLAST_QUEUED_TRANSACTION_END_QUEUE_TIMESTAMP 最後一個已寫入 relay log 的 Transaction 的結束時間。\nQUEUEING_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP 正在寫入 relay log 的 Transaction 其 original_commit_timestamp。\nQUEUEING_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP 正在寫入 relay log 的 Transaction 其 immediate_commit_timestamp。\nQUEUEING_TRANSACTION_START_QUEUE_TIMESTAMP 正在寫入 relay log 的 Transaction 其開始寫入的時間。\nreplication_applier_status_by_worker：記錄每一條 SQL_THREAD 的工作狀態。 LAST_APPLIED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP 最後一個被回放的 Transaction 其 original_commit_timestamp。 LAST_APPLIED_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP 最後一個被回放的 Transaction 其 immediate_commit_timestamp。 LAST_APPLIED_TRANSACTION_START_APPLY_TIMESTAMP 最後一個被回放的 Transaction 其回放的開始時間。 LAST_APPLIED_TRANSACTION_END_APPLY_TIMESTAMP 最後一個被回放的 Transaction 其回放的結束時間。 APPLYING_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP 正在被回放的 Transaction 其 original_commit_timestamp。 APPLYING_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP 正在被回放的 Transaction 其 immediate_commit_timestamp。 APPLYING_TRANSACTION_START_APPLY_TIMESTAMP 正在被回放的 Transaction 其回放的開始時間。 replication_applier_status_by_coordinator：紀錄 MTS 中的 Coordinator 線程的工作狀態，當未開啟 MTS 此表為空。 LAST_PROCESSED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP 最後一個被 Coordinator 線程處理的 Transaction 其 original_commit_timestamp。\nLAST_PROCESSED_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP 最後一個被 Coordinator 線程處理的 Transaction 其 immediate_commit_timestamp。\nLAST_PROCESSED_TRANSACTION_START_BUFFER_TIMESTAMP 最後一個 Transaction 什麼時候開始被 Coordinator 寫入 Worker 線程的 buffer。\nLAST_PROCESSED_TRANSACTION_END_BUFFER_TIMESTAMP\n最後一個 Transaction 什麼時候被 Coordinator 寫入 Worker 線程的 buffer。\nPROCESSING_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP\n正在被 Coordinator 線程處理的 Transaction 其 original_commit_timestamp。\nPROCESSING_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP 正在被 Coordinator 線程處理的 Transaction 其 immediate_commit_timestamp。\nPROCESSING_TRANSACTION_START_BUFFER_TIMESTAMP\n正在被 Coordinator 線程處理的 Transaction 其開始寫入 Worker 線程的 buffer 的時間。\n注意：這些 Table 中的 immediate_commit_timestamp 都是從 relay log 中取得。\n範例 觀察 A → C 之間完整的延遲\n1 2 3 4 5 SELECT TIMEDIFF( LAST_APPLIED_TRANSACTION_END_APPLY_TIMESTAMP, LAST_APPLIED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP ) FROM performance_schema.replication_applier_status_by_worker 觀察 B → C 之間完整的延遲\n1 2 3 4 5 SELECT TIMEDIFF( LAST_APPLIED_TRANSACTION_END_APPLY_TIMESTAMP, LAST_APPLIED_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP ) FROM performance_schema.replication_applier_status_by_worker C 正在回放的 Transaction 和 B 的延遲\n1 2 3 4 5 SELECT TIMEDIFF( APPLYING_TRANSACTION_START_APPLY_TIMESTAMP, APPLYING_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP ) FROM performance_schema.replication_applier_status_by_worker 開啟 MTS 時，Coordinator 正在處理的 Transaction 和 B 的延遲\n1 2 3 4 5 SELECT TIME_DIFF( PROCESSING_TRANSACTION_START_BUFFER_TIMESTAMP, PROCESSING_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP ) FROM performance_schema.replication_applier_status_by_coordinator 觀察 C relaylog 中最後寫入的 Transaction 在 A commit 的延遲\n1 2 3 4 5 SELECT TIMEDIFF( LAST_QUEUED_TRANSACTION_END_QUEUE_TIMESTAMP, LAST_QUEUED_TRANSACTION_ORIGINAL_COMMIT_TIMESTAMP ) FROM performance_schema.replication_connection_status 觀察 B → C 之間 relaylog 的寫入延遲\n1 2 3 4 5 SELECT TIMEDIFF( QUEUEING_TRANSACTION_START_QUEUE_TIMESTAMP, QUEUEING_TRANSACTION_IMMEDIATE_COMMIT_TIMESTAMP ) FROM performance_schema.replication_connection_status 其他用途 在 binlog 中我們知道有 exec_time 這個值，但這個值並不能讓我們準確的知道 Transaction commit 的確切時間，但在 MySQL 8.0 之後我們可以透過觀測 original_commit_timestamp 來確認，參考以下例子：在一張表上執行了 458752 筆資料的 update，總計花費時間 13.62 sec\n1 2 3 4 5 6 7 8 9 10 mysql\u0026gt; select now(); update t1 set name=repeat(\u0026#39;c\u0026#39;,2000); +---------------------+ | now() | +---------------------+ | 2022-12-06 08:55:06 | +---------------------+ 1 row in set (0.00 sec) Query OK, 458752 rows affected (13.62 sec) Rows matched: 524288 Changed: 458752 讓我們看一下 binlog：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #221206 16:55:06 server id 1 end_log_pos 241 CRC32 0x4cc632cf Anonymous_GTID last_committed=0 sequence_number=1 rbr_only=yes original_committed_timestamp=1670316919294397 immediate_commit_timestamp=1670316919294397 transaction_length=190792863 /*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/; # original_commit_timestamp=1670316919294397 (2022-12-06 16:55:19.294397 CST) # immediate_commit_timestamp=1670316919294397 (2022-12-06 16:55:19.294397 CST) /*!80001 SET @@session.original_commit_timestamp=1670316919294397*//*!*/; /*!80014 SET @@session.original_server_version=80021*//*!*/; /*!80014 SET @@session.immediate_server_version=80021*//*!*/; SET @@SESSION.GTID_NEXT= \u0026#39;ANONYMOUS\u0026#39;/*!*/; # at 241 #221206 16:55:06 server id 1 end_log_pos 325 CRC32 0x3035566a Query thread_id=2244 exec_time=1 error_code=0 ... #221206 16:55:06 server id 1 end_log_pos 384 CRC32 0xeed08d18 Rows_query # update t1 set name=repeat(\u0026#39;c\u0026#39;,2000) ... 可以看到 exec_time 顯示的是 1，而不是正確的執行時間，這是因為 exec_time 指的是 update 第一筆資料花費的時間，而不是整個 update 語句執行的時間。\n不過從 MySQL 8.0 開始我們就可以透過 transaction 開始時間 (也就是 16:55:06) 和 transaction commit 的時間 - immediate_commit_timestamp (也就是 16:55:19) 判斷出這個 transaction 執行了 13 sec。\n參考 MySQL :: MySQL 8.0 Reference Manual :: 17.4.11 Delayed Replication\nMySQL :: WL#7319: Infrastructure for GTID based delayed replication and replication lag monitoring\nMySQL :: WL#7374: Performance schema tables to monitor replication lags and queue\n新特性解读 | MySQL 8 复制延迟观测新方式，更全面更精准 - 知乎 (zhihu.com)\nbinlog记录SQL执行时间吗，准不准，时间是否包含锁等待时间 - 柴米油盐酱醋 - 博客园 (cnblogs.com)\nMySQL · 答疑解惑 · 备库Seconds_Behind_Master计算 (taobao.org)\nMySQL 复制延迟计算的问题分析 - ZhenXing_Yu - 博客园 (cnblogs.com)\n","date":"2022-12-23T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-replication-delay-observation-improve/","title":"MySQL8.0 對於 replication delay 觀測改進"},{"content":"重現 事前準備 (schema、初始資料)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 CREATE TABLE `round_to_txn` ( `round_id` varchar(30) NOT NULL COMMENT \u0026#39;訂單號\u0026#39;, `txn_id` char(50) NOT NULL COMMENT \u0026#39;交易代碼\u0026#39;, `end_time` timestamp NOT NULL DEFAULT \u0026#39;0000-00-00 00:00:00\u0026#39; COMMENT \u0026#39;結算時間\u0026#39;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;建立時間\u0026#39;, PRIMARY KEY (`round_id`,`txn_id`,`end_time`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT=\u0026#39;局號關聯的交易單號\u0026#39; /*!50100 PARTITION BY RANGE (unix_timestamp(`end_time`)) (PARTITION PHISTORY VALUES LESS THAN (1654056000) ENGINE = InnoDB, PARTITION P202206 VALUES LESS THAN (1656648000) ENGINE = InnoDB, PARTITION P202207 VALUES LESS THAN (1659326400) ENGINE = InnoDB, PARTITION P202208 VALUES LESS THAN (1662004800) ENGINE = InnoDB, PARTITION P202209 VALUES LESS THAN (1664596800) ENGINE = InnoDB, PARTITION P202210 VALUES LESS THAN (1667275200) ENGINE = InnoDB, PARTITION P202211 VALUES LESS THAN (1669867200) ENGINE = InnoDB, PARTITION P202212 VALUES LESS THAN (1672545600) ENGINE = InnoDB, PARTITION P202301 VALUES LESS THAN (1675224000) ENGINE = InnoDB, PARTITION P202302 VALUES LESS THAN (1677643200) ENGINE = InnoDB, PARTITION P202303 VALUES LESS THAN (1680321600) ENGINE = InnoDB, PARTITION P202304 VALUES LESS THAN (1682913600) ENGINE = InnoDB, PARTITION P202305 VALUES LESS THAN (1685592000) ENGINE = InnoDB, PARTITION P202306 VALUES LESS THAN (1688184000) ENGINE = InnoDB, PARTITION POTHER VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */ ; INSERT INTO round_to_txn(round_id, txn_id, end_time) VALUES (\u0026#39;039910eukXEC\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039911eukXEC\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039910eukXEC\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039911eukXEC\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039912eukXEC\u0026#39;, \u0026#39;9\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039913eukXEC\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039912eukXEC\u0026#39;, \u0026#39;11\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039913eukXEC\u0026#39;, \u0026#39;12\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039914eukXEC\u0026#39;, \u0026#39;13\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039914eukXEC\u0026#39;, \u0026#39;14\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039915eukXEC\u0026#39;, \u0026#39;15\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039915eukXEC\u0026#39;, \u0026#39;16\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039916eukXEC\u0026#39;, \u0026#39;17\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039917eukXEC\u0026#39;, \u0026#39;18\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039916eukXEC\u0026#39;, \u0026#39;19\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039917eukXEC\u0026#39;, \u0026#39;20\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039918eukXEC\u0026#39;, \u0026#39;21\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039919eukXEC\u0026#39;, \u0026#39;22\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039918eukXEC\u0026#39;, \u0026#39;23\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039919eukXEC\u0026#39;, \u0026#39;24\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039920eukXEC\u0026#39;, \u0026#39;25\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039920eukXEC\u0026#39;, \u0026#39;26\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039921eukXEC\u0026#39;, \u0026#39;27\u0026#39;, \u0026#39;0000-00-00 00:00:00\u0026#39;), (\u0026#39;039909eukXEC\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;2022-11-01 00:10:00\u0026#39;), (\u0026#39;039909eukXEC\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;2022-11-01 00:10:00\u0026#39;), (\u0026#39;039908eukXEC\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;2022-10-01 00:10:00\u0026#39;), (\u0026#39;039908eukXEC\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2022-10-01 00:10:00\u0026#39;); 模擬並行 update 資料的程式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 package main import ( \u0026#34;database/sql\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) const ( dbHost string = \u0026#34;10.17.117.203\u0026#34; dbPort int = 3331 dbUser string = \u0026#34;root\u0026#34; dbPassword string = \u0026#34;root\u0026#34; dbDatabase string = \u0026#34;test\u0026#34; dbMaxOpenConns int = 10 dbMaxIdleConns int = 10 dbMaxLifetime int = 3600 ) var DB *sql.DB func initDB() { var err error dsn := fmt.Sprintf(\u0026#34;%s:%s@tcp(%s:%d)/%s\u0026#34;, dbUser, dbPassword, dbHost, dbPort, dbDatabase) DB, err = sql.Open(\u0026#34;mysql\u0026#34;, dsn) DB.SetMaxOpenConns(dbMaxOpenConns) DB.SetMaxIdleConns(dbMaxIdleConns) DB.SetConnMaxLifetime(time.Duration(dbMaxLifetime) * time.Second) if err != nil { fmt.Println(\u0026#34;connection to mysql failed:\u0026#34;, err) return } fmt.Println(\u0026#34;connnect success\u0026#34;) } func txUpdateTest(roundId string, endTime string, wg *sync.WaitGroup) { defer wg.Done() // begin transaction tx, err := DB.Begin() if err != nil { fmt.Println(\u0026#34;begin fail: \u0026#34;, err) return } // prepare stmt, err := tx.Prepare(\u0026#34;UPDATE `round_to_txn` SET `end_time` = ? WHERE `round_id` = ?\u0026#34;) // 會 deadlock // stmt, err := tx.Prepare(\u0026#34;UPDATE `round_to_txn` SET `end_time` = ? WHERE `round_id` = ? AND `end_time` = \u0026#39;0000-00-00 00:00:00\u0026#39;\u0026#34;) // 不會 deadlock // stmt, err := tx.Prepare(\u0026#34;UPDATE `round_to_txn` SET `end_time` = ? WHERE `round_id` = ? AND `end_time` \u0026lt;= \u0026#39;2022-10-31 23:59:59\u0026#39;\u0026#34;) // 不會 deadlock //stmt, err := tx.Prepare(\u0026#34;UPDATE `round_to_txn` SET `end_time` = ? WHERE `round_id` = ? AND (`end_time` \u0026lt;= \u0026#39;2022-10-31 23:59:59\u0026#39; OR `end_time` \u0026gt;= \u0026#39;2022-12-01 00:00:00\u0026#39; )\u0026#34;) // 不會 deadlock // stmt, err := tx.Prepare(\u0026#34;UPDATE `round_to_txn` SET `end_time` = ? WHERE `round_id` = ? AND (`end_time` \u0026lt;= \u0026#39;2022-11-10 23:59:59\u0026#39;)\u0026#34;) // 會 deadlock if err != nil { fmt.Println(\u0026#34;prepare fail: \u0026#34;, err) return } // exec _, err = stmt.Exec(endTime, roundId) if err != nil { fmt.Println(\u0026#34;Exec fail: \u0026#34;, err) return } // commit tx.Commit() } func updateTest(roundId string, endTime string) { _, err := DB.Exec(\u0026#34;UPDATE `round_to_txn` SET `end_time` = ? WHERE `round_id` = ?\u0026#34;, endTime, roundId) if err != nil { fmt.Println(\u0026#34;update fail:\u0026#34;, err) return } } func main() { wg := new(sync.WaitGroup) initDB() defer DB.Close() type sqlValue struct { roundId string endTime string } var initValue = []sqlValue{} for i := 10; i \u0026lt; 21; i++ { initValue = append(initValue, sqlValue{fmt.Sprintf(\u0026#34;0399%deukXEC\u0026#34;, i), \u0026#34;0000-00-00 00:00:00\u0026#34;}) } for _, e := range initValue { updateTest(e.roundId, e.endTime) } var testValue = []sqlValue{} for i := 10; i \u0026lt; 21; i++ { testValue = append(testValue, sqlValue{fmt.Sprintf(\u0026#34;0399%deukXEC\u0026#34;, i), \u0026#34;2022-11-16 08:53:08\u0026#34;}) } for _, e := range testValue { wg.Add(1) go txUpdateTest(e.roundId, e.endTime, wg) } wg.Wait() } 測試結果如下表：\n語法：UPDATE round_to_txn SET end_time = \u0026ldquo;2022-11-16 08:53:08” WHERE … 是否有 deadlock round_id = ? Yes round_id = ? AND end_time = ‘0000-00-00 00:00:00’ No round_id = ? AND end_time \u0026lt;= \u0026lsquo;2022-10-31 23:59:59\u0026rsquo; No round_id = ? AND end_time \u0026lt;= \u0026lsquo;2022-11-10 23:59:59\u0026rsquo; No round_id = ? AND (end_time \u0026lt;= \u0026lsquo;2022-10-31 23:59:59\u0026rsquo; OR end_time \u0026gt;= \u0026lsquo;2022-12-01 00:00:00\u0026rsquo; ) Yes DeadLock 分析 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ------------------------ LATEST DETECTED DEADLOCK ------------------------ 2022-11-18 09:00:57 140176279025408 *** (1) TRANSACTION: TRANSACTION 4914, ACTIVE 0 sec inserting mysql tables in use 1, locked 1 LOCK WAIT 32 lock struct(s), heap size 3488, 18 row lock(s) MySQL thread id 9140, OS thread handle 140176259069696, query id 21183 10.17.117.103 root updating UPDATE `round_to_txn` SET `end_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039912eukXEC\u0026#39; *** (1) HOLDS THE LOCK(S): RECORD LOCKS space id 74 page no 4 n bits 80 index PRIMARY of table `test`.`round_to_txn` /* Partition `p202211` */ trx id 4914 lock_mode X locks gap before rec ... *** (1) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 74 page no 4 n bits 80 index PRIMARY of table `test`.`round_to_txn` /* Partition `p202211` */ trx id 4914 lock_mode X locks gap before rec insert intention waiting ... *** (2) TRANSACTION: TRANSACTION 4923, ACTIVE 0 sec inserting mysql tables in use 1, locked 1 LOCK WAIT 32 lock struct(s), heap size 3488, 18 row lock(s) MySQL thread id 9142, OS thread handle 140176262240000, query id 21200 10.17.117.103 root updating UPDATE `round_to_txn` SET `end_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039915eukXEC\u0026#39; *** (2) HOLDS THE LOCK(S): RECORD LOCKS space id 74 page no 4 n bits 80 index PRIMARY of table `test`.`round_to_txn` /* Partition `p202211` */ trx id 4923 lock_mode X locks gap before rec ... *** (2) WAITING FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 74 page no 4 n bits 80 index PRIMARY of table `test`.`round_to_txn` /* Partition `p202211` */ trx id 4923 lock_mode X locks gap before rec insert intention waiting ... *** WE ROLL BACK TRANSACTION (2) 看一下上方的 log 可以看到 deadlock 的原因是兩者都有 GAP LOCK，而 GAP LOCK 本身互相不衝突，但是都會阻塞 INSERT 操作來達到 RR 級別的可重複讀，就在這時候 2 個 Transaction 同時又要求 Insert Intention Locks，這就導致雙方都在等待對方釋放 GAP LOCK，因此發生了 DEADLOCK。\n但是問題來了，這兩個 Transaction 都是 UPDATE 操作，為什麼會有 INSERT 操作才有的 Insert Intention Locks 呢?\n實驗 沒有 partition 的測試 我們建立一個 schema 相同，但是沒有 partition 的 table 測試\n1 2 3 4 5 6 7 8 9 10 11 mysql\u0026gt; show create table nop_test\\G *************************** 1. row *************************** Table: nop_test Create Table: CREATE TABLE `nop_test` ( `round_id` varchar(30) NOT NULL COMMENT \u0026#39;訂單號\u0026#39;, `txn_id` char(50) NOT NULL COMMENT \u0026#39;交易代碼\u0026#39;, `end_time` timestamp NOT NULL DEFAULT \u0026#39;0000-00-00 00:00:00\u0026#39; COMMENT \u0026#39;結算時間\u0026#39;, `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \u0026#39;建立時間\u0026#39;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT \u0026#39;最新更新時間\u0026#39;, PRIMARY KEY (`round_id`,`txn_id`,`end_time`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT=\u0026#39;局號關聯的交易單號\u0026#39; 單獨一個 update 操作的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; update nop_test set end_time = now() where round_id = \u0026#39;039910eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+-----------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+-----------+-------------+ | 6502 | nop_test | NULL | TABLE | IX | GRANTED | | 6502 | nop_test | PRIMARY | RECORD | X | GRANTED | | 6502 | nop_test | PRIMARY | RECORD | X,GAP | GRANTED | +------+-------------+------------+-----------+-----------+-------------+ mysql\u0026gt; SHOW ENGINE INNODB STATUS\\G *************************** 1. row *************************** ... ---TRANSACTION 6502, ACTIVE 18 sec 3 lock struct(s), heap size 1128, 5 row lock(s), undo log entries 4 MySQL thread id 17233, OS thread handle 140176258012928, query id 39405 localhost root starting SHOW ENGINE INNODB STATUS TABLE LOCK table `test`.`nop_test` trx id 6502 lock mode IX RECORD LOCKS space id 115 page no 4 n bits 96 index PRIMARY of table `test`.`nop_test` trx id 6502 lock_mode X Record lock, heap no 2 PHYSICAL RECORD: n_fields 7; compact format; info bits 32 0: len 12; hex 30333939313065756b584543; asc 039910eukXEC;; 1: len 30; hex 352020202020202020202020202020202020202020202020202020202020; asc 5 ; (total 50 bytes); 2: len 4; hex 00000000; asc ;; 3: len 6; hex 000000001966; asc f;; 4: len 7; hex 020000011e1518; asc ;; 5: len 4; hex 637ae7b8; asc cz ;; 6: len 4; hex 637ae7b8; asc cz ;; ... ... Record lock, heap no 30 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 12; hex 30333939313065756b584543; asc 039910eukXEC;; 1: len 30; hex 372020202020202020202020202020202020202020202020202020202020; asc 7 ; (total 50 bytes); 2: len 4; hex 637ae7c9; asc cz ;; 3: len 6; hex 000000001966; asc f;; 4: len 7; hex 8200000105015d; asc ];; 5: len 4; hex 637ae7b8; asc cz ;; 6: len 4; hex 637ae7c9; asc cz ;; 可以看到如果在沒有 partition 的 table 上進行 update 操作會有以下 LOCK：\n該 Table 的 IX 因為是透過 PK 來掃描，因此在 PK 上命中的行加上 Record Lock 因為條件沒有覆蓋 PK 條件，因此在符合的位置加上 Gap Lock 避免被 INSERT 複數 update 操作的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 -- Transaction 1 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; update p_test set end_time = now() where round_id = \u0026#39;039910eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 -- Transaction 2 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; update p_test set end_time = now() where round_id = \u0026#39;039910eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+-----------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+-----------+-------------+ | 6545 | nop_test | NULL | TABLE | IX | GRANTED | | 6545 | nop_test | PRIMARY | RECORD | X | GRANTED | | 6545 | nop_test | PRIMARY | RECORD | X,GAP | GRANTED | | 6544 | nop_test | NULL | TABLE | IX | GRANTED | | 6544 | nop_test | PRIMARY | RECORD | X | GRANTED | | 6544 | nop_test | PRIMARY | RECORD | X,GAP | GRANTED | +------+-------------+------------+-----------+-----------+-------------+ mysql\u0026gt; show engine innodb status\\G *************************** 1. row *************************** ---TRANSACTION 6545, ACTIVE 21 sec 3 lock struct(s), heap size 1128, 5 row lock(s), undo log entries 4 MySQL thread id 17290, OS thread handle 140175996847872, query id 39805 localhost root TABLE LOCK table `test`.`nop_test` trx id 6545 lock mode IX RECORD LOCKS space id 115 page no 4 n bits 96 index PRIMARY of table `test`.`nop_test` trx id 6545 lock_mode X ... RECORD LOCKS space id 115 page no 4 n bits 96 index PRIMARY of table `test`.`nop_test` trx id 6545 lock_mode X locks gap before rec ... ---TRANSACTION 6544, ACTIVE 32 sec 3 lock struct(s), heap size 1128, 5 row lock(s), undo log entries 4 MySQL thread id 17233, OS thread handle 140176258012928, query id 39809 localhost root starting show engine innodb status TABLE LOCK table `test`.`nop_test` trx id 6544 lock mode IX RECORD LOCKS space id 115 page no 4 n bits 96 index PRIMARY of table `test`.`nop_test` trx id 6544 lock_mode X ... RECORD LOCKS space id 115 page no 4 n bits 96 index PRIMARY of table `test`.`nop_test` trx id 6544 lock_mode X locks gap before rec ... 可以看到當有 2 句 update 操作時其實 LOCK 情況並沒有分別，且因為兩者 Record Lock 不衝突，且 Gap Lock 互相不阻塞，因此兩者都能成功 UPDATE。\n有 partition 的測試 單獨一個 update 非 partition key操作的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; update p_test set update_time = now() where round_id = \u0026#39;039910eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+-----------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+-----------+-------------+ | 7968 | p_test | NULL | TABLE | IX | GRANTED | | 7968 | p_test | PRIMARY | RECORD | X | GRANTED | | 7968 | p_test | PRIMARY | RECORD | X,GAP | GRANTED | +------+-------------+------------+-----------+-----------+-------------+ 3 rows in set (0.00 sec) mysql\u0026gt; SHOW ENGINE INNODB STATUS\\G *************************** 1. row *************************** ... ---TRANSACTION 7968, ACTIVE 34 sec 31 lock struct(s), heap size 3488, 17 row lock(s), undo log entries 2 MySQL thread id 17290, OS thread handle 140175996847872, query id 43462 localhost root starting SHOW ENGINE INNODB STATUS TABLE LOCK table `test`.`p_test` /* Partition `pother` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202306` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202305` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202304` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202303` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202302` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202301` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202212` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202211` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202210` */ trx id 7968 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS -------- 看起來和 partition 的單獨 update 相同，只是因為有切 partition，所以需要對每個 Partition 加上 IX 。\n複數 update 非 partition key 操作的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 -- Transaction 1 mysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; UPDATE `round_to_txn` SET `update_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039912eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 -- Transaction 2 mysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; UPDATE `round_to_txn` SET `update_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039913eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+-----------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+-----------+-------------+ | 7969 | p_test | NULL | TABLE | IX | GRANTED | | 7969 | p_test | PRIMARY | RECORD | X | GRANTED | | 7969 | p_test | PRIMARY | RECORD | X,GAP | GRANTED | | 7968 | p_test | NULL | TABLE | IX | GRANTED | | 7968 | p_test | PRIMARY | RECORD | X | GRANTED | | 7968 | p_test | PRIMARY | RECORD | X,GAP | GRANTED | +------+-------------+------------+-----------+-----------+-------------+ 6 rows in set (0.00 sec) mysql\u0026gt; show engine innodb status\\G *************************** 1. row *************************** ---TRANSACTION 7969, ACTIVE 35 sec 31 lock struct(s), heap size 3488, 17 row lock(s), undo log entries 2 MySQL thread id 17233, OS thread handle 140176258012928, query id 43468 localhost root TABLE LOCK table `test`.`p_test` /* Partition `pother` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202306` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202305` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202304` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202303` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202302` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202301` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202212` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202211` */ trx id 7969 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202210` */ trx id 7969 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS ---TRANSACTION 7968, ACTIVE 108 sec 31 lock struct(s), heap size 3488, 17 row lock(s), undo log entries 2 MySQL thread id 17290, OS thread handle 140175996847872, query id 43472 localhost root starting show engine innodb status TABLE LOCK table `test`.`p_test` /* Partition `pother` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202306` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202305` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202304` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202303` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202302` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202301` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202212` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202211` */ trx id 7968 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202210` */ trx id 7968 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS 可以看到和單獨執行一句 update 一樣，只有 Record Lock、Gap Lock 並沒有產生衝突\n單獨一個 update partition key 操作的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 mysql\u0026gt; begin; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; update p_test set end_time = now() where round_id = \u0026#39;039910eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+-------------+------------+-----------+-----------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+-------------+------------+-----------+-----------+-------------+ | 6228 | p_test | NULL | TABLE | IX | GRANTED | | 6228 | p_test | PRIMARY | RECORD | X | GRANTED | | 6228 | p_test | PRIMARY | RECORD | X,GAP | GRANTED | +------+-------------+------------+-----------+-----------+-------------+ 3 rows in set (0.00 sec) mysql\u0026gt; SHOW ENGINE INNODB STATUS\\G *************************** 1. row *************************** ... ---TRANSACTION 6228, ACTIVE 48 sec 32 lock struct(s), heap size 3488, 19 row lock(s), undo log entries 4 MySQL thread id 17233, OS thread handle 140176258012928, query id 39374 localhost root starting SHOW ENGINE INNODB STATUS TABLE LOCK table `test`.`p_test` /* Partition `pother` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202306` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202305` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202304` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202303` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202302` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202301` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202212` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202211` */ trx id 6228 lock mode IX TABLE LOCK table `test`.`p_test` /* Partition `p202210` */ trx id 6228 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS -------- 看起來和 partition 的單獨 update 相同，只是因為有切 partition，所以需要對每個 Partition 加上 IX 。\n複數 update partition key 操作的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 -- Transaction 1 mysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; UPDATE `round_to_txn` SET `end_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039912eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 -- Transaction 2 mysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; UPDATE `round_to_txn` SET `end_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039913eukXEC\u0026#39;; -- Lock Wait ... mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+--------------+------------+-----------+------------------------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+--------------+------------+-----------+------------------------+-------------+ | 7961 | round_to_txn | NULL | TABLE | IX | GRANTED | | 7961 | round_to_txn | PRIMARY | RECORD | X | GRANTED | | 7961 | round_to_txn | PRIMARY | RECORD | X,GAP | GRANTED | | 7961 | round_to_txn | PRIMARY | RECORD | X,GAP,INSERT_INTENTION | WAITING | | 7956 | round_to_txn | NULL | TABLE | IX | GRANTED | | 7956 | round_to_txn | PRIMARY | RECORD | X | GRANTED | | 7956 | round_to_txn | PRIMARY | RECORD | X,GAP | GRANTED | +------+--------------+------------+-----------+------------------------+-------------+ mysql\u0026gt; show engine innodb status\\G *************************** 1. row *************************** ---TRANSACTION 7961, ACTIVE 20 sec inserting mysql tables in use 1, locked 1 LOCK WAIT 32 lock struct(s), heap size 3488, 18 row lock(s) MySQL thread id 17290, OS thread handle 140175996847872, query id 43421 localhost root updating UPDATE `round_to_txn` SET `end_time` = \u0026#39;2022-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039913eukXEC\u0026#39; ------- TRX HAS BEEN WAITING 20 SEC FOR THIS LOCK TO BE GRANTED: RECORD LOCKS space id 74 page no 4 n bits 80 index PRIMARY of table `test`.`round_to_txn` /* Partition `p202211` */ trx id 7961 lock_mode X locks gap before rec insert intention waiting Record lock, heap no 6 PHYSICAL RECORD: n_fields 7; compact format; info bits 0 0: len 12; hex 30333939313865756b584543; asc 039918eukXEC;; 1: len 30; hex 323120202020202020202020202020202020202020202020202020202020; asc 21 ; (total 50 bytes); 2: len 4; hex 6374a4f4; asc ct ;; 3: len 6; hex 000000001f09; asc ;; 4: len 7; hex 82000000fc0110; asc ;; 5: len 4; hex 63760cc6; asc cv ;; 6: len 4; hex 637b2b14; asc c ;; ------------------ TABLE LOCK table `test`.`round_to_txn` /* Partition `pother` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202306` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202305` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202304` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202303` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202302` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202301` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202212` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202211` */ trx id 7961 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202210` */ trx id 7961 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS ---TRANSACTION 7956, ACTIVE 27 sec 31 lock struct(s), heap size 3488, 19 row lock(s), undo log entries 4 MySQL thread id 17233, OS thread handle 140176258012928, query id 43425 localhost root starting show engine innodb status TABLE LOCK table `test`.`round_to_txn` /* Partition `pother` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202306` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202305` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202304` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202303` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202302` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202301` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202212` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202211` */ trx id 7956 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202210` */ trx id 7956 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS 我們可以看到出現了 Insert Intention Locks，因為 Insert Intention Locks 是延遲加鎖機制，只有和 Gap Lock 發生衝突才加上來的，所以單獨執行沒發生衝突也看不到 Insert Intention Locks，同時我們也知道了當在\n複數 update partition key 操作，但不變動 partition key 的 Lock 測試 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 -- Transaction 1 mysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; UPDATE `round_to_txn` SET `end_time` = \u0026#39;2020-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039912eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 -- Transaction 2 mysql\u0026gt; begin; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; UPDATE `round_to_txn` SET `end_time` = \u0026#39;2020-11-16 08:53:08\u0026#39; WHERE `round_id` = \u0026#39;039913eukXEC\u0026#39;; Query OK, 2 rows affected (0.00 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql\u0026gt; SELECT DISTINCT ENGINE_TRANSACTION_ID AS TID,OBJECT_NAME,INDEX_NAME,LOCK_TYPE,LOCK_MODE,LOCK_STATUS FROM performance_schema.data_locks; +------+--------------+------------+-----------+-----------+-------------+ | TID | OBJECT_NAME | INDEX_NAME | LOCK_TYPE | LOCK_MODE | LOCK_STATUS | +------+--------------+------------+-----------+-----------+-------------+ | 8908 | round_to_txn | NULL | TABLE | IX | GRANTED | | 8908 | round_to_txn | PRIMARY | RECORD | X,GAP | GRANTED | | 8908 | round_to_txn | PRIMARY | RECORD | X | GRANTED | | 8907 | round_to_txn | NULL | TABLE | IX | GRANTED | | 8907 | round_to_txn | PRIMARY | RECORD | X,GAP | GRANTED | | 8907 | round_to_txn | PRIMARY | RECORD | X | GRANTED | +------+--------------+------------+-----------+-----------+-------------+ mysql\u0026gt; show engine innodb status\\G *************************** 1. row *************************** ------------ TRANSACTIONS ------------ Trx id counter 8913 Purge done for trx\u0026#39;s n:o \u0026lt; 8913 undo n:o \u0026lt; 0 state: running but idle History list length 2 LIST OF TRANSACTIONS FOR EACH SESSION: ---TRANSACTION 421651726690736, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 421651726689928, not started 0 lock struct(s), heap size 1128, 0 row lock(s) ---TRANSACTION 8908, ACTIVE 39 sec 31 lock struct(s), heap size 3488, 19 row lock(s), undo log entries 4 MySQL thread id 29087, OS thread handle 140175996847872, query id 66467 localhost root starting show engine innodb status TABLE LOCK table `test`.`round_to_txn` /* Partition `pother` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202306` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202305` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202304` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202303` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202302` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202301` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202212` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202211` */ trx id 8908 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202210` */ trx id 8908 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS ---TRANSACTION 8907, ACTIVE 50 sec 31 lock struct(s), heap size 3488, 19 row lock(s), undo log entries 4 MySQL thread id 29008, OS thread handle 140176595552000, query id 66460 localhost root TABLE LOCK table `test`.`round_to_txn` /* Partition `pother` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202306` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202305` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202304` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202303` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202302` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202301` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202212` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202211` */ trx id 8907 lock mode IX TABLE LOCK table `test`.`round_to_txn` /* Partition `p202210` */ trx id 8907 lock mode IX 10 LOCKS PRINTED FOR THIS TRX: SUPPRESSING FURTHER PRINTS 我們可以看到這一次沒有 Insert Intention Locks，這是因為 update 的值沒有導致資料需要被變更到別的 partition，所以加鎖的情況會等同於普通的 update 並不會產生 Insert Intention Locks 從而導致 DeadLock 的發生。\n結論 在有 partition 的 Table 上執行 UPDATE 操作更新 partition key 發生跨區時，會先由 UPDATE 操作產生 Record Lock (或 Next Key Lock 也就是包含 Gap Lock)，之後轉變成 INSERT 操作將資料塞入新的分區。\n因此如果可以盡量避免去 UPDATE 有切 partition 的欄位。\n","date":"2022-11-28T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-partition-deadlock/","title":"partition deadlock"},{"content":"semi-join 當兩個 Table 之間進行 INNER JOIN 時，當同一個值有多個符合的行，就會返回同等的數量。但是有時候，我們只在乎是否有符合的行，而不是符合的數量。假設當我們想知道有哪些商品(product)被購買時，可以使用以下的語法：\n1 2 3 4 SELECT product.product_num , product.product_name FROM product INNER JOIN orders WHERE product.product_num = orders.product_num; 但是當有一樣商品被重複購買時，上述查詢會產生重複的結果。\n當然也可以透過 DISTINCT 來去除重複，但先生產所有符合的行才去除重複，因此效率很低。此時可以使用子查詢來獲得同樣不重複\n1 2 3 4 SELECT product.product_num , product.product_name FROM product WHERE product_num IN (SELECT product_num FROM orders); 使用以上語法優化器可以知道此處的 IN 語句要求子查詢只需要返回不重複的 product_num，在此情況下，查詢會使用 semi-join。\n從 8.0.16開始，帶有 EXISTS子查詢的語句，也能享受到 IN 子查詢所使用的 semi-join優化－\n1 2 3 4 SELECT product.product_num , product.product_name FROM product WHERE EXISTS (SELECT * FROM orders WHERE product.product_num = orders.product_num); anti-join 從 8.0.17 開始加入了 anti-join的優化，和 semi-join是相同的，差別在於多了 NOT的修飾，以下子查詢將被轉換為 anti-join：\nNOT IN (SELECT \u0026hellip; FROM \u0026hellip;) *子查詢中不可有NULL值 NOT EXISTS (SELECT \u0026hellip; FROM \u0026hellip;) IN (SELECT \u0026hellip; FROM \u0026hellip;) IS NOT TRUE EXISTS (SELECT \u0026hellip; FROM \u0026hellip;) IS NOT TRUE IN (SELECT \u0026hellip; FROM \u0026hellip;) IS FALSE EXISTS (SELECT \u0026hellip; FROM \u0026hellip;) IS FALSE 簡而言之，只要是否定帶有 IN (SELECT ... FROM ...) 或 EXISTS (SELECT ... FROM ...) 的子查詢都會被轉換為 anti-join。\nanti-join 只會返回沒有符合的行，考慮以下查詢－\n1 2 3 4 SELECT product.product_num , product.product_name FROM product WHERE product_num NOT IN (SELECT product_num FROM orders); 此查詢會在內部被改寫為 anti-join，對於 product 的每一行資料，只要在 orders 中有找到符合的資料， product 就會丟棄符合的資料。\n此外當遇到表達式有 NULL值時，則無法轉換為 anti-join，除非使用 ... NOT IN (SELECT ...) IS NOT FALSE或同等的 ... IN (SELECT ...) IS NOT TRUE才能轉換為 anti-join。\n適用情境 子查詢若符合以下條件，就能使用 semi-join(8.0.17 anti-join)來優化\n通用規則 必須是 IN 或 =ANY 出現在最外層的 WHERE或 ON語句 不包含 UNION結構的 SINGAL SELECT 不包含 HAVING 不能包含任何聚合函數(SUM、 MAX\u0026hellip;) 不包含 LIMIT 不包含 STRAIGHT_JOIN (按照撰寫順序做 INNER JOIN的語句) The number of outer and inner tables together must be less than the maximum number of tables permitted in a join. 5.7.* 規則 不包含 GROUP BY 不包含 ORDER BY 不包含 IS [NOT] TRUE|FALSE 8.0.16以上 規則 除了 IN 或 =ANY 還可以是 EXISTS 在沒有聚合函數的情況下使用 GROUP BY，但會被忽略掉 DISTINTCT 可以使用，但會被忽略掉 ORDER BY 可以使用，但會被忽略掉 不包含 IS [NOT] TRUE|FALSE 8.0.17以上規則 可以包含 IS [NOT] TRUE|FALSE 注意： UPDATE 和 DELETE 無法使用 semi-join 優化，建議採用 JOIN 來進行優化\n優化方式 TablePullout\n假設有以下查詢，找出所屬城市有小於特定人口數的國家\n1 2 3 4 5 6 7 SELECT * FROM city WHERE city.country IN ( SELECT country.code FROM country WHERE country.population \u0026lt; 100*1000 ); 當 conutry.code在 country 中不重複(即為 PRIMARY KEY或 UNIQUE INDEX) 時，可以直接改寫為一般的 INNER JOIN即可。\n1 2 3 4 SELECT city.* FROM city,country WHERE city.country = country.code AND country.population \u0026lt; 100*1000; 當觸發 TablePullout時， EXPLAIN 後 SHOW WARNINGS 時可以看到語句被改寫為 INNER JOIN\n適用情境：\noptimizer_switch 中 semijoin=on (預設) IN 子句當中的欄位，必須為該表的 PRIMARY KEY 或 UNIQUE INDEX FirstMatch\n假設有以下查詢，找出所屬城市有超過特定人口數的國家\n1 2 3 4 5 6 7 SELECT * FROM country WHERE country.code IN ( SELECT city.country FROM city WHERE city.population \u0026gt; 1*1000*1000 ); 假設使用 INNER JOIN 如下圖，可以看到就算找到了Germany有符合條件的城市(Berlin)，仍舊會篩選Germany的下一個城市(Koln)，從而造成不必要的篩選與重複結果\n若使用 FirstMatch 則如下圖，可以看出區別在於當找到Germany有符合的城市(Berlin)之後，就不會再往下確認下一個城市(Koln)，而是會確認下一個country France是否有符合的城市，避免了不必要的檢查與產生重複的結果\n當觸發 FirstMatch時， EXPLAIN 中的 EXTRA 中會顯示 FirstMatch\n適用情境：\noptimizer_switch中 firstmatch=on(預設) 子查詢中沒有 GROUP BY / 聚合函數 Duplicate Weedout\n此方案會先使用一般的 INNER JOIN 之後，並使用 臨時表去除重複。假設有一個查詢為找出有城市人口數超過國家總人口的33%以上且超過 110001000\n1 2 3 4 5 6 7 8 SELECT * FROM country where country.code IN ( SELECT city.country FROM city WHERE city.population \u0026gt; 0.33 * country.population AND city.population \u0026gt; 1*1000*1000 ); 對這兩張表進行 INNER JOIN\n透過帶有 PRIMARY KEY的 臨時表 將重複的資料進行過濾\n當觸發 Duplicate Weedout時，會在 EXPLAIN 的 Extra 中顯示 Start temporary; End temporary\n適用情境：\noptimizer_switch中 duplicateweedout=on (預設) 子查詢中沒有 GROUP BY / 聚合函數 LooseScan\n假設有以下查詢擁有衛星的國家，其中 satellite.country_code 有 INDEX\n1 2 3 4 5 6 SELECT * FROM country WHERE country.code IN ( SELECT country_code FROM satellite ); 此時會透過 INDEX 取得 GROUP BY 的動作，來達到去除重複的目的\n當觸發 LooseScan時，會在 EXPLAIN 的 Extra 中顯示 LooseScan\n適用情境：\noptimizer_switch中 looseScan=on (預設)\nexpr IN (SELECT tbl.keypart1 FROM tbl ...) 或\nexpr IN (SELECT tbl.keypart2 FROM tbl WHERE tbl.keypart1=const AND ...)\nmaterialization\n假設有以下查詢要尋找擁有大城市的歐洲國家\n1 2 3 4 5 6 7 SELECT * FROM country WHERE country.code IN ( SELECT city.country FROM city WHERE city.population \u0026gt; 7*1000*1000 ) AND country.continent = \u0026#39;Europe\u0026#39; 此方案會先執行 IN後面的子句並將結果存入 臨時表，表中有 PRIMARY KEY來去除重複，之後再和外側的Country做 INNDER JOIN來篩選歐洲國家\n當觸發 materialization時，會在 EXPLAIN 的 table 中出現 \u0026lt;subquery\u0026gt; 並且 select_type 中會出現 MATERIALIZED\n參考資料 MySQL 5.7 文檔\nMySQL 8.0 文檔\nMaria DB 文檔\nAntijoin in MySQL8(by MySQL Server Blog)\nanti-join幾點總結(by 知乎-知數堂)\n","date":"2022-07-01T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-semi-join-and-anti-join/","title":"semi-join(半連結)和anti-join(反連結)"},{"content":"Password Verification-Required Policy MySQL 8.0.13 開始，可以設定在修改密碼時需要一併提供舊密碼。\n可透過以下 2 種方式設定 -\n全域系統變數 password_require_current 預設值為 OFF ，可以透過調整為 ON 要求修改密碼時提供就密碼。\nCREATE 或 ALTER USER 時加上 PASSWORD REQUIRE CURRENT [DEFAULT | OPTIONAL] 設定。\n1 2 3 4 5 6 7 8 9 10 -- admin 建立帳號 mysql\u0026gt; CREATE USER test@localhost IDENTIFIED BY \u0026#39;123\u0026#39; PASSWORD REQUIRE CURRENT; Query OK, 0 rows affected (0.00 sec) -- user 修改密碼 mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY \u0026#39;123\u0026#39;; ERROR 3892 (HY000): Current password needs to be specified in the REPLACE clause in order to change it. mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY \u0026#39;123\u0026#39; REPLACE \u0026#39;456\u0026#39;; Query OK, 0 rows affected (0.01 sec) PASSWORD REQUIRE CURRENT：密碼更改必須指定當前密碼。\nPASSWORD REQUIRE CURRENT OPTIONAL：密碼更改不強迫指定當前密碼。\nPASSWORD REQUIRE CURRENT DEFAUT：依照全域系統變數 password_require_current 設定。\n💡 NOTE：當 USER 具有 global create user 權限或者是在 mysql database 具有 update 權限時，則不受任何限制，意即不需要提供舊密碼。\n參考\nhttps://dev.mysql.com/doc/refman/8.0/en/password-management.html#password-reverification-policy\nhttps://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_password_require_current\n雙密碼功能 (Dual Passwords) MySQL 8.0.14 開始在帳戶管理新增了 2 個子句，用來提供雙密碼的功能，這樣就可以分階段且不需各單位配合也不需要停機的況下更換密碼。\nRETAIN CURRENT PASSWORD 將 user 當前(舊)密碼替換為第二(secondary)密碼，新的密碼則會成為主(primary)密碼。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mysql\u0026gt; CREATE USER test@localhost IDENTIFIED BY \u0026#39;123\u0026#39;; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY \u0026#39;456\u0026#39; RETAIN CURRENT PASSWORD; Query OK, 0 rows affected (0.04 sec) -- 使用 secondary(舊) 密碼登入成功 [root@localhost ~]$ mysql -utest -p123 Your MySQL connection id is 82583 Server version: 8.0.21 MySQL Community Server - GPL -- 使用 primary(新) 密碼登入成功 [root@localhost ~]$ mysql -utest -p456 Your MySQL connection id is 82584 Server version: 8.0.21 MySQL Community Server - GPL 新舊密碼為空時，無法指定 RETAIN CURRENT PASSWORD。\n1 2 3 4 5 6 7 8 9 10 11 mysql\u0026gt; CREATE USER test@localhost; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; ALTER USER test@localhost identified by \u0026#39;123\u0026#39; RETAIN CURRENT PASSWORD; ERROR 3878 (HY000): Empty password can not be retained as second password for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39;. mysql\u0026gt; ALTER USER test@localhost identified by \u0026#39;123\u0026#39;; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; ALTER USER test@localhost identified by \u0026#39;\u0026#39; RETAIN CURRENT PASSWORD; ERROR 3895 (HY000): Current password can not be retained for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39; because new password is empty. 當 user 已有第二(secondary)密碼時，在未指定 RETAIN CURRENT PASSWORD 的情況下更改主(primary)密碼，第二(secondary)密碼會維持不變。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 mysql\u0026gt; CREATE USER test@localhost IDENTIFIED BY \u0026#39;123\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY \u0026#39;456\u0026#39; RETAIN CURRENT PASSWORD; Query OK, 0 rows affected (0.00 sec) -- 此時 123 為 secondary password， 456 為 parmary password mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY \u0026#39;789\u0026#39;; Query OK, 0 rows affected (0.00 sec) -- 此時 123 為 secondary password， 789 為 parmary password -- 使用 123 登入成功 [root@localhost ~]$ mysql -utest -p123 Your MySQL connection id is 82583 Server version: 8.0.21 MySQL Community Server - GPL -- 使用 456 登入失敗 [root@localhost ~]$ mysql -utest -p456 ERROR 1045 (28000): Access denied for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) -- 使用 789 登入成功 [root@localhost ~]$ mysql -utest -p789 Your MySQL connection id is 82583 Server version: 8.0.21 MySQL Community Server - GPL mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY \u0026#39;abc\u0026#39; RETAIN CURRENT PASSWORD; Query OK, 0 rows affected (0.00 sec) -- 此時 789 為 secondary password， abc 為 parmary password 當更改身分驗證插件時，無法指定 RETAIN CURRENT PASSWORD，並且會將第二(secondary)密碼丟棄。\nDISCARD OLD PASSWORD 刪除第二(secondary)密碼。\n1 2 3 4 5 ALTER USER test@localhost DISCARD OLD PASSWORD; -- 使用 secondary password 登入 [root@localhost ~]$ mysql -utest -p123 ERROR 1045 (28000): Access denied for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) 參考\nhttps://dev.mysql.com/doc/refman/8.0/en/alter-user.html\nhttps://dev.mysql.com/doc/refman/8.0/en/password-management.html#dual-passwords\nhttps://www.percona.com/blog/using-mysql-8-dual-passwords/\n生成隨機密碼(Random Password Generation) MySQL 8.0.18 開始在設定密碼的時候可以使用 RANDOM PASSWORD 來為 USER 生成隨機密碼。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 mysql\u0026gt; CREATE USER test@localhost IDENTIFIED BY RANDOM PASSWORD; +------+-----------+----------------------+ | user | host | generated password | +------+-----------+----------------------+ | test | localhost | Oa-J)+nSI40_!TqIaYIt | +------+-----------+----------------------+ mysql\u0026gt; ALTER USER test@localhost IDENTIFIED BY RANDOM PASSWORD; +------+-----------+----------------------+ | user | host | generated password | +------+-----------+----------------------+ | test | localhost | XgtPCz\u0026gt;Sx)Yf8Sxhpg:D | +------+-----------+----------------------+ 1 row in set (0.02 sec) 生成的密碼長度由系統變數 generated_random_password_length 決定，預設值為 20。\n參考\nhttps://dev.mysql.com/doc/refman/8.0/en/password-management.html#random-password-generation\nhttps://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_generated_random_password_length\n登入失敗追蹤和帳號暫時鎖定(Failed-Login Tracking and Temporary Account Locking) MySQL 8.0.19 開始，可以設定當該帳號連續輸入錯誤的密碼時，暫時將帳號鎖定。\nFAILED_LOGIN_ATTEMPTS N：表示當連續輸入 N 次錯誤密碼時，將會觸發鎖定。 PASSWORD_LOCK_TIME {N | UNBOUNDED}：表示要鎖定 N 天，其中 UNBOUNDED 表示永久鎖定直到被解鎖。 以上 N 的允許值為 0~32767，其中 0 表示禁用，預設值皆為 0。只有當兩個 N 都不為 0 ，才能使用到此功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 建立帳號，並設定當密碼連續輸入錯誤 3次時，則會鎖定 3 天 mysql\u0026gt; CREATE USER test@localhost IDENTIFIED BY \u0026#39;123\u0026#39; -\u0026gt; FAILED_LOGIN_ATTEMPTS 3 PASSWORD_LOCK_TIME 3; Query OK, 0 rows affected (0.02 sec) [root@localhost ~]$ mysql -utest -p Enter password: ERROR 1045 (28000): Access denied for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) [root@localhost ~]$ mysql -utest -p Enter password: ERROR 1045 (28000): Access denied for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) [root@localhost ~]$ mysql -utest -p Enter password: ERROR 3955 (HY000): Access denied for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39;. Account is blocked for 3 day(s) (3 day(s) remaining) due to 3 consecutive failed logins. -- error log 2021-07-07T08:13:23.364124Z 86982 [Note] [MY-010914] [Server] Access denied for user \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39;. Account is blocked for 3 day(s) (3 day(s) remaining) due to 3 consecutive failed logins. 以下方式可以重置計數並解鎖所有帳號：\n重啟 server 執行 FLUSH PRIVILEGES 以下狀況會重置計數或解鎖個別帳號：\n成功登入\n持續鎖定的時間已過\n使用 ALTER USER 變更鎖定設定，或者是使用 ACCOUNT UNLOCK 語句。\n1 2 3 4 5 6 7 # 變更鎖定設定也會重置 mysql\u0026gt; ALTER USER test@localhost FAILED_LOGIN_ATTEMPTS 3 PASSWORD_LOCK_TIME 1; Query OK, 0 rows affected (0.02 sec) # 使用 ALTER USER ... ACCOUNT UNLOCK 解鎖 mysql\u0026gt; ALTER USER \u0026#39;test\u0026#39;@\u0026#39;localhost\u0026#39; ACCOUNT UNLOCK; Query OK, 0 rows affected (0.00 sec) 參考\nhttps://dev.mysql.com/doc/refman/8.0/en/password-management.html#failed-login-tracking\n","date":"2021-07-12T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-account-manage-new-feature/","title":"MySQL8.0 新增的帳號管理功能"},{"content":"在 MySQL 8.0.16 之前，如果我們要給予 USER 除了某個 DATABASE 以外都有權限，只能夠每個 DATABASE 都 GRANT 一次權限，這方面有時候並不是很方便。例如：總共有 100 個 DATABASE 其中只有 1 個不給予 USER 權限，我們就需要執行 99 個 GRANT 語法。\n從 MySQL 8.0.16 開始，推出了可以回收部分權限 (Partial Revokes) 的功能，將粗粒度的 GRANT 權限用 REVOKE 收回一部分細粒度權限，大大增加了這方面需求的方便性。\n展示 目標是給予 USER 除了 mysql.* 以外的所有權限，請查看以下範例：\n當 MySQL 版本低於 8.0.16 或者關閉 partial revokes 功能，我們只能逐一給予其他 DB 權限：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 -- BEFORE MySQL 8.0.16，或關閉 partial revokes 功能 mysql\u0026gt; SHOW GLOBAL VARIABLES LIKE \u0026#39;partial_revokes\u0026#39;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | partial_revokes | OFF | +-----------------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; SHOW GRANTS FOR test@localhost; +-------------------------------------------+ | Grants for test@localhost | +-------------------------------------------+ | GRANT SELECT ON *.* TO `test`@`localhost` | +-------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; REVOKE SELECT ON mysql.* FROM test@localhost; ERROR 1141 (42000): There is no such grant defined for user \u0026#39;test\u0026#39; on host \u0026#39;localhost\u0026#39; mysql\u0026gt; REVOKE SELECT ON *.* FROM test@localhost; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; GRANT SELECT ON test.* TO test@localhost; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; GRANT SELECT ON performance_schema.* TO test@localhost; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; GRANT SELECT ON sys.* TO test@localhost; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; SHOW GRANTS FOR test@localhost; +--------------------------------------------------------------+ | Grants for test@localhost | +--------------------------------------------------------------+ | GRANT USAGE ON *.* TO `test`@`localhost` | | GRANT SELECT ON `sys`.* TO `test`@`localhost` | | GRANT SELECT ON `test`.* TO `test`@`localhost` | | GRANT SELECT ON `performance_schema`.* TO `test`@`localhost` | +--------------------------------------------------------------+ 5 rows in set (0.00 sec) 當 MySQL 版本不小於 8.0.16 且開啟 partial revokes 功能，就能很方便的完成需求：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 -- AFTER MySQL 8.0.16，並開啟 partial revokes 功能 mysql\u0026gt; SET GLOBAL partial_revokes = ON; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; SHOW GLOBAL VARIABLES LIKE \u0026#39;partial_revokes\u0026#39;; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | partial_revokes | ON | +-----------------+-------+ 1 row in set (0.00 sec) mysql\u0026gt; REVOKE SELECT ON mysql.* FROM `test`@`localhost`; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; SHOW GRANTS FOR test@localhost; +----------------------------------------------------+ | Grants for test@localhost | +----------------------------------------------------+ | GRANT SELECT ON *.* TO `test`@`localhost` | | REVOKE SELECT ON `mysql`.* FROM `test`@`localhost` | +----------------------------------------------------+ 2 rows in set (0.00 sec) 參考 MySQL 文檔 - GRANT Statement\n","date":"2021-03-12T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-partial-revokes/","title":"MySQL8.0.16 新增 partial revokes 功能"},{"content":"Skip Scan Range 當查詢想要透過 index 優化時，需要遵循最左前綴的原則，意即若有 index(A,B)，查詢條件只有 A = ? 和 A = ? AND B = ? 才能吃到這個 index， B = ? 的條件則無法利用到這個 index\n從 MySQL 8.0.13 開始新增了一個優化，讓某些情況下 B = ? 的條件可以透過這個 index 優化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 CREATE TABLE t1 (id int NOT NULL AUTO_INCREMENT,f1 INT NOT NULL, f2 INT NOT NULL, PRIMARY KEY(id),KEY test(`f1`,`f2`)); INSERT INTO t1(f1,f2) VALUES(1,1), (1,2), (1,3), (1,4), (1,5),(2,1), (2,2), (2,3), (2,4), (2,5); INSERT INTO t1(f1,f2) SELECT f1, f2 + 5 FROM t1; INSERT INTO t1(f1,f2) SELECT f1, f2 + 10 FROM t1; INSERT INTO t1(f1,f2) SELECT f1, f2 + 20 FROM t1; INSERT INTO t1(f1,f2) SELECT f1, f2 + 40 FROM t1; ANALYZE TABLE t1; EXPLAIN SELECT f1, f2 FROM t1 WHERE f2 \u0026gt; 40; -- 8.0.13以上，並且skip_scan=on (default) +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------+ | 1 | SIMPLE | t1 | NULL | range | f1 | f1 | 8 | NULL | 53 | 100.00 | Using where; Using index for skip scan | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+----------------------------------------+ -- 8.0.13以下，或 skip_scan=off +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+ | 1 | SIMPLE | t1 | NULL | index | NULL | f1 | 8 | NULL | 160 | 33.33 | Using where; Using index | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+--------------------------+ 實現方式:1. 在索引前綴(f1) scan 出 distinct 值2. 對其餘索引欄位(f2)，建構subrange scan簡單來說，就是會將其轉化為多個子範圍掃描，以此範例有點類似以下查詢：\n1 2 SELECT f1, f2 FROM t1 WHERE f1 = 1 AND f2 \u0026gt; 40; SELECT f1, f2 FROM t1 WHERE f1 = 2 AND f2 \u0026gt; 40; 主要限制：\n必須是複合索引，EX：KEY(A,B,C)\n只使用了一張表\n不能有 group by 和 select distinct\n不能回表，意即 query 中的select、where 只有使用該 index(含pk) 的欄位\n參考：\nMySQL 官方文檔 MySQL WL#11322 [數據庫內核月報(2019/05)](http://mysql.taobao.org/monthly/2019/05/06/ ","date":"2021-02-26T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-skip-scan-range/","title":"MySQL8.0 skip scan range 優化"},{"content":"MySQL 從 8.0.23 開始支持在創建 user 時使用 netmask 遮罩來限制用戶的訪問範圍。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 mysql\u0026gt; SELECT @@version; +-----------+ | @@version | +-----------+ | 8.0.23 | +-----------+ 1 row in set (0.00 sec) mysql\u0026gt; create user test@\u0026#39;172.17.0.0/24\u0026#39; identified by \u0026#39;test\u0026#39;; Query OK, 0 rows affected (0.01 sec) mysql\u0026gt; select user,host from mysql.user; +------------------+---------------+ | user | host | +------------------+---------------+ | test | 172.17.0.0/24 | ... +------------------+---------------+ HOST 172.17.0.1 \u0026gt; mysql -utest -p --host 172.17.0.5 Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 20 Server version: 8.0.23 MySQL Community Server - GPL 參考 https://dev.mysql.com/doc/refman/8.0/en/account-names.html\n","date":"2021-02-26T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-user-netmask/","title":"MySQL8.0.23 user 支持 netmask 遮罩"},{"content":"Continuous Queries(CQ) 類似於 MySQL 的 Event 可以自動定期的執行 query，並將結果儲存到特定的 measurement 。\nCQ 的使用場景 採樣和數據保留：透過 CQ 和 RP 減輕儲存壓力，透過將高精度數據採樣成低精度數據，再讓 RP 將重要度不高的高精度數據 purge 掉。 預先計算昂貴的查詢：透過使用 CQ 預先將高精度數據採樣到較低精度，再使用低精度的數據查詢將花費較少的時間。 替代 HAVING 子句： InfluxDB 不支持 SQL 中的 HAVING 子句，因此可以透過 CQ 先將 GROUP BY 計算後的結果寫入另一個 measurement，隨後再透過 WHERE 條件從新的 measurement 中過濾資料。 基本 CQ 語法 1 2 3 4 CREATE CONTINUOUS QUERY \u0026lt;cq_name\u0026gt; ON \u0026lt;database_name\u0026gt; BEGIN \u0026lt;cq_query\u0026gt; END \u0026lt;cq_query\u0026gt; 1 2 3 4 5 SELECT \u0026lt;function[s]\u0026gt; INTO \u0026lt;destination_measurement\u0026gt; FROM \u0026lt;measurement\u0026gt; [WHERE \u0026lt;stuff\u0026gt;] GROUP BY time(\u0026lt;interval\u0026gt;)[,\u0026lt;tag_key[s]\u0026gt;] cq_query 內中必須要有 function、 INTO 和 GROUP BY time() 這3個要素。\nGROUP BY time() 中的 \u0026lt;interval\u0026gt; 同時也是 CQ 執行的頻率。\ncq_query 中的 WHERE 不需要時間範圍，就算寫了也會被忽略，因為 InfluxDB 會在執行時自動帶入 now() ~ now() - \u0026lt;interval\u0026gt; 的時間範圍。\nGROUP BY time() 除了 interval 也同樣可以加上 offset_interval。如下範例：\n1 2 3 4 CREATE CONTINUOUS QUERY \u0026#34;cq_cpu_average\u0026#34; ON \u0026#34;test\u0026#34; BEGIN SELECT mean(\u0026#34;loading\u0026#34;) INTO \u0026#34;cpu_average_loading\u0026#34; FROM \u0026#34;cpu\u0026#34; GROUP BY time(1h,15m) END 假設在 16:00 新增此 CQ，則將在 16:15 執行 15:15 ~ 16:14.99999999 的資料運算。\n和一般的 SELECT INTO 一樣，可以在 INTO \u0026lt;destination_measurement\u0026gt; 中使用反向引用語法 :MEASUREMEN。在 FROM 可以使用正則表達式。如下範例：\n1 2 3 4 CREATE CONTINUOUS QUERY \u0026#34;cq_average\u0026#34; ON \u0026#34;test\u0026#34; BEGIN SELECT mean(*) INTO \u0026#34;test\u0026#34;.\u0026#34;autogen\u0026#34;.:MEASUREMENT FROM /.*/ GROUP BY time(30m),* END 基本 CQ 語法不支持使用 fill() 更改不含數據的間隔之回傳值，因此當該段區間沒有資料將不寫入任何結果，可以使用進階語法處理。\nCQ 語法不會對舊有的區間執行，請手動使用 SELECT INTO 語法。\n由於當語法中未包含 GROUP BY * 時，原表的 tag 在新表將被轉換為 field，因此原本用 tag 區別的數據被 overwrite，這可能導致數據的丟失。若要保留 tag 請務必加上 GROUP BY *。\n進階 CQ 語法 1 2 3 4 5 CREATE CONTINUOUS QUERY \u0026lt;cq_name\u0026gt; ON \u0026lt;database_name\u0026gt; RESAMPLE EVERY \u0026lt;interval\u0026gt; FOR \u0026lt;interval\u0026gt; BEGIN \u0026lt;cq_query\u0026gt; END 可以看到進階 CQ 語法多了 2 個元素－\nEVERY \u0026lt;interval\u0026gt;：定義 CQ 執行的間隔。 假設 在 EVERY 中小於(\u0026lt;) GROUP BY，則每 EVERY 時間執行查詢 GROUP BY 時間範圍的資料：\n1 2 3 4 5 6 7 8 CREATE CONTINUOUS QUERY \u0026#34;cq_every\u0026#34; ON \u0026#34;test\u0026#34; RESAMPLE EVERY 30m BEGIN SELECT mean(\u0026#34;loading\u0026#34;) INTO \u0026#34;result_measurement\u0026#34; FROM \u0026#34;source_measurement\u0026#34; GROUP BY time(1h) END 當沒有 RESAMPLE EVERY 30m：\n在 8:00 執行 CQ，資料範圍 [ 7:00 , 8:00 ) 在 9:00 執行 CQ，資料範圍 [ 8:00 , 9:00 ) 當有 RESAMPLE EVERY 30m：\n在 8:00 執行 CQ，資料範圍 [ 7:00 , 8:00 ) 在 8:30 執行 CQ，資料範圍 [ 8:00 , 9:00 ) 在 9:00 執行 CQ，資料範圍 [ 8:00 , 9:00 )，由於執行出來的 time 欄位和 8:30 相同，因此會覆蓋上一次 8:30 執行 CQ 的結果。 假設 在 EVERY 中等於(=) GROUP BY，則和基本語法相同沒有任何影響。\n假設 在 EVERY 中大於(\u0026gt;) GROUP BY，則執行時間和時間範圍都以 EVERY 為主：\n1 2 3 4 5 6 7 8 CREATE CONTINUOUS QUERY \u0026#34;cq_every\u0026#34; ON \u0026#34;test\u0026#34; RESAMPLE EVERY 2h BEGIN SELECT mean(\u0026#34;loading\u0026#34;) INTO \u0026#34;result_measurement\u0026#34; FROM \u0026#34;source_measurement\u0026#34; GROUP BY time(1h) END 當沒有 RESAMPLE EVERY 2h：\n在 8:00 執行 CQ，資料範圍 [ 7:00 , 8:00 ) 在 9:00 執行 CQ，資料範圍 [ 8:00 , 9:00 ) 當有 RESAMPLE EVERY 2h：\n在 8:00 執行 CQ，資料範圍 [ 6:00 , 8:00 ) 在 10:00 執行 CQ，資料範圍 [ 8:00 , 10:00 ) FOR \u0026lt;interval\u0026gt;：定義 CQ 執行時查詢的時間範圍。 假設 在 FOR 中大於(\u0026gt;) GROUP BY，則每隔 GROUP BY 時間執行查詢 FOR 時間範圍的資料，但會以 GROUP BY 時間分組：\n1 2 3 4 5 6 7 8 CREATE CONTINUOUS QUERY \u0026#34;cq_every\u0026#34; ON \u0026#34;test\u0026#34; RESAMPLE FOR 1h BEGIN SELECT mean(\u0026#34;loading\u0026#34;) INTO \u0026#34;result_measurement\u0026#34; FROM \u0026#34;source_measurement\u0026#34; GROUP BY time(30m) END 當沒有 RESAMPLE FOR 1h：\n在 8:00 執行 CQ 資料範圍 [ 7:30 , 8:00 ) 在 8:30 執行 CQ 資料範圍 [ 8:00 , 8:30 ) 當有 RESAMPLE FOR 1h：\n在 8:00 執行 CQ 資料範圍 [ 7:00 , 8:00 )，產生 2 個 Point [ 7:00 , 7:30 ) 和 [ 7:30 , 8:00 ) 在 8:30 執行 CQ 資料範圍 [ 7:30 , 8:30 )，產生 2 個 Point [ 7:30 , 8:00 ) 和 [ 8:00 , 8:30 ) 在 9:00 執行 CQ 資料範圍 [ 8:00 , 9:00 )，產生 2 個 Point [ 8:00 , 8:30 ) 和 [ 8:30 , 9:00 ) 假設 在 FOR 中等於(=) GROUP BY，則和基本語法相同沒有任何影響。\n假設 在 FOR 中小於(\u0026lt;) GROUP BY，則不允許建立此 CQ。\nSHOW CQ 顯示所有的 CQ ，會依照 database 進行分組顯示。\n1 SHOW CONTINUOUS QUERIES DROP CQ 從一個指定的 database 刪除 CQ。\n1 DROP CONTINUOUS QUERY \u0026lt;cq_name\u0026gt; ON \u0026lt;database_name\u0026gt; 修改 CQ CQ 建立後無法修改，只能 DROP 之後重新 CREATE。\n","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/continuous-queries/","title":"InfluxDB 1.X CQ"},{"content":"InfluxDB is not CRUD 首先我們要了解到 InfluxDB 是針對時間序列數據進行優化的數據庫，並且時間序列的數據通常只會寫入一次，很少會發生更新的情境，因此 InfluxDB 沒有完整的 CRUD，官方將其稱為 CR-ud。\n相比 UPDATE 和 DELETE 更著重在 CREATE 和 READ 上，為了讓 CREATE 和 READ 性能更高， UPDATE 和 DELETE 操作有以下的限制：\n如果要 UPDATE 一個 point，只能透過 INSERT 一個具有相同 series + timestamp 的 point 不可根據 field value 刪除數據，可以先透過 READ 取得 timestamp，隨後在透過 timestamp 進行刪除。 不能夠 UPDATE 或 RENAME tags ，有關更多訊息可以參考 github 不能夠透過 tag key 刪除 tag InfluxQL (v1.x SQL LIKE) Database Manage Query Show Schema INSERT SELECT Continuous Queries 權限 FLUX (v2.0 JavaScript LIKE) 參考 Influx Query Language (InfluxQL) reference - influxdata 文檔\nExplore your schema using InfluxQL - influxdata 文檔\nManage your database - influxdata 文檔\nExplore data using InfluxQL\n","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/","title":"InfluxDB 1.X CR-ud"},{"content":"CREATE DATABASE 1 CREATE DATABASE \u0026lt;database_name\u0026gt; [WITH [DURATION \u0026lt;duration\u0026gt;] [REPLICATION \u0026lt;n\u0026gt;] [SHARD DURATION \u0026lt;duration\u0026gt;] [NAME \u0026lt;retention-policy-name\u0026gt;]] WITH 後面是可選的，用來為 database 設定 retention policy，若沒有指定則會預設為 autogen\n範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; CREATE DATABASE test \u0026gt; SHOW DATABASES name: databases name ---- _internal test \u0026gt; CREATE DATABASE test2 WITH DURATION 3d REPLICATION 1 SHARD DURATION 1h NAME \u0026#34;liquid\u0026#34; \u0026gt; SHOW DATABASES name: databases name ---- _internal test test2 DROP DATABASE 1 DROP DATABASE \u0026lt;database_name\u0026gt; USE DATABASE 1 USE \u0026lt;database_name\u0026gt; CREATE Retention policy 1 CREATE RETENTION POLICY \u0026lt;retention_policy_name\u0026gt; ON \u0026lt;database_name\u0026gt; DURATION \u0026lt;duration\u0026gt; REPLICATION \u0026lt;n\u0026gt; [SHARD DURATION \u0026lt;duration\u0026gt;] [DEFAULT] DURATION：用來定義 InfluxDB 會保存數據多久。\n格式為 int + 時間單位，此外還可以設置成 INF(infinite) 表示永久保存。\n1 2 duration_unit = \u0026#34;ns\u0026#34; | \u0026#34;u\u0026#34; | \u0026#34;µ\u0026#34; | \u0026#34;ms\u0026#34; | \u0026#34;s\u0026#34; | \u0026#34;m\u0026#34; | \u0026#34;h\u0026#34; | \u0026#34;d\u0026#34; | \u0026#34;w\u0026#34; \u0026lt;duration\u0026gt; = int duration_unit | INF duration_unit：\nREPLICATION： 數據存在 cluster 裡面的副本數量，開源單節點版本只會是 1。\nSHARD DURATION：選填，表示每個 shard group 包含的時間範圍。\n格式為 int + 時間單位，但不可以設置成 INF，最小值為 1h。\n當 1h \u0026gt; duration \u0026gt; 0s 則會自動將 改為 1h；\n當 duration = 0s 則會自動將 改為預設值。\n預設值會根據 retention policy 的 DURATITION 決定，如下圖：\nDEFAULT：選填，將此 RP 設定為 database 預設的 RP。\n範例：\n1 CREATE RETENTION POLICY \u0026#34;one_day_only\u0026#34; ON \u0026#34;NOAA_water_database\u0026#34; DURATION 23h60m REPLICATION 1 DEFAULT ALTER Retention policy 1 ALTER RETENTION POLICY \u0026lt;retention_policy_name\u0026gt; ON \u0026lt;database_name\u0026gt; [DURATION \u0026lt;duration\u0026gt;] [REPLICATION \u0026lt;n\u0026gt;] [SHARD DURATION \u0026lt;duration\u0026gt;] [DEFAULT] DURATION、 REPLICATION、 SHARD DURATION 和 DEFAULT 至少選填其中一項，未填寫的部分會保持原本的設定值。\nDROP Retention policy 刪除 RP 和該 RP 底下所有的 measurements and data\n1 DROP RETENTION POLICY \u0026lt;retention_policy_name\u0026gt; ON \u0026lt;database_name\u0026gt; CREATE Measurement 在 InfluxDB 中不需要顯式的建立 measurement，在 INSERT 數據時就會自動建立。\nDROP Measurement 1 DROP MEASUREMENT \u0026lt;measurement_name\u0026gt; DROP SERIES 刪除指定 series 的所有 Points，並將 series 從 index 中刪除\n1 DROP SERIES FROM \u0026lt;measurement_name[,measurement_name]\u0026gt; WHERE \u0026lt;tag_key\u0026gt;=\u0026#39;\u0026lt;tag_value\u0026gt;\u0026#39; 刪除單個 measurement 的所有 series 和 points\n1 \u0026gt; DROP SERIES FROM \u0026#34;test\u0026#34; 刪除單個 measurement 的特定 tag pair 的 series 和 points\n1 \u0026gt; DROP SERIES FROM \u0026#34;test\u0026#34; WHERE \u0026#34;host\u0026#34; = \u0026#39;A\u0026#39; 刪除 database 內所有擁有特定 tag pair 的 measurement 內的 series 和 points\n1 \u0026gt; DROP SERIES WHERE \u0026#34;host\u0026#34; = \u0026#39;A\u0026#39; DELETE Series 刪除指定 series 的所有 Points，但不將 series 從 index 中刪除。\n1 DELETE FROM \u0026lt;measurement_name\u0026gt; WHERE [\u0026lt;tag_key\u0026gt;=\u0026#39;\u0026lt;tag_value\u0026gt;\u0026#39;] | [\u0026lt;time interval\u0026gt;] 刪除 database 內所有小於 2020-01-01 的 Points\n1 \u0026gt; DELETE WHERE time \u0026lt; \u0026#39;2020-01-01\u0026#39; DELETE 在 FROM 的 \u0026lt;measurement_name\u0026gt; 和 WHERE 的 tag_value 都支持正則表達式。 DELETE 不支持在 WHERE 條件中以 fields 為條件。 DELETE 預設會帶入 time \u0026lt; now() 條件，因此若要刪除未來時間的資料，需要明確指定時間。 DROP Shard 1 DROP SHARD \u0026lt;shard_id_number\u0026gt; ","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/database-mange-query/","title":"InfluxDB 1.X Database Manage Query"},{"content":"Syntax 1 2 3 4 5 6 -- insert 不指定 RP INSERT \u0026lt;line protocol\u0026gt; -- insert 指定 RP INSERT INTO \u0026lt;retention policy\u0026gt; \u0026lt;line protocol\u0026gt; -- line protocol \u0026lt;line protocol\u0026gt;: \u0026lt;measurement\u0026gt;[,\u0026lt;tag_key\u0026gt;=\u0026lt;tag_value\u0026gt;[,\u0026lt;tag_key\u0026gt;=\u0026lt;tag_value\u0026gt;]] \u0026lt;field_key\u0026gt;=\u0026lt;field_value\u0026gt;[,\u0026lt;field_key\u0026gt;=\u0026lt;field_value\u0026gt;] [\u0026lt;timestamp\u0026gt;] line protocol 元素 1 2 3 4 measurementName,tagKey=tagValue fieldKey=\u0026#34;fieldValue\u0026#34; 1465839830100400200 --------------- --------------- --------------------- ------------------- | | | | | | Measurement Tag set 空格 Field set 空格 Timestamp Measurement 必填， Measurement 名稱對於大小寫是敏感的，並且不可以 _ 為開頭，此 _ 為 InfluxDB system 保留使用。 Data type: String\nTag set 選填，當有多個 Tag set 時用 , 做為區隔。 Tag set 對於大小寫是敏感的， Tag key 不可以 _ 為開頭。 Key data type: String\nValue data type: String\nField set 必填， Point 必須至少有一對 Field set，當有多個 Field set 時用 , 做為區隔。 Field keys 對於大小寫是敏感的，且不可以 _ 為開頭。 當 Field values 為 String 型態時，請使用雙引號 \u0026quot; 包起來。 Key data type: String\nValue data type: Float | Integer | UInteger | String | Boolean\nTimestamp 選填，預設使用 InfluxDB Host 的系統時間(UTC)。 為了確保 Point 上的時間為觀測到數據的時間，而不是 InfluxDB 收到的時間，因此建議總是帶入 Timestamp。 默認精度為 nanoseconds(ns)，若 insert 的時間精度不是 ns 則必須指定精度，InfluxDB 接受以下精度： nanoseconds(ns)、microseconds(us)、milliseconds(ms) 和 seconds(s)。 Data type: Unix timestamp\nLine Protocol Data types Float 此為預設的數值型態，為 IEEE-754 64-bit 的浮點數，並且 InfluxDB 支援科學記號的方式記錄\n1 2 3 myMeasurement fieldKey=1.0 myMeasurement fieldKey=1 myMeasurement fieldKey=-1.234456e+78 Integer 在數值的後方加上 i 指定其為整數型態，為 Signed 64-bit 整數。\n1 2 3 myMeasurement fieldKey=-1i myMeasurement fieldKey=12485903i myMeasurement fieldKey=-12485903i UInteger 在數值的後方加上 u 指定其為 Unsigned 的整數型態，為 Unsigned 64-bit 整數。\n1 2 myMeasurement fieldKey=1u myMeasurement fieldKey=12485903u String 字串，長度限制為 64KB\n1 2 # String measurement name, field key, and field value myMeasurement fieldKey=\u0026#34;this is a string\u0026#34; Bollean True or False，支持以下名稱：\n注意不可包含 \u0026quot; ，否則會被轉換為 string 型態\n1 2 3 4 5 6 myMeasurement fieldKey=true myMeasurement fieldKey=false myMeasurement fieldKey=t myMeasurement fieldKey=f myMeasurement fieldKey=TRUE myMeasurement fieldKey=FALSE Unix timestamp 支持的精度：nanoseconds(ns)、microseconds(us)、milliseconds(ms) 和 seconds(s)，預設為 ns。\n1 myMeasurementName fieldKey=\u0026#34;fieldValue\u0026#34; 1556813561098000000 引號(Quotes) InfluxDB 支持單雙引號，具體如下：\nField value 的 String 必須也只能使用雙引號 \u0026quot; 包起來。\nLimited 表示引號會被視為名稱的部分，範例：\n1 2 3 4 5 6 \u0026gt; insert test,\u0026#39;host\u0026#39;=\u0026#34;A\u0026#34;,host=A value=\u0026#34;test\u0026#34; \u0026gt; select * from test name: test time \u0026#39;host\u0026#39; host value ---- ------ ---- ----- 1607417652586210324 \u0026#34;A\u0026#34; A test 特殊字元與轉義 當 Strings 型態中出現特殊字元時，需要使用 \\ 進行轉義，以下特殊字元需要轉義：\n1 2 3 4 5 6 7 8 9 10 11 # Measurement 名稱中有空格 my\\ Measurement fieldKey=\u0026#34;string value\u0026#34; # field values 的 sting 中有雙引號 myMeasurement fieldKey=\u0026#34;\\\u0026#34;string\\\u0026#34; within a string\u0026#34; # Tag keys and values 名稱中有空格 myMeasurement,tag\\ Key1=tag\\ Value1,tag\\ Key2=tag\\ Value2 fieldKey=100 # Emojis 不需要轉義 myMeasurement,tagKey=🍭 fieldKey=\u0026#34;Launch 🚀\u0026#34; 1556813561098000000 註解 寫在 # 後的皆為註解，直到換行 \\n。\n1 2 # This is a comment myMeasurement fieldKey=\u0026#34;string value\u0026#34; 1556813561098000000 命名限制 Measurement names、 tag keys 和 field keys 不能以 _ 為開頭，此開頭為 InfluxDB 系統使用。\n參考 Write data to InfluxDB with insert - influxdata 文檔\nLine protocol - influxdata 文檔\nline protocol - data types and format - influxdata 文檔\n","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/insert/","title":"InfluxDB 1.X INSERT 語句"},{"content":"InfluxQL 是 SQL LIKE 語法，所以整體而言的語法很 SQL 沒有太大的區別，以下文件假定使用者了解SQL語法，因此只簡列出特別需要注意的部分。以下為目錄：\nSELECT \u0026hellip; FROM \u0026hellip; 用於從 FROM 指定的 measurement，將 SELECT 的 fields 和 tags 顯示出來。\n1 2 SELECT \u0026lt;field_key\u0026gt;[,\u0026lt;field_key\u0026gt;,\u0026lt;tag_key\u0026gt;] FROM \u0026lt;measurement_name\u0026gt;[,\u0026lt;measurement_name\u0026gt;] SELECT * 表示返回所有的 field_key tag_key。\n當需要 SELECT tag_key 時，至少需要包含一個 field_key，否則不會返回任何結果，這是有關於數據儲存方式的結果。\nSELECT \u0026quot;\u0026lt;field_key\u0026gt;\u0026quot;::field,\u0026quot;\u0026lt;tag_key\u0026gt;\u0026quot;::tag 其中 ::[field | tag] 是用來區分擁有相同名稱的 field_key 和 tag_key，當同名沒有指定 ::[field | tag] 時，預設會是顯示 field key\n範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; INSERT test,host=A host=\u0026#34;B\u0026#34;,loading=0.5 \u0026gt; SELECT * FROM test name: test time host host_1 loading ---- ---- ------ ------- 1607668578356932984 B A 0.5 \u0026gt; SELECT host,loading FROM test name: test time host loading ---- ---- ------- 1607668578356932984 B 0.5 \u0026gt; SELECT host::tag,loading FROM test name: test time host loading ---- ---- ------- 1607668578356932984 A 0.5 SELECT 不可在使用 聚合函數 時，包含 非聚合函數、field key 或 tag key。也就是相當於 MySQL 中 sql_mode 包含 ONLY_FULL_GROUP_BY 的情況。\n1 2 3 4 5 6 7 8 \u0026gt; SELECT * FROM test name: test time host loading ---- ---- ------- 1607672144573710142 A 0.5 1607672146554038115 A 0.6 \u0026gt; SELECT host,SUM(loading) FROM test ERR: mixing aggregate and non-aggregate queries is not supported FROM \u0026lt;database_name\u0026gt;.\u0026lt;retention_policy_name\u0026gt;.\u0026lt;measurement_name\u0026gt; 可以使用此方式指定到特定 database 和 retention policy 的 measurement。\nFROM \u0026lt;database_name\u0026gt;..\u0026lt;measurement_name\u0026gt; 此方式會指定到對應 database 使用 DEFAULT RP 的 measuremen。\nFROM \u0026lt;measurement_name\u0026gt;,\u0026lt;measurement_name\u0026gt; 會傳回多個 measurement 的數據。\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; INSERT test,host=A loading=0.5,extra=\u0026#34;test\u0026#34; \u0026gt; INSERT test2,host=B loading=0.5,extra2=\u0026#34;test2\u0026#34; \u0026gt; SELECT * FROM test,test2 name: test time extra extra2 host loading ---- ----- ------ ---- ------- 1607672996339840129 test A 0.5 name: test2 time extra extra2 host loading ---- ----- ------ ---- ------- 1607673009199242222 test2 B 0.5 引號的規則和 line protocol 不同，規則如下：\n' 用於 String 和 timestamp values，請勿用於標識符(database names, retention policy names, user names, measurement names, tag keys, and field keys)。 \u0026quot; 用於標識符，標識符database names, retention policy names, user names, measurement names, tag keys, and field keys)。 1 2 3 4 5 6 7 8 9 10 -- YES SELECT bikes_available FROM bikes WHERE station_id=\u0026#39;9\u0026#39; SELECT \u0026#34;bikes_available\u0026#34; FROM \u0026#34;bikes\u0026#34; WHERE \u0026#34;station_id\u0026#34;=\u0026#39;9\u0026#39; SELECT MIN(\u0026#34;avgrq-sz\u0026#34;) AS \u0026#34;min_avgrq-sz\u0026#34; FROM telegraf SELECT * from \u0026#34;cr@zy\u0026#34; where \u0026#34;p^e\u0026#34;=\u0026#39;2\u0026#39; SELECT \u0026#34;water_level\u0026#34; FROM \u0026#34;h2o_feet\u0026#34; WHERE time \u0026gt; \u0026#39;2015-08-18T23:00:01.232000000Z\u0026#39; AND time \u0026lt; \u0026#39;2015-09-19\u0026#39; -- NO SELECT \u0026#39;bikes_available\u0026#39; FROM \u0026#39;bikes\u0026#39; WHERE \u0026#39;station_id\u0026#39;=\u0026#34;9\u0026#34; SELECT * from cr@zy where p^e=\u0026#39;2\u0026#39; SELECT \u0026#34;water_level\u0026#34; FROM \u0026#34;h2o_feet\u0026#34; WHERE time \u0026gt; \u0026#34;2015-08-18T23:00:01.232000000Z\u0026#34; AND time \u0026lt; \u0026#34;2015-09-19\u0026#34; WHERE 只顯示符合 WHERE 條件的資料。\n1 SELECT ... FROM ... WHERE \u0026lt;conditional_expression\u0026gt; [(AND|OR) \u0026lt;conditional_expression\u0026gt; [...]] Fields 1 field_key \u0026lt;operator\u0026gt; [\u0026#39;string\u0026#39; | boolean | float | integer] String field value 必須使用 ' 包起來，否則不會返回數據，並起大部分時候不會返回錯誤。 operator 支援：=、 \u0026lt;\u0026gt;、!=、\u0026gt;、\u0026gt;=、\u0026lt;、\u0026lt;=、算術運算符和正則表達式。 Tags 1 tag_key \u0026lt;operator\u0026gt; [\u0026#39;tag_value\u0026#39;] tag value 必須使用 ' 包起來，否則不會返回數據，並起大部分時候不會返回錯誤。 operator 支援：=、 \u0026lt;\u0026gt;、!= 和 正則表達式。 Timestamp 預設值為 (UTC) 1677-09-21 00:12:43.145224194 ~ 2262-04-11T23:47:16.854775806Z 當包含 GROUP BY time() 時，預設值為 (UTC) 1677-09-21 00:12:43.145224194 ~ now() 不支持在 time 上使用 OR 指定多個時間範圍，對於該查詢會返回空結果。 SELECT INTO 將 SELECT 的結果寫入到 INTO 指定的 measurement\n1 SELECT_clause INTO \u0026lt;measurement_name\u0026gt; FROM_clause [WHERE_clause] [GROUP_BY_clause] 可用於 RENAME DATABASE，如下範例：\n1 SELECT * INTO \u0026#34;copy_test\u0026#34;.\u0026#34;autogen\u0026#34;.:MEASUREMENT FROM \u0026#34;test\u0026#34;.\u0026#34;autogen\u0026#34;./.*/ GROUP BY * 將 test DB 下 autogen RP 的資料寫入到 copy_test DB 下 autogen RP 。 反向引用語法 \u0026lt;:MEASUREMENT\u0026gt; 讓 copy_test DB 中 measurement 名稱引用 test DB 中的名稱。請注意在執行前必須確保 copy_test DB 及 autogen RP 存在。 若語法中未包含 GROUP BY * 在新的 measurement 中 tag 會被轉為 field。 當移動大量數據時，建議在 WHERE 條件中加入時間條件分批寫入，避免系統內存不足。 經常用於採樣，將高精度的資料透過 function 和 group by 聚合成低精度的數據。\n由於當語法中未包含 GROUP BY * 時，原表的 tag 在新表將被轉換為 field，因此原本用 tag 區別的數據被 overwrite，這可能導致數據的丟失。若要保留 tag 請務必加上 GROUP BY *。\nGROUP BY 將數據依照 GROUP BY 指定的 tag key 或 時間區間 進行分組並聚合。\ntags 1 SELECT_clause FROM_clause [WHERE_clause] GROUP BY [* | \u0026lt;tag_key\u0026gt;[,\u0026lt;tag_key]] GROUP BY * 會透過所有的 tag_key 來聚合結果。 time() 1 SELECT \u0026lt;function\u0026gt;(\u0026lt;field_key\u0026gt;) FROM_clause WHERE \u0026lt;time_range\u0026gt; GROUP BY time(\u0026lt;time_interval\u0026gt;[,\u0026lt;offset_interval\u0026gt;]),[tag_key] [fill(\u0026lt;fill_option\u0026gt;)] time(time_interval)：InfluxDB 根據 time_interval 對時間範圍進行分組，分組出來的結果包下不包上。如下範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026gt; SELECT * FROM \u0026#34;test\u0026#34; name: test -------------- time value 2015-08-18T00:00:00Z 1 2015-08-18T00:12:00Z 1 2015-08-18T00:18:00Z 1 \u0026gt; SELECT COUNT(\u0026#34;value\u0026#34;) FROM \u0026#34;test\u0026#34; GROUP BY time(12m) name: test -------------- time count 2015-08-18T00:00:00Z 1 2015-08-18T00:12:00Z 2 -- 2015-08-18T00:00:00Z： 2015-08-18T00:00:00Z \u0026lt;= time \u0026lt; 2015-08-18T00:12:00Z -- 2015-08-18T00:12:00Z： 2015-08-18T00:12:00Z \u0026lt;= time \u0026lt; 2015-08-18T00:24:00Z time_interval 的格式為 uint + time units， time units 可參考以下表格：\ntime(time_interval,offset_interval)： InfluxDB 根據 offset_interval 調整時間邊界，並根據 time_interval 對時間範圍進行分組。\noffset_interval 的格式為 int(可以為負) + time units。\n當未指定 offset_interval 時，InfluxDB會以預設的時間邊界開始分組。如下範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026gt; SELECT * FROM test name: test time host value ---- ---- ----- 2020-11-01T00:00:00Z A 0 2020-11-01T00:06:00Z A 1 2020-11-01T00:12:00Z A 2 2020-11-01T00:18:00Z A 3 2020-11-01T00:24:00Z A 4 2020-11-01T00:36:00Z A 5 -- GROUP BY time(8m)，預設從 00:00:00 開始每8分鐘為一組，COUNT 在 WHERE 時間範圍內的筆數 \u0026gt; SELECT COUNT(\u0026#34;value\u0026#34;) FROM \u0026#34;test\u0026#34; WHERE time \u0026gt;= \u0026#39;2020-11-01T00:06:00Z\u0026#39; AND time \u0026lt;= \u0026#39;2020-11-01T00:36:00Z\u0026#39; GROUP BY time(8m) name: test time count ---- ----- 2020-11-01T00:00:00Z 1 2020-11-01T00:08:00Z 1 2020-11-01T00:16:00Z 1 2020-11-01T00:24:00Z 1 2020-11-01T00:32:00Z 1 -- GROUP BY time(8m,6m)，從 00:06:00 開始每8分鐘為一組，COUNT 在 WHERE 時間範圍內的筆數 \u0026gt; SELECT COUNT(\u0026#34;value\u0026#34;) FROM \u0026#34;test\u0026#34; WHERE time \u0026gt;= \u0026#39;2020-11-01T00:06:00Z\u0026#39; AND time \u0026lt;= \u0026#39;2020-11-01T00:36:00Z\u0026#39; GROUP BY time(8m,6m) name: test time count ---- ----- 2020-11-01T00:06:00Z 2 2020-11-01T00:14:00Z 1 2020-11-01T00:22:00Z 1 2020-11-01T00:30:00Z 1 fill(\u0026lt;fill_option\u0026gt;)：選填，預設情況下當組別沒有資料時會返回 NULL，該選項用來改變當沒有資料時返回的結果。\nfill_option 有以下值－\nnull：包含該組別但值返回 NULL，此為默認值。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; SELECT MAX(\u0026#34;value\u0026#34;) FROM \u0026#34;cpu\u0026#34; GROUP BY time(1s) name: cpu time max ---- --- 1607937488000000000 1 1607937489000000000 1607937490000000000 1607937491000000000 2 1607937492000000000 3 1607937493000000000 4 numerical value：返回該數值。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; SELECT MAX(\u0026#34;value\u0026#34;) FROM \u0026#34;cpu\u0026#34; GROUP BY time(1s) fill(100) name: cpu time max ---- --- 1607937488000000000 1 1607937489000000000 100 1607937490000000000 100 1607937491000000000 2 1607937492000000000 3 1607937493000000000 4 linear： 根據 linear interpolation 顯示值。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; SELECT MAX(\u0026#34;value\u0026#34;) FROM \u0026#34;cpu\u0026#34; GROUP BY time(1s) fill(linear) name: cpu time max ---- --- 1607937488000000000 1 1607937489000000000 1.3333333333333333 1607937490000000000 1.6666666666666665 1607937491000000000 2 1607937492000000000 3 1607937493000000000 4 none：不顯示該組別。\n1 2 3 4 5 6 7 8 \u0026gt; SELECT MAX(\u0026#34;value\u0026#34;) FROM \u0026#34;cpu\u0026#34; GROUP BY time(1s) fill(none) name: cpu time max ---- --- 1607937488000000000 1 1607937491000000000 2 1607937492000000000 3 1607937493000000000 4 previous：顯示前一個組別的結果。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; SELECT MAX(\u0026#34;value\u0026#34;) FROM \u0026#34;cpu\u0026#34; GROUP BY time(1s) fill(previous) name: cpu time max ---- --- 1607937488000000000 1 1607937489000000000 1 1607937490000000000 1 1607937491000000000 2 1607937492000000000 3 1607937493000000000 4 ORDER BY time 將結果按照時間排序。\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] [GROUP_BY_clause] ORDER BY time ASC|DESC 預設使用 ASC 排序 在 influxQL 中只能用 time 排序 LIMIT and SLIMIT LIMIT LIMIT \u0026lt;N\u0026gt; 返回前 N 個 Points。\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] [GROUP_BY_clause] [ORDER_BY_clause] LIMIT \u0026lt;N\u0026gt; SLIMIT SLIMIT \u0026lt;N\u0026gt; 返回前 N 個 Series 的所有 Points，注意必須要搭配 GROUP BY 才能使用。\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] GROUP BY *[,time(\u0026lt;time_interval\u0026gt;)] [ORDER_BY_clause] SLIMIT \u0026lt;N\u0026gt; LIMIT SLIMIT 返回 N2 個 Series，每個 Series 返回 N1 個 Points\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] GROUP BY *[,time(\u0026lt;time_interval\u0026gt;)] [ORDER_BY_clause] LIMIT \u0026lt;N1\u0026gt; SLIMIT \u0026lt;N2\u0026gt; OFFSET and SOFFSET OFFSET 返回資料時，跳過前面 N 筆 Points\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] [GROUP_BY_clause] [ORDER_BY_clause] LIMIT_clause OFFSET \u0026lt;N\u0026gt; [SLIMIT_clause] SOFFSET 返回資料時，跳過前面 N 個 Series，注意必須要搭配 GROUP BY 和 SLIMIT 才能使用。\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] GROUP BY *[,time(time_interval)] [ORDER_BY_clause] [LIMIT_clause] [OFFSET_clause] SLIMIT_clause SOFFSET \u0026lt;N\u0026gt; Time Zone tz() 預設情況下 InfluxDB 返回 UTC+0 時間，可以在 SELECT 語句的末尾加上 tz('時區') ，使其將 time 的時區進行轉換。\n1 SELECT_clause [INTO_clause] FROM_clause [WHERE_clause] [GROUP_BY_clause] [ORDER_BY_clause] [LIMIT_clause] [OFFSET_clause] [SLIMIT_clause] [SOFFSET_clause] tz(\u0026#39;\u0026lt;time_zone\u0026gt;\u0026#39;) 時間格式必須採用 RFC3339 format 才會進行轉換。 \u0026lt;time_zone\u0026gt; 可參考 List of tz database time zones(WIKI) 。 參考 Explore data using InfluxQL - Influxdata 文檔\n","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/select/","title":"InfluxDB 1.X SELECT 語句"},{"content":"Show Schema SHOW DATABASE 1 SHOW \u0026lt;database_name\u0026gt; SHOW Retention policy 1 SHOW RETENTION POLICIES [ON \u0026lt;database_name\u0026gt;] ON \u0026lt;database_name\u0026gt; 雖然是選填的，但是若不帶入必須先運行 USE \u0026lt;database_name\u0026gt;。 SHOW Measurement 1 SHOW MEASUREMENTS [ON \u0026lt;database_name\u0026gt;] [WITH MEASUREMENT \u0026lt;regular_expression\u0026gt;] [WHERE \u0026lt;tag_key\u0026gt; \u0026lt;operator\u0026gt; [\u0026#39;\u0026lt;tag_value\u0026gt;\u0026#39; | \u0026lt;regular_expression\u0026gt;]] [LIMIT_clause] [OFFSET_clause] ON \u0026lt;database_name\u0026gt; 雖然是選填的，但是若不帶入必須先運行 USE \u0026lt;database_name\u0026gt;。 SHOW Series 1 SHOW SERIES [ON \u0026lt;database_name\u0026gt;] [FROM_clause] [WHERE \u0026lt;tag_key\u0026gt; \u0026lt;operator\u0026gt; [ \u0026#39;\u0026lt;tag_value\u0026gt;\u0026#39; | \u0026lt;regular_expression\u0026gt;]] [LIMIT_clause] [OFFSET_clause] ON \u0026lt;database_name\u0026gt; 雖然是選填的，但是若不帶入必須先運行 USE \u0026lt;database_name\u0026gt;。\nWHERE 條件不支持 field 判斷\nWHERE 條件中的 operator 支持 等於 =、不等於 \u0026lt;\u0026gt; OR !=、 LIKE =~、 NOT LIKE !~\nWHERE 條件中還能帶入 time 限縮，只有當條件為 time 時才可以使用 \u0026gt; \u0026lt; 。 當以時間為條件時，實際上是使用 shard 為粒度，會判斷該時間所屬哪一個 shard 以此進行篩選，所以會出現超出 time 範圍的資料，如下範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; show shards name: hour_test id database retention_policy shard_group start_time end_time expiry_time owners -- -------- ---------------- ----------- ---------- -------- ----------- ------ 50 hour_test mytest 50 2020-12-08T03:00:00Z 2020-12-08T04:00:00Z 2020-12-15T04:00:00Z 52 hour_test mytest 52 2020-12-08T04:00:00Z 2020-12-08T05:00:00Z 2020-12-15T05:00:00Z 51 hour_test mytest 51 2020-12-08T05:00:00Z 2020-12-08T06:00:00Z 2020-12-15T06:00:00Z 53 hour_test mytest 53 2020-12-08T06:00:00Z 2020-12-08T07:00:00Z 2020-12-15T07:00:00Z 54 hour_test mytest 54 2020-12-08T07:00:00Z 2020-12-08T08:00:00Z 2020-12-15T08:00:00Z \u0026gt; select * from test name: test time test_key_12 test_key_13 test_key_init value ---- ----------- ----------- ------------- ----- 1607399129788792227 0 1 1607400000000000000 12 1 1607403600000000000 13 1 \u0026gt; show series where time \u0026gt; 1607400000000000000 key --- test,test_key_12=12 test,test_key_13=13 SHOW Tag Keys 1 SHOW TAG KEYS [ON \u0026lt;database_name\u0026gt;] [FROM_clause] [WHERE \u0026lt;tag_key\u0026gt; \u0026lt;operator\u0026gt; [\u0026#39;\u0026lt;tag_value\u0026gt;\u0026#39; | \u0026lt;regular_expression\u0026gt;]] [LIMIT_clause] [OFFSET_clause] ON \u0026lt;database_name\u0026gt; 雖然是選填的，但是若不帶入必須先運行 USE \u0026lt;database_name\u0026gt;。 WHERE 條件不支持 field 判斷 WHERE 條件中的 operator 支持 等於 =、不等於 \u0026lt;\u0026gt; OR !=、 LIKE =~、 NOT LIKE !~ WHERE 條件中還能帶入 time 限縮，只有當條件為 time 時才可以使用 \u0026gt; \u0026lt; 。 當以時間為條件時，實際上是使用 shard 為粒度，會判斷該時間所屬哪一個 shard 以此進行篩選，所以會出現超出 time 範圍的資料。 SHOW Tag Values 1 SHOW TAG VALUES [ON \u0026lt;database_name\u0026gt;][FROM_clause] WITH KEY [ [\u0026lt;operator\u0026gt; \u0026#34;\u0026lt;tag_key\u0026gt;\u0026#34; | \u0026lt;regular_expression\u0026gt;] | [IN (\u0026#34;\u0026lt;tag_key1\u0026gt;\u0026#34;,\u0026#34;\u0026lt;tag_key2\u0026#34;)]] [WHERE \u0026lt;tag_key\u0026gt; \u0026lt;operator\u0026gt; [\u0026#39;\u0026lt;tag_value\u0026gt;\u0026#39; | \u0026lt;regular_expression\u0026gt;]] [LIMIT_clause] [OFFSET_clause] ON \u0026lt;database_name\u0026gt; 雖然是選填的，但是若不帶入必須先運行 USE \u0026lt;database_name\u0026gt;。\nWHERE 條件不支持 field 判斷\nWITH 和 WHERE 條件中 operator 支持 等於 =、不等於 \u0026lt;\u0026gt; OR !=、 LIKE =~、 NOT LIKE !~\nWITH 為必填支援指定的 tag_key、正則表達式和多個 tag_key (IN)\n1 2 3 4 5 6 7 8 \u0026gt; SHOW TAG VALUES ON \u0026#34;NOAA_water_database\u0026#34; WITH KEY IN (\u0026#34;location\u0026#34;,\u0026#34;randtag\u0026#34;) WHERE \u0026#34;randtag\u0026#34; =~ /./ LIMIT 3 name: h2o_quality key value --- ----- location coyote_creek location santa_monica randtag\t1 WHERE 條件中還能帶入 time 限縮，只有當條件為 time 時才可以使用 \u0026gt; \u0026lt; 。 當以時間為條件時，實際上是使用 shard 為粒度，會判斷該時間所屬哪一個 shard 以此進行篩選，所以會出現超出 time 範圍的資料。\nSHOW Field Keys 1 SHOW FIELD KEYS [ON \u0026lt;database_name\u0026gt;] [FROM \u0026lt;measurement_name\u0026gt;] ON \u0026lt;database_name\u0026gt; 雖然是選填的，但是若不帶入必須先運行 USE \u0026lt;database_name\u0026gt;。\nWHERE 條件中還能帶入 time 限縮，只有當條件為 time 時才可以使用 \u0026gt; \u0026lt; 。 當以時間為條件時，實際上是使用 shard 為粒度，會判斷該時間所屬哪一個 shard 以此進行篩選，所以會出現超出 time 範圍的資料。\nField Values 在不同的 shard 允許不同的資料型態，因此 SHOW FIELD KEYS 會返回所有的資料型態，如下範例：\n1 2 3 4 5 6 7 8 9 \u0026gt; SHOW FIELD KEYS FROM cpu name: cpu fieldKey fieldType -------- --------- all_the_types integer all_the_types float all_the_types string all_the_types boolean ","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/show-schema/","title":"InfluxDB 1.X show schema"},{"content":"權限 開啟驗證 建立 admin 帳號\n1 CREATE USER \u0026lt;username\u0026gt; WITH PASSWORD \u0026#39;\u0026lt;password\u0026gt;\u0026#39; WITH ALL PRIVILEGES 調整設定檔\n預設情況下是沒有開啟驗證的，需要先到設定檔/etc/influxdb/influxdb.conf 將 [http] 底下的 auth-enabled 測定為 true\n1 2 3 4 ... [http] auth-enabled = true ... 重啟\n1 systemctl restart influxdb 登入方式 HTTP API 當使用 HTTP API 時，有以下兩種登入方式。\n查詢時，加入 -u \u0026lt;username\u0026gt;:\u0026lt;password\u0026gt; 進行驗證，此為推薦的方式。 1 curl -G http://localhost:8086/query -u root:root --data-urlencode \u0026#34;q=SHOW DATABASES\u0026#34; 查詢時，加入 --data-urlencode \u0026quot;u=\u0026lt;username\u0026gt;\u0026quot; --data-urlencode \u0026quot;p=\u0026lt;password\u0026gt;\u0026quot; 進行驗證。 1 curl -G http://localhost:8086/query --data-urlencode \u0026#34;u=root\u0026#34; --data-urlencode \u0026#34;p=root\u0026#34; --data-urlencode \u0026#34;q=SHOW DATABASES\u0026#34; CLI 當使用 CLI 時，有以下三種登入方式。\n設置環境變數後，直接登入。 1 2 3 export INFLUX_USERNAME=root export INFLUX_PASSWORD=root influx 登入時使用 -username 和 -password 選項帶入帳號密碼。 1 influx -username root -password root 進入 influxdb 後，使用 auth 指令驗證。 1 2 3 4 5 6 [root@localhost lib]# influx Connected to http://localhost:8086 version 1.8.3 InfluxDB shell version: 1.8.3 \u0026gt; auth username: root password: 權限管理 權限 總共有以下四種權限－\nALL PRIVILEGES： admin 權限。 READ ON \u0026lt;database_name\u0026gt;：對 \u0026lt;database_name\u0026gt; 有 SELECT、SHOW 權限。 WRITE ON \u0026lt;database_name\u0026gt;：對 \u0026lt;database_name\u0026gt; 有 INSERT 權限。 ALL ON \u0026lt;database_name\u0026gt;：對 \u0026lt;database_name\u0026gt; 有 INSERT、SELECT 和 SHOW 權限。 指令 顯示所有 USER\n1 SHOW USERS 建立 USER\n當 \u0026lt;username\u0026gt; 包含保留字、特殊符號或數字開頭時，必須使用 \u0026quot; 包起來。\n\u0026lt;password\u0026gt; 必須使用 ' 包起來，當包含 ' 或 換行符號時，需使用 / 轉譯。\n1 2 3 4 5 -- 建立 admin user CREATE USER \u0026#34;\u0026lt;username\u0026gt;\u0026#34; WITH PASSWORD \u0026#39;\u0026lt;password\u0026gt;\u0026#39; WITH ALL PRIVILEGES -- 建立非 admin user CREATE USER \u0026#34;\u0026lt;username\u0026gt;\u0026#34; WITH PASSWORD \u0026#39;\u0026lt;password\u0026gt;\u0026#39; 刪除 USER\n1 DROP USER \u0026lt;username\u0026gt; 給予權限\n1 2 3 4 5 -- 新增 admin 權限 GRANT ALL PRIVILEGES TO \u0026lt;username\u0026gt; -- 新增 非admin 權限 GRANT [READ,WRITE,ALL] ON \u0026lt;database_name\u0026gt; TO \u0026lt;username\u0026gt; 顯示 USER 權限\n1 SHOW GRANTS FOR \u0026lt;user_name\u0026gt; 移除權限\n1 2 3 4 5 -- 移除 admin 權限 REVOKE ALL PRIVILEGES FROM \u0026lt;username\u0026gt; -- 移除 非admin 權限 REVOKE [READ,WRITE,ALL] ON \u0026lt;database_name\u0026gt; FROM \u0026lt;username\u0026gt; 重設密碼\n1 SET PASSWORD FOR \u0026lt;username\u0026gt; = \u0026#39;\u0026lt;password\u0026gt;\u0026#39; 參考 Authentication and authorization in InfluxDB - influxdata 文檔\n","date":"2021-01-22T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-1-cr-ud/privilege/","title":"InfluxDB 1.X 權限管理"},{"content":"InfluxDB 儲存引擎是 TSM 主要是根據 LSM 優化而來的\n目錄與檔案結構 InfluxDB 的資料夾下，大略是以下結構：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /var/lib/influxdb |-- data | |-- test | |-- _series | | |-- 00 | | | `-- 0000 | `-- autogen | `-- 140 | |-- 000000002-000000003.tsm | `-- fields.idx |-- meta | `-- meta.db `-- wal |-- test `-- autogen `-- 140 `-- _00004.wal 每一個 shard(如：140) 都會有一個自己的資料夾，資料夾下包含以下資料：\ndata #####.tsm：實際儲存數據的文件。 #####.tombstone：紀錄刪除的數據，當 TSM Files 重寫壓縮刪除了數據後，會將此檔案刪除。 fields.idx：存放 fields 的 metadata。 meta meta.db：用來儲存 InfluxDB 的 metadata，包括 users、databases 、 retention policies、shards 和 continuous queries。 wal #####.wal：數據寫入時，會先 appended 到 WAL 文件避免數據丟失。 當 Compact 到 TSM Files 後，會刪除對應的 WAL 文件釋放空間。 TSM 組件 WAL (Write Ahead Log) 一種專門針對寫入優化的儲存格式，寫入時是將資料 append 到 WAL File，透過順序寫入 Disk 的方式，大幅提升數據寫入的性能 ，但也因此犧牲了讀取的性能。\n寫入資料時，除了寫入 Cache 還會寫入 WAL 確保數據不會丟失，用途類似於 MySQL 的 binlog 。\nWAL 被儲存成 _00001.wal 這種樣子的檔案，每當一個檔案到達 10MB 之後會再創建一個新的 WAL 文件並遞增編號，如： _00002.wal。\nCache 寫入資料時，除了寫入 WAL 還會寫入 Cache， cache 是 WAL 文件中的數據在內存中的緩存，因此可以透過重新讀取 WAL 文件，重新創建 cache 緩存。\n在查詢數據時，會將 Cache 和 TSM Files 的數據進行合併，在 Cache 中的數據優先度較高。\n和 TSM Files 不同，緩存在 cache 內的數據不會被壓縮。\ncache 有 2 個很重要的設定，每次寫入數據時都會檢查以下閾值：\n當 cache 內的資料達到 cache-snapshot-memory-size(預設25M) 所設定的大小時，會將數據寫入 TSM Files 並釋放內存空間。 當 cache 內的資料超過 cache-max-memory-size(預設1G) 設定的大小時，則會拒絕數據寫入。 此外，還有一個設定－ cache-snapshot-write-cold-duration(預設10m)，當該 shard 超過這段時間沒有收到 insert、delete 請求也會將數據寫入 TSM Files 釋放內存空間。\nTSM Files 用於存放經過壓縮的數據。\nFileStore 用來管理 TSM Files，並可以確保 TSM Files 再壓縮重寫時保持 atomically(原子性)。\nCompactor 負責將 TSM Files 進行優化，便於查詢和節省空間，透過以下 4 種方式：\nSnapshots：將 Cache 和 WAL 中的數據轉換為 TSM Files，來釋放 WAL segment 和 Cache 所使用的內存和磁碟空間。 Level Compactions：分為 1~4 級，會將 TSM Files 存 Snapshots 壓縮到 1級文件，再將多個 1級文件壓縮成 2級文件，直到文件達到 4級或者達到 TSM Files 的最大大小限。低級別的文件表示數據時間點較新，為了避免解壓縮耗費大量 CPU，因此使用較低的壓縮率。高級別的文件表示數據時間點較舊，因為使用的頻率降低，所以使用較高的壓縮率。 Index Optimization：當積累了許多 4 級 TSM Files 時， 內部索引越來越大，造成搜尋的成本增加，透過將相同 series 的 points 拆分到一組新的 TSM Files，讓同一個 series ，避免同一個 series 的資料需要跨越多個 TSM Files 來查詢。 Full Compaction：當該 shard 已經變成冷數據，或者 shard 上出現了 delete 操作 ，會執行包括 Level Compactions 和 Index Optimization 的所有優化，以此產生最佳的 TSM Files，除非該 shard 有心的 insert、delete ，否則不會再執行其他 compaction。 Compaction Planner 決定哪些 TSM Files 可以進行壓縮，並確保多個併發的 Compactor 不會互相影響。\nCompression 根據不同的資料型態對資料進行壓縮和解碼。\n資料流 INSERT INSERT 操作會被 appended 到當前的 WAL segment，並且也會被寫到 cache 中。\n當 WAL segment 達到 10MB 之後，會關閉並建立一個新的 WAL segment。 當 WAL segment 被關閉後，則會執行 Snapshots 將資料寫入 TSM Files 並且 fsync 到硬碟上，隨後讓 FilsStore 進行加載和引用。 當 cache 內緩存的數據量達到 cache-snapshot-memory-size 時，也會啟動 Snapshots。 當 cache 內緩存的數據量進一步達到 cache-max-memory-size 時，則會拒絕寫入直到 Snapshots 線程將 cache 釋放。 UPDATE 針對已經寫入的 Points 寫入新的值，在 InfluxDB 中等同於 INSERT 操作，較新寫入的值具有優先權會覆蓋舊的值。\nDELETE DELETE 在 WAL segment 寫入之後，會更新 Cache 和 FileStore 來進行刪除。\n刪除 Cache 內的相關數據。 FileStore 會在 TSM 資料夾下建立 .tombstone 檔案，當從 TSM Files 查詢數據時會比對 .tombston 的數據來過濾刪除的數據。 當觸發 Compactor 重寫壓縮 TSM Files 時，會透過 .tombstone 讓刪除的數據不再寫入新的 TSM Files，達成真正刪除數據的動作。 SELECT SELECT 操作透過 FileStore 和 Cache 讀取資料。\nCache 中的值因為較新，所以會 overlaid(覆蓋) 在 FileStore 返回的值上。 參考 In-memory indexing and the Time-Structured Merge Tree (TSM) - influxdata 文檔\ninfluxdb/tsdb/engine/tsm1/DESIGN.md - github\nLSM Tree 学习笔记 - fatedier blog\nInfluxDB详解之TSM存储引擎解析（一） - fatedier blog\nInfluxDB详解之TSM存储引擎解析（二） - fatedier blog\n","date":"2021-01-18T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-introduction-3/","title":"InfluxDB 簡介 - 3"},{"content":"InfluxDB 核心術語 Database 對應 SQL 中的 database。不同的 database 資料存放在不同目錄。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- influxDB \u0026gt; create database test; \u0026gt; show databases; name: databases name ---- _internal test \u0026gt; use test; Using database test -- linux root@e6c0eae8a31f:/var/lib/influxdb/data# ls -l total 0 drwx------ 4 root root 36 Nov 3 02:49 _internal drwx------ 4 root root 36 Nov 13 10:05 test Retention Policy 用來設定數據保留策略，過期的數據會被刪除。包含以下三個元素－\nduration：用來描述 influxDB 會保存數據多久。 replication factor：數據存在 cluster 裡面的副本數量，開源版本只會是 1。 shard (group) duration：表示一個 shard (group) 跨越了多少的時間。 範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 -- autogen 為默認的保留策略，數據保留時間為永久 \u0026gt; show retention policies; name duration shardGroupDuration replicaN default ---- -------- ------------------ -------- ------- autogen 0s 168h0m0s 1 true \u0026gt; show shards name: test id database retention_policy shard_group start_time end_time expiry_time owners -- -------- --------------- ----------- ---------- -------- ----------- ------ 12 test autogen 12 2020-11-09T00:00:00Z 2020-11-16T00:00:00Z 2020-11-16T00:00:00Z 16 test autogen 16 2020-11-16T00:00:00Z 2020-11-23T00:00:00Z 2020-11-23T00:00:00Z 24 test autogen 24 2020-11-23T00:00:00Z 2020-11-30T00:00:00Z 2020-11-30T00:00:00Z 32 test autogen 32 2020-11-30T00:00:00Z 2020-12-07T00:00:00Z 2020-12-07T00:00:00Z Shard 類似於 MySQL 的 partition 在同一個實例上將一張 table 切為多個實體檔案。\n包含實際的數據，在 disk 上儲存為 TSM 文件，每一個 shard 都包含了一個彼此不重複的時間段。\n1 2 3 4 5 6 7 8 \u0026gt; show shards name: test id database retention_policy shard_group start_time end_time expiry_time owners -- -------- --------------- ----------- ---------- -------- ----------- ------ 12 test autogen 12 2020-11-09T00:00:00Z 2020-11-16T00:00:00Z 2020-11-16T00:00:00Z 16 test autogen 16 2020-11-16T00:00:00Z 2020-11-23T00:00:00Z 2020-11-23T00:00:00Z 24 test autogen 24 2020-11-23T00:00:00Z 2020-11-30T00:00:00Z 2020-11-30T00:00:00Z 32 test autogen 32 2020-11-30T00:00:00Z 2020-12-07T00:00:00Z 2020-12-07T00:00:00Z 1 2 3 4 5 6 7 root@e6c0eae8a31f:/var/lib/influxdb# tree ./data/test/autogen test |-- autogen |-- 12 `-- 16 |-- 000000003-000000002.tsm `-- fields.idx Shard groups 類似於 Mongo 的 sharding，將同個 table 的資料分散到不同的實例上。\nshard 的 logical containers，每個 shard 都只會屬於其中一個 shard group，InfluxDB 將數據進行 hash 寫入到不同的 server，每個 server 同一個時間區間的所有shard 就屬於同一個 shard group。\n此為付費版本的 cluster 功能，開源的單實例版本無此功能。\nShard (group) duration 表示一個 shard (group) 跨越了多少的時間，可以在 retention policy 中設定。\nMeasurement 對應 SQL 中的 table，但不需要預先建立，insert 資料時自動建立。\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; show measurements \u0026gt; INSERT cpu,host=A loading=0.65 \u0026gt; show measurements name: measurements name ---- cpu \u0026gt; select * from \u0026#34;cpu\u0026#34; name: cpu time host loading ---- ---- ------- 1605592932144992788 A 0.65 Timestamp 數據關聯的時間點，在 InfluxDB 裡的所有時間都是 UTC。\nField (set) 儲存 metadata 和 真實數據。作為查詢條件不會被索引，只能全表掃描。\nfield key：和 MySQL 中沒有建立 index 的 column 概念相似。 field value：field key 所對應的值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- 除了 time 以外，還有 host 和 loading 2個欄位 \u0026gt; select * from \u0026#34;cpu\u0026#34; name: cpu time host loading ---- ---- ------- 1605592932144992788 A 0.65 \u0026gt; show field keys from cpu; name: cpu fieldKey fieldType -------- --------- loading float -- loading 是 field key -- 0.65 是 field value -- loading = 0.65 是 field set Tag (set) 選用，用於儲存常用的 metadata。作為查詢條件會被索引，查詢效率高。\nTag key：和 MySQL 中有建立 index 的 column 概念相似。 Tag value：tag key 所對應的值。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- 除了 time 以外，還有 host 和 loading 2個欄位 \u0026gt; select * from \u0026#34;cpu\u0026#34; name: cpu time host loading ---- ---- ------- 1605592932144992788 A 0.65 \u0026gt; show tag keys from cpu; name: cpu tagKey ------ host -- host 是 tag key -- A 是 tag value -- host = A 是 tag set Series 擁有相同 measurement 和 tag set 的結果集。\nseries key： 由 measurement、 tag set 和 field key 定義。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026gt; select * from cpu name: cpu time comment host loading ---- ------- ---- ------- 1605592932144992788 new A 0.65 1605592932144992788 B 0.05 1605592932144992790 next A 0.85 \u0026gt; show series from cpu key --- cpu,host=A cpu,host=B # 上述例子中有兩個 series cpu,host=A 1605592932144992788 new A 0.65 1605592932144992790 next A 0.85 cpu,host=B 1605592932144992788 B 0.05 # 上述例子中 series key 有以下4組 cpu, host=A loading cpu, host=A comment cpu, host=B loading cpu, host=B comment Point 對應 MySQL 中一個完整的 Row，由 measurement、 tag set、 field set 和 timestamp組成。\n在同一個 series 底下時，同一個 timestamp 只會有一個 point ，因此 series + timestamp 可以視為 MySQL 的 Primary key。\n若在同一個 series + timestamp INSERT 資料，field 會合併，範例如下：\nseries 為 cpu,host=A，因此在 cpu 裡面 host = A 且 time=1605592932144992788 只會有一筆紀錄。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; select * from \u0026#34;cpu\u0026#34; name: cpu time host loading ---- ---- ------- 1605592932144992788 A 0.65 \u0026gt; show series from cpu key --- cpu,host=A 新增 series 相同，但 field key 不同的資料，會發現資料合併。\n1 2 3 4 5 6 \u0026gt; INSERT cpu,host=A comment=\u0026#34;old\u0026#34; 1605592932144992788 \u0026gt; select * from cpu name: cpu time comment host loading ---- ------- ---- ------- 1605592932144992788 old A 0.65 新增 series 相同，且 field key 相同的資料，則會發現資料被覆蓋。\n1 2 3 4 5 6 7 \u0026gt; INSERT cpu,host=A loading=0.05,comment=\u0026#34;new\u0026#34; 1605592932144992788 \u0026gt; select * from cpu name: cpu time comment host loading ---- ------- ---- ------- 1605592932144992788 new A 0.05 參考 influxdata - data elements\ninfluxdata - Simplifying InfluxDB: Shards and Retention Policies\ninfluxDB shard - Go語言中文網\n","date":"2021-01-10T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-introduction-2/","title":"InfluxDB 簡介 - 2"},{"content":"時間序列數據(Time Series Data) 時間序列數據是在一段時間內重複測量取得的結果集，如 CPU 使用率隨時間的變化。\n時序數據以時間作為主要的查詢維度，將連續的多個時序數據繪製成報表，可以用於揭示背後的趨勢、規律和異常，做為預測和預警的依據。\n時序數據具有以下特性：\n不變性：因為資料是歷史數據，一旦產生就不會在異動。 唯一性：同一個時間同一個對象同一個指標，只會有一個值。 按時間排序：時間主要的座標軸，數據隨著時間順序產生。 時間序列數據分為兩種類型：\n定期收集到的 metrics(指標)，例如：監控。\n不定期收集到的 events(事件)，例如：Logs。\n時序型資料庫(Time Series Database、TSDB) TSDB 專門處理帶有 time-stamped 的 metrics(指標)、 events 這種時間序列數據的數據庫。\nTSDB 和其他資料庫的負載不同：\n平穩、持續的高併發的 INSERT 時序數據，沒有 UPDATE 操作 資料的儲存和壓縮 數據的生命週期管理 數據彙整 大範圍且大量的數據掃描 InfluxDB 由 InfluxData 使用 GO 語言開發的開源 TSDB，並提供 SQL LIKE 的查詢語言 InfluxQL，在 DB-ENGINES Ranking 時序行數據庫中排名第一。\n排名第二的 Kdb+ 則是商業軟體，只有 32 位元的免費版本可以使用，爬文說是華爾街廣泛應用於行情服務的 TSDB，以速度快著稱。\n排名第三的 Prometheus 也是開源 TSDB，則是更適合應用在監控系統的場景。\n💡 延伸閱讀： 在早期 InfluxDB 是完全開源的，後來為了維持公司運營，因而閉源了集群版本。 在 2017 的 Percona Live 上 InfluxData 做了開源數據庫商業模型正面臨危機的演講，雲服務供應商(如：AWS) 將開源項目作為 SaaS(軟體及服務) 進行營利獲取大部分的利潤，而且大部分還不回饋開源社區，被其稱為開源吸血鬼，也讓部分開源軟體修改了開源的許可方式，例如： MongoDB、 Redis、Kafka\u0026hellip;\u0026hellip; 等。\nInfluxdata 團隊還提供了一個完整的生態環境 TICK，其中除了 influxDB 還包含了其他三種軟體：\nTelegraf：數據收集器，協助收集指標的 agent，類似 pmm 中 pmm-client 的角色。 influxDB：時序數據庫，用來儲存時序數據的資料庫，類似 pmm 中 prometheus 的角色。 Chronograf：可視化 UI，用來查詢展示 influxDB 的數據，類似 pmm 中 grafana 的角色。 Kapacitor：處理和監控服務，用於處理、監控和告警時序數據的框架。 在 2020-11-10 Influxdata 發佈了 influxDB 2.0 (GA) 版本，目標是將 TICK 整合為一個整體，並提供了新的 Flux 語言用來取代 Kapacitor 原本使用的 TICKscript。\n參考 TSDB：\ninfluxdata (官方文檔 \u0026amp; blog)\ninfluxdata\ninfluxdata - What is time series data\ninfluxdata - TSDB\n中文 blog\nInfluxdb · 源码分析 · Influxdb cluster实现探究\n時間序列數據庫(TSDB) - 簡書\nInfluxDB與Prometheus用在於監控系統上的比較\n其他\nDB-ENGINES Ranking of TSDB\n开源危机：云计算厂商成为开源吸血鬼？\n时序数据库InfluxDB 2.0 alpha 发布：主推新的Flux查询语言，TICK栈将成为整体\nDolphinDB 在台湾永丰金证券的应用\n","date":"2021-01-04T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/influxdb-introduction-1/","title":"InfluxDB 簡介 - 1"},{"content":"pager 可以做到 Linux 中的 pipe(|)功能，只需要 client 端中輸入關鍵字 pager並加上 Linux shell 命令即可，若有結束只需要再次輸入 pager 即可。\n範例：透過 grep -v，在 show processlist 時過濾掉不需要看到的 user\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 mysql\u0026gt; show processlist; +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ | 1 | event_scheduler | localhost | NULL | Daemon | 62 | Waiting on empty queue | NULL | | 3 | rep | gateway:56222 | NULL | Binlog Dump | 59 | Master has sent all binlog to slave; waiting for more updates | NULL | | 4 | root | localhost | NULL | Query | 0 | starting | show processlist | +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; pager grep -v rep PAGER set to \u0026#39;grep -v rep\u0026#39; mysql\u0026gt; show processlist; +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ | 1 | event_scheduler | localhost | NULL | Daemon | 125 | Waiting on empty queue | NULL | | 4 | root | localhost | NULL | Query | 0 | starting | show processlist | +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ 3 rows in set (0.01 sec) mysql\u0026gt; pager Default pager wasn\u0026#39;t set, using stdout. 範例：透過 cat \u0026gt; /dev/null，讓查詢不顯示結果集只顯示執行結果，可以用於方便只需要單純比對查詢執行時間的情境\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 mysql\u0026gt; select * from test; +----+------+------+ | id | name | age | +----+------+------+ | 0 | C | 26 | | 1 | A | 30 | | 2 | B | 25 | +----+------+------+ 3 rows in set (0.00 sec) mysql\u0026gt; pager cat \u0026gt; /dev/null PAGER set to \u0026#39;cat \u0026gt; /dev/null\u0026#39; mysql\u0026gt; select * from test; 3 rows in set (0.00 sec) mysql\u0026gt; pager Default pager wasn\u0026#39;t set, using stdout. 範例：我們都知道 show engine innodb status 的輸出很長，這時候就可以透過 less 方便查看\n1 2 3 4 5 6 7 8 mysql\u0026gt; pager less PAGER set to \u0026#39;less\u0026#39; mysql\u0026gt; show engine innodb status\\G 1 row in set (0.00 sec) mysql\u0026gt; pager Default pager wasn\u0026#39;t set, using stdout. 範例：透過 awk 取得 Command 結果，並透過 sort 排序，最後 uniq -c去除重複並計算數量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 mysql\u0026gt; show processlist; +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ | 1 | event_scheduler | localhost | NULL | Daemon | 1024 | Waiting on empty queue | NULL | | 3 | rep | gateway:56222 | NULL | Binlog Dump | 1021 | Master has sent all binlog to slave; waiting for more updates | NULL | | 6 | root | localhost | NULL | Query | 0 | starting | show processlist | +----+-----------------+---------------+------+-------------+------+---------------------------------------------------------------+------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; pager awk -F \u0026#39;|\u0026#39; \u0026#39;{print $6}\u0026#39; | sort | uniq -c PAGER set to \u0026#39;awk -F \u0026#39;|\u0026#39; \u0026#39;{print $6}\u0026#39; | sort | uniq -c\u0026#39; mysql\u0026gt; show processlist; 3 1 Binlog Dump 1 Command 1 Daemon 1 Query 3 rows in set (0.00 sec) prompt 可以自定義 mysql 的 prompt，預設為 mysql\u0026gt; 。\n有以下方式可以設置：\n設定在 OS 層，可以使用 $() 來做命令替換：\n設定 MYSQL_PS1 環境變數\n1 export MYSQL_PS1=\u0026#34;`hostname -s` \\r:\\m:\\s [\\d] mysql\u0026gt; \u0026#34; 連線時指定\n1 mysql -u -p --prompt=\u0026#34;`hostname -s` \\r:\\m:\\s [\\d] mysql\u0026gt; \u0026#34; 透過 aliase (可以寫到 bashrc 持久化)\n1 alias mysql=\u0026#39;mysql --prompt=\u0026#34;`hostname -s` \\r:\\m:\\s [\\d] mysql\u0026gt; \u0026#34;\u0026#39; 設定在 my.cnf 中\n1 2 [mysql] (或 [client]) prompt= \u0026#34;host名稱 \\\\r:\\\\m:\\\\s [\\\\d] mysql\u0026gt;\\\\_\u0026#34; 上述的應用結果如下：\n1 2 3 [root@test-11 ~]$ mysql -uGuCi -p Enter password: test-11 01:51:17 [(none)] mysql\u0026gt; 參考 MySQL :: MySQL 8.0 Reference Manual :: 4.5.1.2 mysql Client Commands\n","date":"2020-09-20T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-client-command/","title":"MySQL Client Command"},{"content":"MySQL5.6 開始新增了 semi-join 優化了 IN (SELECT ... FROM ...)，但有相似效果的 EXISTS 及 NOT IN/EXISTS 卻沒有類似的優化，大多時候可能都必須透過其他的方式 (例如： LEFT JOIN) 來達到優化的效果，但從 8.0.16和 8.0.17 大家都能享受到優化，可以更愉快的使用這類語法囉！\n實際執行 表結構 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE TABLE `member` ( `id` int NOT NULL, `name` varchar(20) NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; INSERT INTO member VALUES(1,\u0026#39;Johnson\u0026#39;),(2,\u0026#39;John\u0026#39;),(3,\u0026#39;Son\u0026#39;); CREATE TABLE `orders` ( `id` int NOT NULL, `member_id` int NOT NULL, `amount` int NOT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; INSERT INTO orders VALUES(1,1,10),(2,2,20),(3,3,30); EXISTS 優化 8.0.16 中優化了 EXISTS 也可以吃到 IN 的 semi-join 優化！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- 5.7.* mysql\u0026gt; EXPLAIN SELECT * FROM orders WHERE EXISTS(SELECT * FROM member ); +----+-------------+--------+-------+---------+-------------+ | id | select_type | table | type | key | Extra | +----+-------------+--------+-------+---------+-------------+ | 1 | PRIMARY | orders | ALL | NULL | NULL | | 2 | SUBQUERY | member | index | PRIMARY | Using index | +----+-------------+--------+-------+---------+-------------+ 2 rows in set, 1 warning (0.00 sec) mysql\u0026gt; SHOW WARNINGS\\G *************************** 1. row *************************** Level: Note Code: 1003 Message: /* select#1 */ select `test`.`orders`.`id` AS `id`, `test`.`orders`.`member_id` AS `member_id`, `test`.`orders`.`amount` AS `amount` from `test`.`orders` where 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- 8.0.16 mysql\u0026gt; EXPLAIN SELECT * FROM orders WHERE EXISTS(SELECT * FROM member ); +----+-------------+--------+-------+---------+---------------------------------------+ | id | select_type | table | type | key | Extra | +----+-------------+--------+-------+---------+---------------------------------------+ | 1 | SIMPLE | member | index | PRIMARY | Using index; FirstMatch | | 1 | SIMPLE | orders | ALL | NULL | Using join buffer (Block Nested Loop) | +----+-------------+--------+-------+---------+---------------------------------------+ 2 rows in set, 1 warning (0.00 sec) mysql\u0026gt; SHOW WARNINGS\\G *************************** 1. row *************************** Level: Note Code: 1003 Message: /* select#1 */ select `test`.`orders`.`id` AS `id`, `test`.`orders`.`member_id` AS `member_id`, `test`.`orders`.`amount` AS `amount` from `test`.`orders` semi join (`test`.`member`) where 1 如上範例，可以注意到 8.0.16 的 EXISTS 語句不只在 EXPLAIN 中出現 semi-join 的 FirstMatch 優化，而且在 WARNINGS 中的改寫也出現 semi-join，相對的 SUBQUERY也消失了。\nNOT IN/EXISTS 優化 8.0.17 中優化了帶有 NOT 的 IN、EXISTS 可以使用 anti-join 的優化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -- 5.7.*、8.0.16 mysql\u0026gt; EXPLAIN SELECT count(*) FROM orders WHERE NOT EXISTS (SELECT * FROM member WHERE orders.member_id = member.id); +----+--------------------+--------+--------+---------+-----------------------+--------+-------------+ | id | select_type | table | type | key | ref | rows | Extra | +----+--------------------+--------+--------+---------+-----------------------+--------+-------------+ | 1 | PRIMARY | orders | ALL | NULL | NULL | 100536 | Using where | | 2 | DEPENDENT SUBQUERY | member | eq_ref | PRIMARY | test.orders.member_id | 1 | Using index | +----+--------------------+--------+--------+---------+-----------------------+--------+-------------+ 2 rows in set, 1 warning (0.00 sec) mysql\u0026gt; SHOW warnings\\G *************************** 1. row *************************** Level: Note Code: 1276 Message: Field or reference \u0026#39;test.orders.member_id\u0026#39; of SELECT #2 was resolved in SELECT #1 *************************** 2. row *************************** Level: Note Code: 1003 Message: /* select#1 */ select count(0) AS `count(*)` from `test`.`orders` where (not(exists(/* select#2 */ select 1 from `test`.`member` where (`test`.`orders`.`member_id` = `test`.`member`.`id`)))) mysql\u0026gt; SELECT count(*) FROM orders WHERE NOT EXISTS (SELECT * FROM member WHERE orders.member_id = member.id); +----------+ | count(*) | +----------+ | 99897 | +----------+ 1 row in set (0.25 sec) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 -- 8.0.17 mysql\u0026gt; EXPLAIN SELECT count(*) FROM orders WHERE NOT EXISTS (SELECT * FROM member WHERE orders.member_id = member.id); +----+--------------+-------------+--------+---------------------+-----------------------+--------+-------------------------+ | id | select_type | table | type | key | ref | rows | Extra | +----+--------------+-------------+--------+---------------------+-----------------------+--------+-------------------------+ | 1 | SIMPLE | orders | ALL | NULL | NULL | 100411 | NULL | | 1 | SIMPLE | \u0026lt;subquery2\u0026gt; | eq_ref | \u0026lt;auto_distinct_key\u0026gt; | test.orders.member_id | 1 | Using where; Not exists | | 2 | MATERIALIZED | member | index | PRIMARY | NULL | 100 | Using index | +----+--------------+-------------+--------+---------------------+-----------------------+--------+-------------------------+ 2 rows in set, 1 warning (0.00 sec) mysql\u0026gt; SHOW WARNINGS\\G *************************** 1. row *************************** Level: Note Code: 1276 Message: Field or reference \u0026#39;test.orders.member_id\u0026#39; of SELECT #2 was resolved in SELECT #1 *************************** 2. row *************************** Level: Note Code: 1003 Message: /* select#1 */ select count(0) AS `count(*)` from `test`.`orders` anti join (`test`.`member`) on((`\u0026lt;subquery2\u0026gt;`.`id` = `test`.`orders`.`member_id`)) where true mysql\u0026gt; SELECT count(*) FROM orders WHERE NOT EXISTS (SELECT * FROM member WHERE orders.member_id = member.id); +----------+ | count(*) | +----------+ | 99906 | +----------+ 1 row in set (0.03 sec) 如上範例，可以注意到 8.0.17的 NOT IN能看到 WARNING 中被改寫為 anti-join，相對的 SUBQUERY也消失了，而且還沒有可怕的 DEPENDENT SUBQUERY，執行時間上當然也有所縮短。\n結語： 本次 MySQL 8.0 針對 (NOT) IN|EXISTS 的優化方式個人認為相當的實用，並且 semi(anti)-join 還能夠搭配上 8.0 的HASH JOIN 相比過去能更大幅度的改善這類語法的效能，也不用像過去為了讓這類語法有更好的效能，用其他手段改寫導致可能犧牲一些可讀性，一舉數得真的很棒呢 😍\n延伸閱讀 semi-join(半連結)和anti-join(反連結)\n參考資料 MySQL 5.7 文檔\nMySQL 8.0 文檔\nAntijoin in MySQL8(by MySQL Server Blog)\nanti-join幾點總結(by 知乎-知數堂)\n","date":"2020-07-23T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mysql-exists-optimize/","title":"MySQL8.0 EXISTS 及 NOT IN/EXISTS 優化"},{"content":"Journaling 關於 journal 在 MongoDB 官方文檔的開頭有以下描述：\nTo provide durability in the event of a failure, MongoDB uses write ahead logging to on-disk journal files.\n可以讓我們了解 MongoDB 的 journal files 是一種預寫日誌(WAL)，作用就類似 MySQL 的 redolog ，都是為了在 DB 服務意外 crash 後恢復數據保證數據持久性的方法。\nJournaling 和 WiredTiger 儲存引擎 WiredTiger 使用 checkpoints 來\n恢復的流程大致如下：\n在 data files 中找到最後一個 checkpoint 在 journal files 中找到上一步驟中的 checkpoint 應用 journal files 中上一步驟 checkpoint 之後的操作 Journaling Process WiredTiger 會為每個 clinet 端發起的寫操作創建一個 journal record 紀錄包含內部的所有寫入操作，例如：執行了 update 操作，journal record 除了會記錄更新操作同時也會記錄相應索引的修改。\nMongoDB 設定 WiredTiger 使用內存 buffer 來儲存 journal record\nWiredTiger 會在以下情況下將 buffere 中的 journal records 寫入 disk：\n對於 replica set members (包含 primary 和 secondary)： If there are operations waiting for oplog entries. Operations that can wait for oplog entries include: forward scanning queries against the oplog read operations performed as part of causally consistent sessions 對於 secondary 在每次批量應用 oplog 之後。 當寫入操作包含 j: true 選項。 依據 storage.journal.commitIntervalMs 的設置頻率，預設為每 100 ms。 當 WiredTiger 創建一個新的 journal file 時，約為每 100MB 數據會創建一個新的 journal file。 💡 透過 serverStatus 指令中的 wiredTiger.log 資訊可以查看 WiredTiger journal 的統計資訊。 Journal file MongoDB 會在 dbPath 設定的目錄下中建立一個名為 journal 的目錄，WiredTiger 的 journal file 會在這個 journal 目錄下：\n1 2 3 4 5 ➜ ll /var/lib/mongo/journal 總計 307200 -rw------- 1 root root 104857600 7月 15 17:04 WiredTigerLog.0000000058 -rw------- 1 root root 104857600 7月 12 16:49 WiredTigerPreplog.0000000027 -rw------- 1 root root 104857600 7月 15 16:29 WiredTigerPreplog.0000000054 其中 WiredTigerLog.{序號} 是已記錄或使用中的 Journal file，而 WiredTigerPreplog.{序號} 是預先分配的 Journal file。\nWiredTiger 的 journal file 最大大小為 100MB，當超過時會建立一個新的 journal file，此外會自動刪除舊的 journal file 僅保留從上一個 checkpoint 恢復所需要的文件。\nJournal record WiredTiger 會為每個 clinet 端發起的寫操作創建一個 journal record 紀錄包含內部的所有寫入操作，例如：執行了 update 操作，journal record 除了會記錄更新操作同時也會記錄相應索引的修改。 每個 record 會有一個 unique identifier WiredTiger 的 journal record 最小有 128 bytes 的大小。 預設情況下 MongoDB 會將 WiredTiger 超過 128 bytes 的 journal record 使用 snappy 進行壓縮，這部分可以透過storage.wiredTiger.engineConfig.journalCompressor 設定不同的壓縮演算法\nOpLog MongoDB 在 primary node 上應用資料庫操作之後會將其記錄到 OpLog，之後 secondary node 會複製並應用這些操作，也就是類似於 MySQL 的 binlog。\noplog 中的每個操作都是冪等，也就是說 oplog 無論在目標 node 上應用一次或多次都會產生相同的結果。\ncluster 中的所有 node 都包含 local.oplog.rs collection 中的 oplog 副本，所以所有的 secondary node 可以向 cluster 內的任意 node 獲取 oplog。\n參考 Journal file\nJournaling — MongoDB Manual\nWiredTiger Storage Engine — MongoDB Manual\n【MongoDB】数据存储（Storage）之 日志（Journaling）_奇斯的博客-CSDN博客_wiredtiger\nOpLOG\nReplica Set Oplog — MongoDB Manual\n","date":"2020-07-20T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mongodb-oplog-journalfile/","title":"MongoDB Oplog 和 Journal File"},{"content":"mongodump、mongorestore 將 MongoDB 的資料內容導出成二進制檔案\n1 2 mongodump \u0026lt;options\u0026gt; \u0026lt;connection-string\u0026gt; mongorestore \u0026lt;options\u0026gt; \u0026lt;connection-string\u0026gt; \u0026lt;directory or file to restore\u0026gt; 可以使用以下 --uri 或者是 --host 的方式指定要連線的 MongoDB 服務，如下範例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 連線到 mongoDB instance mongodump --uri=\u0026#34;mongodb://mongodb0.example.com:27017\u0026#34; [additional options] mongodump --host=\u0026#34;mongodb0.example.com:27017\u0026#34; [additional options] mongodump --host=\u0026#34;mongodb0.example.com\u0026#34; --port=27017 [additional options] # 連線到 mongoDB replica set (優先從 primary 讀取) mongodump --uri=\u0026#34;mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017/?replicaSet=myReplicaSetName\u0026#34; [additional options] mongodump --host=\u0026#34;myReplicaSetName/mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com\u0026#34; [additional options] # 連線到 mongoDB replica set (優先從 secondary 讀取) mongodump --uri=\u0026#34;mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017/?replicaSet=myReplicaSetName\u0026amp;readPreference=secondary\u0026#34; [additional options] mongodump --host=\u0026#34;myReplicaSetName/mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017\u0026#34; --readPreference=secondary [additional options] # 連線到 mongoDB replica set (優先從 secondary 讀取，並指定 tag) mongodump --uri=\u0026#34;mongodb://mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017/?replicaSet=myReplicaSetName\u0026amp;readPreference=secondary\u0026amp;readPreferenceTags=region:east\u0026#34; [additional options] mongodump --host=\u0026#34;myReplicaSetName/mongodb0.example.com:27017,mongodb1.example.com:27017,mongodb2.example.com:27017\u0026#34; --readPreference=\u0026#39;{mode: \u0026#34;secondary\u0026#34;, tagSets: [ { \u0026#34;region\u0026#34;: \u0026#34;east\u0026#34; } ]}\u0026#39; [additional options] 行為 只能還原到相同版本的 MongoDB 服務，並且 mongodump 和 mongorestore 版本也需要相同。 預設情況下會優先連線 Primary node，可以透過 readPreference 選項來調整。 mongodump 不會 dump local database。 mongodump 不會備份 index，需要自行重建。 如果有使用 read-only views，mongodump 預設只會 dump 其 metadata，需要添加 --viewAsCollections 來匯出 view 中的數據。 mongodump 會在以下情況下 fails： 當 resharding 正在運行時。 當 reshardCollection 指令在 mongodump 操作期間執行時。 對 WiredTiger 引擎使用 mongodump 會匯出未壓縮的數據。 mongodump 會影響到 mongod 的性能，如果數據量大於系統內存 mongodump 會導致 working set 被推出內存。 mongodump 需要具有欲備份 database 的 find 權限，內建的 backup role 具有備份所有 database 的權限。 常用選項 --uri ：\n1 2 3 --uri=\u0026#34;mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]\u0026#34; mongodump --username joe --password secret1 mongodb://mongodb0.example.com:27017 --ssl --host=\u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt;, -h=\u0026lt;hostname\u0026gt;\u0026lt;:port\u0026gt;：指定要連線的 mongod。\n--readPreference=\u0026lt;string|document\u0026gt;：指定優先讀取的 node，預設值為 primary，範例如下：\nmaxStalenessSeconds：由於各種原因 secondary node 可以會落後 prmary node，該選項用來設定 secondary node 最大延遲的秒數，當 secondary 落後超過該秒數則 mongodump 停止進行讀取操作，該值必須大於等於 90。 1 2 3 4 5 # 優先讀取 secondary node --readPreference=secondary # 優先讀取 secondary 中 tag 為 region:east 的 node，允許的最大延遲為 120 --readPreference=\u0026#39;{mode: \u0026#34;secondary\u0026#34;, tagSets: [ { \u0026#34;region\u0026#34;: \u0026#34;east\u0026#34; } ], maxStalenessSeconds: 120}\u0026#39; --db=\u0026lt;database\u0026gt;, -d=\u0026lt;database\u0026gt;：指定要備份的 database，若未指定會備份 local 以外的所有 database。\n--collection=\u0026lt;collection\u0026gt;, -c=\u0026lt;collection\u0026gt;：指定要備份的 collection，若未指定會備份 database 內的所有 collection。\n--query=\u0026lt;json\u0026gt;, -q=\u0026lt;json\u0026gt;：必須搭配 --collection 選項，僅匯出符合此條件的數據，必須使用單引號 ' 將查詢文檔包起來，範例如下：\n1 mongodump -d=test -c=records -q=\u0026#39;{ \u0026#34;a\u0026#34;: { \u0026#34;$gte\u0026#34;: 3 }, \u0026#34;date\u0026#34;: { \u0026#34;$lt\u0026#34;: { \u0026#34;$date\u0026#34;: \u0026#34;2016-01-01T00:00:00.000Z\u0026#34; } } }\u0026#39; --gzip：壓縮輸出。\n--oplog：當沒有該選項時，mongodump 運行期間的寫入\n將 mongodump 運作期間產生的 oplog 一併匯出，該檔案提供了\nmongodump \u0026ndash;oplog 運行過程中 client 端運行以下指令將導致 mogodump 失敗：\nrenameCollection db.collection.renameCollection() db.collection.aggregate() with $out mongodump \u0026ndash;oplog 必須完整備份 replica set ，因此不可和 --db 及 --collection 一起使用。\n備份策略 mogodump、mongorestore 可以作為單實例、一般 cluster 的備援方案\nmongodump、mongorestore 通過與正在運行的 mongod instance 交互來運行，不僅會產生流量，還會強制資料庫透過記憶體讀取所有數據，因此會導致mongod 性能下降。\nmogodump、mongorestore 不能作為 sharding cluster 的備援方案，因為 mongodump 創建的備份不會維護跨 shard 事務的原子性保證。\n對於 sharding cluster 建議使用以下支持維護跨 shard 事務原子性保證的備援方案：\nMongoDB Atlas MongoDB Cloud Manager MongoDB Ops Manager mongoexport 可以將 MongoDB 中的數據匯出成 JSON 或 CSV 格式。\n1 mongoexport --collection=\u0026lt;coll\u0026gt; \u0026lt;options\u0026gt; \u0026lt;connection-string\u0026gt; mongoimport 將 mongoexport 或其他第三方匯出的 JSON、CSV 或 TSV 格式的數據匯入到 MongoDB。\n參考 mongodump — MongoDB Database Tools\nmongorestore — MongoDB Database Tools\nmongoexport — MongoDB Database Tools\nmongoimport — MongoDB Database Tools\nBack Up and Restore with MongoDB Tools — MongoDB Manual\nMongoDB Backup Methods — MongoDB Manual\nMongoDB的常规备份策略 - yaoxing - 博客园 (cnblogs.com)\n","date":"2020-07-15T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/mongodb-backup-restore/","title":"MongoDB 備份還原"},{"content":"在 MySQL 中透過 undo log 來實現 MVCC 的機制，但在 PG 中是將新舊數據都存放在表中，由此產生了表膨脹及 vacuum 的機制。\nMVCC 常用實現方式 一般MVCC有2种实现方法：\n写新数据时，把旧数据转移到一个单独的地方，如回滚段中，其他人读数据时，从回滚段中把旧的数据读出来，如Oracle数据库和MySQL中的innodb引擎。 写新数据时，旧数据不删除，而是把新数据插入。PostgreSQL就是使用的这种实现方法。 两种方法各有利弊，相对于第一种来说，PostgreSQL的MVCC实现方式优缺点如下：\n优点 无论事务进行了多少操作，事务回滚可以立即完成 数据可以进行很多更新，不必像Oracle和MySQL的Innodb引擎那样需要经常保证回滚段不会被用完，也不会像oracle数据库那样经常遇到“ORA-1555”错误的困扰 缺点 旧版本的数据需要清理。当然，PostgreSQL 9.x版本中已经增加了自动清理的辅助进程来定期清理 旧版本的数据可能会导致查询需要扫描的数据块增多，从而导致查询变慢 也就是說 PostgresSQL 的 MVCC 實現方式會導致表中堆積無用的舊數據導致表空間的膨脹問題，也因此需要透過定期的 vacuum 或者 auto vacuum 來釋放這些無用的舊數據占用的空間。\nvacuum 指令 支持以下選項\nFULL [ ***boolean*** ]：將表的全部內容重寫到新的 Disk 文件，也就是說能夠確實釋放所有 dead tuple 占用的空間給 OS，但是在完成操作之前不會釋放舊副本的Disk 空間，並且在這期間該表會被加上 ACCESS EXCLUSIVE LOCK 阻塞所有對該表的操作。\n備註：沒有 FULL 選項的 vacuum 只是回收空間供該表能夠重複使用，並不會將空間釋放給 OS。\n備註：類似於 MySQL OPTIMIZE TABLE。\nFREEZE [ ***boolean*** ]：選擇積極的 freezing，等同於在 vacuum_freeze_min_age、vacuum_freeze_table_age 設置為 0 時運行 vacuum。\n備註：選項 FULL 總是會積極的 freezing，因此指定 FULL 選項時無需附帶 FREEZE 選項。\nVERBOSE [ ***boolean*** ]：打印 VACUUM 期間的詳細資訊。\nANALYZE [ ***boolean*** ]：執行 cacuum 後執行 ANALYZE，也就是會更新 planner 使用的統計資訊，確保生成高效的執行計畫。類似於 MySQL 的 ANALYZE TABLE。\nDISABLE_PAGE_SKIPPING [ ***boolean*** ] ：此選項禁用 page_skpping 行為，通常只有在導致數據庫損壞的軟硬件問題時才需要使用。\nSKIP_LOCKED [ ***boolean*** ] ：指定 VACUUM 在開始處理 relation 時不等待其他衝突鎖的釋放直接跳過。\nINDEX_CLEANUP { AUTO | ON | OFF } ：默認值為 AUTO，允許 VACUUM 在適當的情況下跳過 index cleanup 階段。\nPROCESS_TOAST [ ***boolean*** ] ：此為默認行為，指定 Vacuum 應該嘗試處理對應的 TOAST 表。\n備註：使用選項 FULL 時，還需要包含此選項。\nTRUNCATE [ ***boolean*** ] ：指定 VACUUM 應該截斷表末位的空頁，並將其 Disk 空間返回給 OS。\n此為默認行為，除非 vacuum_truncate = false。\n備註：包含選項 FULL 時，此選項無效。\nPARALLEL ***integer***：指定 index vacuum、index cleanup 階段時並行縣程數量。\n此選項還受 max_parallel_maintenance_workers 限制上限，並且只有當 INDEX 大小 \u0026gt; min_parallel_index_scan_size 時，該 INDEX 才能 parallel vacuum。\n備註：不能與 FULL 選項一起指定。\n帶有 full 選項的 vacuum 可以在 pg_stat_progress_cluster 觀察進度，如果不帶有 full 選項的 vacuum 則是在 pg_stat_progress_vacuum 中觀察進度。\nAutoVacuum 簡述 PostgreSQL中的MVCC机制同时存储新旧版本的元组，对于经常更新的表来说，会造成表膨胀的情况。为了解决这个问题，PostgreSQL 引入了 VACUUM 和 ANALYZE 命令，并且引入了AutoVacuum自动清理。\n在PostgreSQL中，AutoVacuum自动清理操作包括：\n删除或重用无效元组的磁盘空间\n更新数据统计信息，保证执行计划更优\n更新visibility map，加速index-only scans\n避免XID 回卷(wraparound)造成的数据丢失\n在 PG 中 XID 是用32位无符号数来表示的，也就是说如果不引入特殊的处理，当PostgreSQL的XID 到达40亿，会造成溢出，从而新的XID 为0。而按照PostgreSQL的MVCC 机制实现，之前的事务就可以看到这个新事务创建的元组，而新事务不能看到之前事务创建的元组，这违反了事务的可见性。本文将这种现象称为XID 的回卷问题。\n備註：MySQL 為 48 位約 281 兆的量，雖然理論上會發生同樣的狀況，但實務上非常困難。\n为了实现自动清理，PostgreSQL引入了两种类型的辅助进程：\nautovacuum launcher：AutoVacuum机制的守护进程，周期性地调度autovacuum worker进程。 autovacuum worker：进行具体的自动清理工作。 相關參數 Automatic Vacuuming autovacuum (boolean)：是否啟用 auto vacuum 功能，需要啟用 track_counts (默認)，默認是開啟的，另外此參數可以 BY Table 單獨設置。\nautovacuum_max_workers (integer)：指定 auto vacuum 進程數 (不包含 launcher) 默認值為 3。\nautovacuum_naptime (integer)：設置兩次 auto vacuum 之間的間隔時間，默認值為 1min。\nautovacuum_vacuum_threshold (integer)：與 autovacuum_vacuum_scale_factor 搭配使用，默認值為 50。\nautovacuum_vacuum_scale_factor (floating point)：當一張表的 update 或 delete 的元組 (tuples) 數超過 autovacuum_vacuum_threshold + autovacuum_vacuum_scale_factor * table size 會觸發 vacuum。預設值為 0.2 (表大小的 20%)，另外此參數可以 BY Table 單獨設置。\nautovacuum_analyze_threshold (integer)：與 autovacuum_analyze_scale_factor 搭配使用，默認值為 50。\nautovacuum_analyze_scale_factor (floating point)：當一張表的 update 或 delete 的元組 (tuples) 數超過 autovacuum_analyze_threshold + autovacuum_analyze_scale_factor * table size 會觸發 ANALYZE。預設值為 0.1 (表大小的 10%)，另外此參數可以 BY Table 單獨設置。\nautovacuum_vacuum_insert_threshold (integer)：與 autovacuum_vacuum_insert_scale_factor 搭配使用，默認值為 1000。\nautovacuum_vacuum_insert_scale_factor (floating point)：當一張表 insert 指定的元組 (tuples) 數達到 autovacuum_vacuum_insert_threshold + autovacuum_vacuum_insert_scale_factor * table size 會觸發 vacuum。預設值為 0.2 (表大小的 20%)，另外此參數可以 BY Table 單獨設置。\nautovacuum_freeze_max_age (integer)：設置當 XID (pg_class .relminmxid)達到此上限值時，必須強制 vacuum 避免 XID 的 wraparound。默認值為 2 億。\n注意：即使 autovacuum 沒有開啟仍舊會觸發強制 vacuum 。\nautovacuum_multixact_freeze_max_age (integer)：設置當 multi XID (pg_class .relminmxid)上限值達到此上限值時，必須強制 vacuum 避免 XID 的 wraparound。默認值為 4 億。\n注意：即使 autovacuum 沒有開啟仍舊會觸發強制 vacuum 。\nautovacuum_vacuum_cost_limit (integer)：設置 auto vacuum 的開銷限制，默認值為 -1 表示使用 vacuum_cost_limit 的設定。開銷的計算依據 vacuum_cost_page_hit, vacuum_cost_page_miss, vacuum_cost_page_dirty 的設置。\nautovacuum_vacuum_cost_delay (floating point)：設置如過超過 autovacuum_vacuum_cost_limit 上的開銷限制，則需要延遲多少時間清理，默認值為 2 (ms)，當此設定設置為 -1 時表示依照 vacuum_cost_delay 的設定。\nRESOURCE USAGE autovacuum_work_mem (integer)：指定每個 autovacuum worker 進程使用的最大 memory 量，默認值為 -1 表示使用 maintenance_work_mem。\n建議單獨設置，因為實際最多可能會消耗 autovacuum_max_workers * autovacuum_work_mem 量的 memory，這部分和 maintenance_work_mem * max_connections 不同，因此為了更加安全的限制資源使用量應該分開設置。\nvacuum_cost_page_hit (integer)：清理一个在共享缓存中找到的缓冲区的估计代价。它表示锁住缓冲池、查找共享哈希表和扫描页内容的代价。默认值为1。\nvacuum_cost_page_miss (integer)：清理一个必须从磁盘上读取的缓冲区的代价。它表示锁住缓冲池、查找共享哈希表、从磁盘读取需要的块以及扫描其内容的代价。默认值为10。\nvacuum_cost_page_dirty (integer)：当清理修改一个之前干净的块时需要花费的估计代价。它表示再次把脏块刷出到磁盘所需要的额外I/O。默认值为20。\nvacuum_cost_limit (integer)：設置 vacuum 的開銷限制達到此設置時休眠 vacuum_cost_delay 的設置，默認值為 200。開銷的計算依據 vacuum_cost_page_hit, vacuum_cost_page_miss, vacuum_cost_page_dirty 的設置。\nvacuum_cost_delay (floating point)：如過超過 vacuum 開銷成本達到 vacuum_cost_limit 限制時需要休眠多久，默認值為 0 表示禁用基於成本計算的 delay 功能。\u0026gt; 0 表示開啟，但一般也不建議設置超過 \u0026gt; 1ms，建議可以保持默認值關閉就好。\n其他 track_counts (boolean)：是否啟用統計信息收集功能，默認是開啟的，因為 autovacuum 的 launcher 進程需要這些統計資訊。 log_autovacuum_min_duration (integer)：當 auto vacuum 運行超過該時間或因鎖衝突而退出則會記錄到 log 中，預設值為 10 (min)，若設為 -1 表示禁用。 設置建議 固定\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 vacuum_cost_delay = 0 # 以下無用 vacuum_cost_page_hit = 1 vacuum_cost_page_miss = 10 vacuum_cost_page_dirty = 20 vacuum_cost_limit = 10000 # 以上無用 autovacuum = on log_autovacuum_min_duration = 0 autovacuum_analyze_scale_factor = 0.05 autovacuum_freeze_max_age = 1200000000 autovacuum_multixact_freeze_max_age = 1400000000 autovacuum_vacuum_cost_delay=0 autovacuum_vacuum_scale_factor = 0.02 # 0.005~ 0.15 vacuum_freeze_table_age = 200000000 vacuum_multixact_freeze_table_age = 200000000 變動\n1 2 autovacuum_work_mem # min( 8G, (规格内存*1/8)/autovacuum_max_workers ) autovacuum_max_workers # max(min( 8 , CPU核数/2 ) , 5) 後記 在 PostgreSQL 中因為透過保存舊的 tuples (元組) 來實現 MVCC 機制，容易造成數據的膨脹進而導致儲存空間的消耗也可能降低查詢的效能。\n在開源社區也有持續進行討論，目前內部比較認可的方式是構建一種新的儲存格式，也就是由 *EnterpriseDB 公司主導的 zheap。\n*EnterpriseDB 公司提供基於 PostgreSQL 的企業級產品與服務廠商。\n參考 PostgreSQL: Documentation: 15: VACUUM\nPostgreSQL: Documentation: 15: 25.1. Routine Vacuuming\nPgSQL · 特性分析 · MVCC机制浅析 (taobao.org)\nPgSQL · 答疑解惑 · 表膨胀 (taobao.org)\nPgSQL · 源码分析 · AutoVacuum机制之autovacuum launcher (taobao.org)\nPgSQL · 源码分析 · AutoVacuum机制之autovacuum worker (taobao.org)\nPgSQL · 新特性解读 · undo log 存储接口（上） (taobao.org)\nPgSQL · 特性分析 · 事务ID回卷问题 (taobao.org)\nblog/20181203_01.md at master · digoal/blog · GitHub\n【Postgresql】VACUUM 垃圾回收 - 知乎 (zhihu.com)\nPostgreSQL VACUUM 之深入浅出 (一) - DBADaily - 博客园 (cnblogs.com)\nPostgreSQL 事务—MVCC_postgresql mvcc_obvious__的博客-CSDN博客\nPostgreSQL Vacuum\u0026mdash;元组删除_heap_page_obvious__的博客-CSDN博客\n","date":"2020-02-28T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/postgre-vacuum/","title":"PostgreSQL vacuum"},{"content":"pg_dump 就像 mysqldump 一樣的效果，將數據 dump 成 SQL 語句。\n備份 使用 pg_dump 來備份單個 database：\n1 /usr/bin/pg_dump test \u0026gt; test.dump 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ➜ ~ cat test.dump ... CREATE TABLE public.test ( id integer ); ALTER TABLE public.test OWNER TO postgres; COPY public.test (id) FROM stdin; 1 2 3 4 \\. ... 預設情況下 dump 出來的備份檔是以 COPY 語句來還原數據，如果需要將 copy 語法變為 insert 可以使用 column-inserts 並透過 rows-per-insert 指定一個 insert 語句包含的行數：\n1 2 3 4 5 6 7 8 9 /usr/bin/pg_dump --column-inserts --rows-per-insert 2 test \u0026gt; test.dump # test.dump 中的部分內容 INSERT INTO public.test (id) VALUES (1), (2); INSERT INTO public.test (id) VALUES (3), (4); 還原 使用 psql 來還原：\n1 2 3 4 # 建立要還原的目標 database psql --command \u0026#34;create database test_restore\u0026#34; # 還原 psql test_restore \u0026lt; test.dump 預設情況下還原遇到錯誤繼續執行，如果希望可以發生 SQL 錯誤時退出，可以使用以下方式：\n1 psql --set ON_ERROR_STOP=on dbname \u0026lt; dumpfile 如果還需要更進一步將整個還原過程視為一個 Transaction，可以透過添加 \u0026ndash;single-transaction：\n1 psql --set ON_ERROR_STOP=on --single-transaction dbname \u0026lt; dumpfile 此外還可以透過 pipeline 的方式在 pg_dump 的同時直接還原：\n1 pg_dump -h host1 dbname | psql -h host2 dbname 其他事項 pg_dump 的 User 需要對該 Table 有讀取權限。\npg_dump 一次只能備份一個 database，並且不包含 role、tablespace (因為他們屬於 cluster 範圍，而不是 database)。\npg_dump 運行時會執行 database snapshot 來達到內部一致性。\npg_dump 會和 ALTER 阻塞。\n要一次備份整個 cluster 請使用 pg_dumpall，這會 dump 所有的 database 和 cluster 範圍的數據，例如 role、tablespace。\n1 2 3 4 # 備份 pg_dumpall \u0026gt; dumpfile # 還原 psql -f dumpfile postgres 但是需要注意因為包含 cluster 範圍的數據，因此必須使用 super user 的權限。\n注意：pg_dumpall 實際上會為每個 database 調用 pg_dump，也就是不保證所有 database snapshot 是同步的。\n此外可以透過 --globals-only 選項來只有備份 cluster 範圍的數據。\n如果在 pg_dump 時使用非純文本的格式(-Fc) 時，可以使用 pg_restore 來還原。\n優點：\n可以還原到不同的 RDBMS。 可以還原到不同版本的 PostgreSQL。 缺點：\n因為等於需要運行每一個 SQL 命令來還原，因此還原速度較慢。 pg_basebackup 為 PostgreSQL 內建的物理備份工具，用於對 PostgreSQL 進行全量物理熱備份。\npg_basebackup 會在備份期間創建一個備份歷史文件，該文件會以備份時的第一個 WAL 文件為命名，例如 000000010000000000000002.00000028.backup 表示備份時第一個 WAL 名稱是 000000010000000000000002 另外的 00000028 表示其中的確切位置 (一般來說可以忽略)，以下是該檔案包含的資訊：\n1 2 3 4 5 6 7 8 9 10 11 [root@ed875d053382 pg_wal]# cat 000000010000000000000002.00000028.backup START WAL LOCATION: 0/2000028 (file 000000010000000000000002) STOP WAL LOCATION: 0/2000100 (file 000000010000000000000002) CHECKPOINT LOCATION: 0/2000060 BACKUP METHOD: streamed BACKUP FROM: primary START TIME: 2023-04-17 07:07:01 UTC LABEL: pg_basebackup base backup START TIMELINE: 1 STOP TIME: 2023-04-17 07:07:02 UTC STOP TIMELINE: 1 也就是說只需要保存包含 000000010000000000000002 之後的 WAL 就可以完整的復原。\n範例 1 pg_basebackup -P -D /var/data/backup/pg_back_$(date +\u0026#34;%F_%T\u0026#34;) 選項 -D：指定備份的目的地 -F、：指定輸出的格式 p、plain：預設值，輸出成普通文件。 t、tar：輸出為 tar 文件。 -R：創建 standy.signal 文件，並將相關的連接設置附加到 postgresql.auto.conf 中，用於便於將備份檔用於建置 replica。 -X：指定備份在備份期間中產生的 WAL。 n、none：不備份 WAL。 f、fetch：將在備份結束後收集 WAL，因此需要有足夠高的 wal_keep_size，否則可能發生所需的 wal 被回收導致備份無法使用。 s、stream：默認值，在備份的同時透過 streaming replication 持續傳輸 WAL，這將額外開一個連結來進行 WAL 的備份， -P：顯示進度。 其他事項 優點：\n缺點：只能備份整個 Instance 無法指定單表。\nContinuous archiving 與 PITR 只要是數據庫都有最基本的 Durability(持久性) 需要保證，這大部分都是透過 WAL 技術也就是日誌先行來達到，在 MySQL 中是 REDO LOG 而在 PostgreSQL 中則是 WAL (在 PG 10 之前稱為 xlog)。\n因此就像 MySQL 可以透過 xtrabackup 的物理備份加上 binlog 做後續的增量恢復，PostgreSQL 同樣可以透過 pg_basebackup 產生的全量備份加上後續的 WAL 達到增量恢復，這樣還有 point-in-time recovery 的優勢。\n設置 WAL Archining PostgreSQL 每 16 MB (預設值)就會輪換一個新的 WAL 文件，而當所有的 WAL 超過 max_wal_size 舊的 WAL 會被一一刪除 (依照 checkpoint 判斷是否不再需要對應的 WAL)，為了避免全量備份後所需的 WAL 在經過一陣子後被刪除導致整個全量備份不可用，我們需要為 WAL 設置 Archining 的方式，確保在刪除 WAL 之前有進行歸檔。\n要配置 WAL Archining 需要以下設定：\nwal_level = replica | logical archive_mode = ON arvhive_command = ‘test ! -f /mnt/server/archivedir/%f \u0026amp;\u0026amp; cp %p /mnt/server/archivedir/%f’ %f 會被替換成歸檔的 wal 文件名稱。 %p 會被替換成歸檔的 wal 路徑。 1 2 3 wal_level = replica archive_mode = ON arvhive_command = \u0026#39;test ! -f /var/data/xlog_archive/%f \u0026amp;\u0026amp; cp %p /var/data/xlog_archive/%f\u0026#39; 範例 透過 pg_basebackup 獲取全量備份\n1 pg_basebackup -P -D /var/data/backup/pg_back_$(date +\u0026#34;%F_%T\u0026#34;) 關閉 server：\n1 pg_ctl stop 對當前的實體檔案暫存，以備不時之需：\n1 cp -R /var/data/postgres/ /var/data/postgres_backup/ 備註：如果沒有足夠的空間應至少保留 pg_wal 子目錄，因為可能包含尚未 archive 的 wal 需用於稍後恢復。\n清除當前的實體檔案\n1 rm -rf /var/data/postgres/* 從 Base Backup 進行恢復，注意請使用 DB系統用戶 (postgre) 進行包含正確權限的恢復。\n1 cp -R /var/data/backup/pg_back_2023-04-13_02\\:55\\:49/* /var/data/postgres/ 如果有使用 tablespace 應該檢查 pg_tblspc 中的 symbolic link 是否正確恢復。\n移除 Base Backup 中的 pg_wal/ 下的所有文件，因為這些是當初 Base Backup 的 wal 文件可能已經過時了\n1 rm -rf /var/data/postgres/pg_wal/* 將步驟 2 中保存的未歸檔 wal 文件複製到 pg_wal\n1 cp -R /var/data/postgres_backup/pg_wal/* /var/data/postgres/pg_wal/ 在 postgresql.conf 中設置恢復相關的配置\n1 2 3 restore_command = \u0026#39;cp /var/data/xlog_archive/%f %p\u0026#39; # recovery_target_time 可以配置恢復到的時間點 # recovery_target_timeline 建立 recovery.signal 文件來觸發 restore\n1 touch recovery.signal 注意：此時還可以調整 pg_hba.conf 來防止其他 role 來連線剛恢復的 cluster。\n啟動 server\n1 pg_ctl -D /var/data/postgres -l logfile start 恢復成功後 recovery.signal 會被刪除，避免稍後意外重新進入恢復模式。\n檢查數據庫是否恢復完成，如果完成記得重新調整 pg_hba.conf 恢復其他使用者的存取。\n實例 新增一些測試資料：\n1 2 3 4 5 6 7 8 9 10 create database test; \\c test; create table test_table(id int primary key,name varchar(10)); [postgres @ test] [local]:5432] 02:53:21 \u0026gt; select * from test_table; id | name ----+------- 1 | test 2 | test2 (2 rows) 進行 Base backup：\n1 pg_basebackup -P -D /var/data/backup/pg_back_$(date +\u0026#34;%F_%T\u0026#34;) 新增增量測試資料：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 create table test_table2(id int primary key,name varchar(10)); insert into test_table values(3,\u0026#39;test3\u0026#39;),(4,\u0026#39;test4\u0026#39;); insert into test_table2 values(5,\u0026#39;test5\u0026#39;),(6,\u0026#39;test6\u0026#39;); [postgres @ test] [local]:5432] 02:57:25 \u0026gt; select * from test_table; id | name ----+------- 1 | test 2 | test2 3 | test3 4 | test4 (4 rows) Time: 0.381 ms [postgres @ test] [local]:5432] 02:57:29 \u0026gt; select * from test_table2; id | name ----+------- 5 | test5 6 | test6 (2 rows) 強制關閉 pg 服務\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [postgres@3f5b5718e08f postgres]$ ps aux| grep postgre root 801 0.0 0.1 83584 2196 pts/0 S 02:14 0:00 su postgres postgres 802 0.0 0.1 14096 2888 pts/0 S 02:14 0:00 bash postgres 1148 0.0 1.0 216872 19112 ? Ss 02:56 0:00 /usr/local/postgres/bin/postgres postgres 1150 0.0 0.0 216872 1568 ? Ss 02:56 0:00 postgres: checkpointer postgres 1151 0.0 0.1 217008 2596 ? Ss 02:56 0:00 postgres: background writer postgres 1152 0.0 0.5 216872 9720 ? Ss 02:56 0:00 postgres: walwriter postgres 1153 0.0 0.1 217428 2776 ? Ss 02:56 0:00 postgres: autovacuum launcher postgres 1154 0.0 0.0 216872 1580 ? Ss 02:56 0:00 postgres: archiver postgres 1155 0.0 0.0 67512 1756 ? Ss 02:56 0:00 postgres: stats collector postgres 1156 0.0 0.1 217428 2316 ? Ss 02:56 0:00 postgres: logical replication launcher postgres 1173 0.0 0.1 53332 1876 pts/0 R+ 02:57 0:00 ps aux postgres 1174 0.0 0.0 10696 984 pts/0 S+ 02:57 0:00 grep --color=auto postgre [postgres@3f5b5718e08f postgres]$ kill -9 postgres 備份當前實體檔案並清除\n1 2 cp -R /var/data/postgres/ /var/data/postgres_backup/ rm -rf /var/data/postgres/* 從 Base Backup 進行恢復，並清空備份中的 wal，再將原本的 wal 檔案複製過來\n1 2 3 cp -R /var/data/backup/pg_back_2023-04-13_02\\:55\\:49/* /var/data/postgres/ rm -rf /var/data/postgres/pg_wal/* cp -R /var/data/postgres_backup/pg_wal/* /var/data/postgres/pg_wal/ 配置 restore_command\n1 restore_command = \u0026#39;cp /var/data/xlog_archive/%f %p\u0026#39; 建立 recovery.signal 文件來觸發 restore\n1 touch recovery.signal 啟動並檢查\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [postgres@3f5b5718e08f postgres]$ pg_ctl -D /var/data/postgres -l logfile start [postgres@3f5b5718e08f postgres]$ psql test Timing is on. psql (14.7) Type \u0026#34;help\u0026#34; for help. [postgres @ test] [local]:5432] 03:00:30 \u0026gt; \\dt List of relations Schema | Name | Type | Owner --------+-------------+-------+---------- public | test_table | table | postgres public | test_table2 | table | postgres (2 rows) [postgres @ test] [local]:5432] 03:00:32 \u0026gt; select * from test_table; id | name ----+------- 1 | test 2 | test2 3 | test3 4 | test4 (4 rows) Time: 0.620 ms [postgres @ test] [local]:5432] 03:00:37 \u0026gt; select * from test_table2; id | name ----+------- 5 | test5 6 | test6 (2 rows) Time: 0.715 ms Point-in-time recovery 預設情況下會直接恢復到 WAL 的末尾，可以透過設置 recovery_target 相關參數來指定一個更早的停止點，達到 Point-in-time recovery。\n相關參數如下：\nrecovery_target = ’immediate’：目前只有 immediate 此設定，表示盡早結束也就是該備份結束的時間點。\nrecovery_target_name (string)：指定透過 pg_create_restore_point() 所創建的 restore point，指示恢復到此位置。\nrecovery_target_time (timestamp)：指定恢復到指定的時間戳。\n準確來說是指 WAL 中記錄\nrecovery_target_xid (string)：指定恢復到指定的 Tranasction ID，注意雖然 Transaction ID 是順序分配的，但是可能依照不同順序 commit，此設置同時也會恢復該 Transaction ID 之前 commit 但具有更大的 Transaction ID 的事務。\nrecovery_target_lsn (string)：指定恢復到指定的 LSN 位置。\nrecovery_target_inclusive (boolean)：影響當設置 recovery_target_time、 recovery_target_xid 和 recovery_target_lsn，默認值 ON 表示恢復完這些目標才停止，如果是 OFF 則表示恢復到這些設置之前就停止。\nrecovery_target_timeline (string)：指定恢復到一個 timeline 中，該值可以 timeline id 或以下特定值：\ncurrent：沿著 base backup 的 timeline 進行恢復。 latest：默認值，恢復到最新的 timeline。 recovery_target_action (enum)：指定當達到 recovery target 後的動作：\npause：默認值，表示停止 recovery 並允許查詢。\n如果 hot_standby = off，則此值行為和 shutdown 等同。\n如果在 promote 中達到 recovery target，則此值行為和 promote 等同。\npromote：表示恢復結束後 sever 將允許連接。\nshutdown：表示恢復結束後停止 server，設置此值時 recovery.singal 將不會被移除。\n備註：如果沒有設置 recovery target 相關參數，則此參數無效。\n💡 注意：recovery_target、recovery_target_name、recovery_target_time、recovery_target_xid 、recovery_target_lsn 只能夠設置其中一個，設置多個將引發錯誤。\n實做 當前資料庫的資料內容\n1 2 3 4 5 6 7 8 9 10 [postgres @ test] [local]:5432] 03:24:20 \u0026gt; select * from test; id | timeline | create_time ----+----------+---------------------------- 1 | 1 | 2023-04-19 03:07:52.695513 2 | 1 | 2023-04-19 03:08:06.031361 3 | 1 | 2023-04-19 03:08:14.686946 4 | 1 | 2023-04-19 03:15:46.191272 5 | 1 | 2023-04-19 03:20:29.690359 6 | 1 | 2023-04-19 03:24:08.854501 (6 rows) 使用 base backup 復原後調整設定檔\n1 2 3 4 5 [postgres@31650d651e1c data]$ cp -r backup/pg_back_2023-04-19_03\\:08\\:41/* postgres/ [postgres@31650d651e1c postgres]$ vim postgresql.conf recovery_target_time = \u0026#39;2023-04-19 03:20:00\u0026#39; [postgres@31650d651e1c postgres]$ touch recovery.signal 備註：可以透過 pg_waldump 確認 wal log 來確認要恢復到的位置，例如我希望恢復到 id = 5 被 insert 之前的狀況，透過 waldump 確認該 transaction 在 2023-04-19 03:20:29.690738 UTC commit，因此只要將 recovery_target_time 設置的比其小即可。\n1 2 3 4 5 6 7 8 [postgres@31650d651e1c xlog_archive]$ pg_waldump 00000001000000000000000D rmgr: Standby len (rec/tot): 50/ 50, tx: 0, lsn: 0/0D000028, prev 0/0C000358, desc: RUNNING_XACTS nextXid 748 latestCompletedXid 747 oldestRunningXid 748 rmgr: Standby len (rec/tot): 50/ 50, tx: 0, lsn: 0/0D000060, prev 0/0D000028, desc: RUNNING_XACTS nextXid 748 latestCompletedXid 747 oldestRunningXid 748 rmgr: XLOG len (rec/tot): 114/ 114, tx: 0, lsn: 0/0D000098, prev 0/0D000060, desc: CHECKPOINT_ONLINE redo 0/D000060; tli 1; prev tli 1; fpw true; xid 0:748; oid 24582; multi 1; offset 0; oldest xid 726 in DB 1; oldest multi 1 in DB 1; oldest/newest commit timestamp xid: 0/0; oldest running xid 748; online rmgr: Standby len (rec/tot): 50/ 50, tx: 0, lsn: 0/0D000110, prev 0/0D000098, desc: RUNNING_XACTS nextXid 748 latestCompletedXid 747 oldestRunningXid 748 rmgr: Heap len (rec/tot): 54/ 298, tx: 748, lsn: 0/0D000148, prev 0/0D000110, desc: INSERT off 5 flags 0x00, blkref #0: rel 1663/16384/16391 blk 0 FPW rmgr: Btree len (rec/tot): 53/ 193, tx: 748, lsn: 0/0D000278, prev 0/0D000148, desc: INSERT_LEAF off 5, blkref #0: rel 1663/16384/16394 blk 1 FPW rmgr: Transaction len (rec/tot): 34/ 34, tx: 748, lsn: 0/0D000340, prev 0/0D000278, desc: COMMIT 2023-04-19 03:20:29.690738 UTC 啟動 server\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [postgres@945f297dce73 postgres]$ pg_ctl start 2023-04-19 07:44:25.775 UTC [1828] LOG: starting point-in-time recovery to 2023-04-19 03:20:00+00 2023-04-19 07:44:25.817 UTC [1828] LOG: restored log file \u0026#34;00000001000000000000000B\u0026#34; from archive 2023-04-19 07:44:25.975 UTC [1828] LOG: redo starts at 0/B000028 2023-04-19 07:44:25.977 UTC [1828] LOG: consistent recovery state reached at 0/B000100 2023-04-19 07:44:25.977 UTC [1827] LOG: database system is ready to accept read-only connections 2023-04-19 07:44:26.008 UTC [1828] LOG: restored log file \u0026#34;00000001000000000000000C\u0026#34; from archive 2023-04-19 07:44:26.198 UTC [1828] LOG: restored log file \u0026#34;00000001000000000000000D\u0026#34; from archive 2023-04-19 07:44:26.351 UTC [1828] LOG: recovery stopping before commit of transaction 748, time 2023-04-19 03:20:29.690738+00 2023-04-19 07:44:26.351 UTC [1828] LOG: pausing at the end of recovery 2023-04-19 07:44:26.351 UTC [1828] HINT: Execute pg_wal_replay_resume() to promote. [postgres@31650d651e1c postgres]$ psql test Timing is on. psql (14.7) Type \u0026#34;help\u0026#34; for help. [postgres @ test] [local]:5432] 05:13:41 \u0026gt; select * from test; test-# ; id | timeline | create_time ----+----------+---------------------------- 1 | 1 | 2023-04-19 03:07:52.695513 2 | 1 | 2023-04-19 03:08:06.031361 3 | 1 | 2023-04-19 03:08:14.686946 4 | 1 | 2023-04-19 03:15:46.191272 timeline 想像時間旅行的科幻作品，如果從現在回到過去並改變過去發生的事件會導致未來發生改變，也就是出現了不同的時間線。\n在 PG 中也有類似的狀況，假設在 12:00 誤刪除了資料表，並在 13:00 將 PG 恢復到 11:00 的時間點並正常啟動和運作，此時會出現 2 個時間線：\n過去 11:00~13:00 產生的 WAL 恢復後從 13:00 開始產生的 WAL 如果沒有 timeline 的設計，恢復後產生的 WAL 覆蓋了過去產生的 WAL，此時如果發現決策錯誤希望回到過去的 12:00 數據庫狀態將無法做到。\n因此 PG 有了 timeline 的設計，透過保存不同 timeline 的 WAL 來讓使用者能夠自由的恢復到不同的時間線。\n新的 timeline 產生時機 PITR：設置 recovery_target 相關參數進行恢復後會出現新的 timeline。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 [postgres@31650d651e1c postgres]$ ll pg_wal/ total 32768 -rw-------. 1 postgres postgres 16777216 Apr 19 03:27 00000001000000000000000B -rw-------. 1 postgres postgres 16777216 Apr 19 03:27 00000001000000000000000C drwx------. 2 postgres postgres 80 Apr 19 03:27 archive_status # 配置 recovery_target 參數並進行 PITR [postgres@31650d651e1c postgres]$ vim postgresql.conf recovery_target_time = \u0026#39;2023-04-19 03:15:46\u0026#39; recovery_target_action = \u0026#39;promote\u0026#39; [postgres@31650d651e1c postgres]$ touch recovery.singal [postgres@31650d651e1c postgres]$ pg_ctl -l logfile restart waiting for server to shut down.... done server stopped waiting for server to start.... done server started [postgres@31650d651e1c pg_wal]$ ll total 49156 -rw-------. 1 postgres postgres 16777216 Apr 19 03:30 00000001000000000000000C -rw-------. 1 postgres postgres 16777216 Apr 19 03:30 00000002000000000000000C -rw-------. 1 postgres postgres 16777216 Apr 19 03:27 00000002000000000000000D -rw-------. 1 postgres postgres 50 Apr 19 03:30 00000002.history drwx------. 2 postgres postgres 73 Apr 19 03:30 archive_status [postgres@31650d651e1c pg_wal]$ cat 00000002.history 1 0/C0002F8 before 2023-04-19 03:15:46.192096+00 standby promote：當 standby 被 promote 成 primary 時會出現新的 timeline。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [postgres@31650d651e1c pg_wal]$ ll total 32768 -rw-------. 1 postgres postgres 16777216 Apr 19 02:00 000000010000000000000006 -rw-------. 1 postgres postgres 16777216 Apr 19 02:00 000000010000000000000007 drwx------. 2 postgres postgres 6 Apr 19 02:00 archive_status [postgres@31650d651e1c pg_wal]$ pg_ctl promote waiting for server to promote.... done server promoted [postgres@31650d651e1c pg_wal]$ ll total 49160 -rw-------. 1 postgres postgres 16777216 Apr 19 02:03 000000010000000000000006.partial -rw-------. 1 postgres postgres 16777216 Apr 19 02:03 000000020000000000000006 -rw-------. 1 postgres postgres 16777216 Apr 19 02:00 000000020000000000000007 -rw-------. 1 postgres postgres 41 Apr 19 02:03 00000002.history drwx------. 2 postgres postgres 80 Apr 19 02:03 archive_status [postgres@31650d651e1c pg_wal]$ cat 00000002.history 1\t0/A000198\tno recovery target specified timeline 實體檔案 從上一節中可以看到產生新的 timeline 時會出現後綴相同的 wal 及 history 檔案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 [postgres@31650d651e1c postgres]$ ll pg_wal/ total 32768 -rw-------. 1 postgres postgres 16777216 Apr 19 03:27 00000001000000000000000B -rw-------. 1 postgres postgres 16777216 Apr 19 03:27 00000001000000000000000C drwx------. 2 postgres postgres 80 Apr 19 03:27 archive_status # 配置 recovery_target 參數並進行 PITR [postgres@31650d651e1c postgres]$ vim postgresql.conf recovery_target_time = \u0026#39;2023-04-19 03:15:46\u0026#39; recovery_target_action = \u0026#39;promote\u0026#39; [postgres@31650d651e1c postgres]$ touch recovery.singal [postgres@31650d651e1c postgres]$ pg_ctl -l logfile restart waiting for server to shut down.... done server stopped waiting for server to start.... done server started [postgres@31650d651e1c pg_wal]$ ll total 49156 -rw-------. 1 postgres postgres 16777216 Apr 19 03:30 00000001000000000000000C -rw-------. 1 postgres postgres 16777216 Apr 19 03:30 00000002000000000000000C -rw-------. 1 postgres postgres 16777216 Apr 19 03:27 00000002000000000000000D -rw-------. 1 postgres postgres 50 Apr 19 03:30 00000002.history drwx------. 2 postgres postgres 73 Apr 19 03:30 archive_status [postgres@31650d651e1c pg_wal]$ cat 00000002.history 1 0/C0002F8 before 2023-04-19 03:15:46.192096+00 可以觀察到有一個 00000002.history 的 timeline 相關檔案，這個件紀錄了這個 timeline 從哪條 timeline 分支出來及什麼時候，這包含了以下 3 個字段：\nparentTLI：parent timeline 的 ID。 LSN：發生 timline 切換的 WAL 位置。 reason：timeline 產生的原因。 例如：\n1 2 [postgres@31650d651e1c pg_wal]$ cat 00000002.history 1\t0/A000198\tbefore 2023-4-19 12:05:00.861324+00 以上表示了 timeline 2 是基於 timeline 1 的 basebackup 透過 WAL 恢復到 0/A000198 對應 2023-4-19 12:05:00.861324+00 之前的位置。\n另外還可以注意到出現新的 timeline 的時候 WAL 檔名也有了變化：00000001000000000000000C → 00000002000000000000000C，可以觀察到前 8 碼由 00000001 變成 00000002，事實上 WAL 檔名的前 8 碼就是用來標示其所屬的 timeline id。\n參考 PostgreSQL: Documentation: 15: Chapter 26. Backup and Restore\nPostgreSQL备份恢复实现 - 知乎 (zhihu.com)\n1.pg_basebackup 介绍及使用 - www.cqdba.cn - 博客园 (cnblogs.com)\nPostgreSQL 從入門到出門 第 8 篇 備份與恢復 - 台部落 (twblogs.net)\nPostgreSQL时间线(timeline)和History File_pg history_foucus、的博客-CSDN博客\nThe Internals of PostgreSQL : Chapter 10 Base Backup \u0026amp; Point-in-Time Recovery (interdb.jp)\n","date":"2020-02-26T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/postgre-backup-restore/","title":"PostgreSQL 備份還原"},{"content":"Replication 是提供高可用及 load balance 的基礎，因此不論在哪一種 database 都是一項重要的功能。\n在不同的 Database 下對於主備 Server 都有不同的術語：\nMySQL \u0026lt; 8.0.26 MySQL \u0026gt; 8.0.26 MongoDB PostgreSQL 主 Master Source Primary Primary 備 Slave Replica Secondary Standby 在 MySQL 中透過 Server 層的 binlog 透過\n在 PG 中則是直接透過 WAL (相對於 InnoDB redo log)\nStandby (Slave) 的行為 當 server 啟動時數據目錄中包含 standby.signal 文件時，則 server 會進入 standby 模式。\n在 standby 模式下，standby 可以透過以下兩種方式來獲取並回放 Primary 上的 WAL：\nWAL Archive Streaming Replication 除此之外 Standby 還會嘗試恢復在 pg_wal 目錄中的任何 WAL。\nStandby 在啟動時會有以下行為：\n調用 restore_command 進行恢復。 當步驟1 達到 WAL 末尾且恢復失敗，則將嘗試恢復 pg_wal 目錄中可用的 WAL。 當步驟2失敗，且配置了 Streaming Replication ，則會嘗試連接到 Primary 並從存檔或 pg_wal 目錄中找到有效的紀錄開始 Streaming WAL。 當步驟3失敗，或是沒有配置 Streaming Replication 則將回到步驟1重新嘗試 以上步驟的 retry 循環或一直持續到 server 關閉或者 failover。\nfailover 可以透過運行 pg_ctl promote、調用 pg_promote() 或發現 trigger file (promote_trigger_file) 時，則會退退出 standby 模式成為 primary 提供正常操作。\n建議 在不同的主要版本號中通常是無法進行 log shipping 的 雖然 PG 沒有正式支持不同次要版本之間的 log shipping，但在次要版本中一般不更改 Disk 格式，並且新的次要版本更可能從舊的次要版本讀取 WAL，因此升級小版本號時建議先升級 standby。 在 Primary 上設置 Continuous archiving 時，應該考慮將歸檔位置設為 standby 本身或是非 Primary 機器上，避免因為 Primary 機器本身出問題而無法訪問。 使用 Streaming Replicaiton 需要注意以下事項： 創建 replication role，並在 ph_hba.conf 有正確的設置，確保 standby 能夠連線 Primary。 確保 Primary 上的 max_wal_senders 設置足夠大。 如果使用 Replication Slot 還需要確保 max_replication_slots 設置。 設置 Standby Log Shipping (warm standby) 在 PG 9.0 之前，PostgreSQL 只提供這種異步 replication 方式，這是透過 Primary 每次傳送一個 WAL 給 Standby 來實現，缺陷也很明顯就是 Standby 至少會落後 Primary 一個 WAL。\n配置方式 在 Primary 中新增以下設置\n1 2 archive_mode = on archive_command = \u0026#39;test ! -f /var/data/xlog_archive/%f \u0026amp;\u0026amp; cp %p /var/data/xlog_archive/%f\u0026#39; 對 Primary 進行 Base backup\n1 pg_basebackup -P -D /var/data/backup/pg_back_$(date +\u0026#34;%F_%T\u0026#34;) 還原到 Standby\n1 cp -R ./backup/pg_back_2023-04-17_07\\:06\\:57/* /var/data/postgres 修改 Standby 設置，並以 standby 模式運行\n1 restore_command = \u0026#39;cp /var/data/xlog_archive/%f \u0026#34;%p\u0026#34;\u0026#39; 1 2 touch standby.signal pg_ctl -D /var/data/postgres -l logfile start 透過在 Primary 新增資料，並使用 pg_switch_wal() 強制觸發 WAL 的切換來觀察\nprimary\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- primary [postgres @ postgres] [local]:5432] 07:16:07 \u0026gt; \\c test You are now connected to database \u0026#34;test\u0026#34; as user \u0026#34;postgres\u0026#34;. [postgres @ test] [local]:5432] 07:16:08 \u0026gt; select * from test; id | name ----+------- 1 | test1 (1 row) Time: 1.607 ms [postgres @ test] [local]:5432] 07:16:13 \u0026gt; insert into test values(2,\u0026#39;test2\u0026#39;); INSERT 0 1 Time: 1.594 ms [postgres @ test] [local]:5432] 07:16:24 \u0026gt; select * from test; id | name ----+------- 1 | test1 2 | test2 (2 rows) Time: 0.330 ms [postgres @ test] [local]:5432] 07:16:25 \u0026gt; SELECT pg_switch_wal(); pg_switch_wal --------------- 0/30003D8 (1 row) Time: 171.419 ms standby\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [postgres @ postgres] [local]:5432] 07:15:41 \u0026gt; \\c test You are now connected to database \u0026#34;test\u0026#34; as user \u0026#34;postgres\u0026#34;. [postgres @ test] [local]:5432] 07:15:44 \u0026gt; \\dt List of relations Schema | Name | Type | Owner --------+------+-------+---------- public | test | table | postgres (1 row) [postgres @ test] [local]:5432] 07:15:52 \u0026gt; select * from test; id | name ----+------- 1 | test1 (1 row) Time: 0.660 ms [postgres @ test] [local]:5432] 07:16:00 \u0026gt; select * from test; id | name ----+------- 1 | test1 (1 row) Time: 0.425 ms -- 在 primeary 觸發 WAL 刷新後 [postgres @ test] [local]:5432] 07:16:27 \u0026gt; select * from test; id | name ----+------- 1 | test1 2 | test2 (2 rows) Time: 0.334 ms 相關參數 Archiving archive_mode (enum)：設置是否進行 archive，有以下三種設置：\noff：關閉 archive。\non：正常模式下開啟 archive，但是在 recovery 或是 standby 時不進行 archvie。\\\n當 standby提升為 primary 時只會 archive 自己產生的 WAL，而不會 archive 原本從另一個 primary 取得的 WAL。\nalways：不論什麼模式都進行 archive。\narchive_command (string)：設置 archive WAL 的 shell 指令。\narchive_library (string)：設置用於 archive WAL 的 library，若為空表示使用 archive_command。\narchive_timeout (integer)：此參數為時間設置預設單位為秒，當此參數大於 0 時，會強制 server 只要距離上次切換到新的 WAL 已經過去這段時間，且有數據庫活動就必須切換到新的 WAL。\n因為 archive 只會針對完成的 WAL 作用，因此設置此參數可以避免當 WAL 輪換不頻繁時，導致 Transaction 過久沒有被安全的歸檔或者同步到 standby。\n注意：強制切換 WAL 的文件大小和完整的文件大小相同都是 16MB，因此設置太短的 archive_timeout 會導致歸檔存檔膨脹，通常 1 分鐘左右的設置是合理。如果希望 Primary 和 Standby 之間的延遲更小應該考慮 streaming replication 而不是調整此值。\nArchive Recovery 此處用於設置 recovery 期間的設定，recovery 包含以下兩者：\nrecovery mode：透過在數據目錄中創建 recovery.signal 設置 standby mode：透過在數據目錄中創建 standby.signal 設置，首先進入 recovery mode 並在恢復到歸檔的 WAL 末尾時不會停止，而是會嘗試透過 primary_conninfo 向指定的 primary 請求 WAL 或 restore_command 來繼續回放 WAL。 備注：如果 2 個 signal 都被建立則會以 standby mode 優先。\nrestore_command (string)：用於設置如何將歸檔的 WAL 用於 restore 的 shell 命令。\n範例如下：\n1 restore_command = \u0026#39;cp /mnt/server/archivedir/%f \u0026#34;%p\u0026#34;\u0026#39; 上述設定表示將複製 /mnt/server/archivdir 底下的 WAL 到 pg_wal 中。\n%f：表示歸檔 WAL 文件名稱。 %p：表示放置用於恢復 WAL 的目錄 (pg_wal)。 archive_cleanup_cpmmand (string)：用於設置清理 standby 不再需要的歸檔 WAL shell 命令。\n範例如下：\n1 archive_cleanup_command = \u0026#39;pg_archivecleanup /mnt/server/archivedir %r\u0026#39; 上述設定表示運行 pg_archivecleanup 將上一個 WAL 文件刪除。\n%r：表示需要的 WAL 文件的上一個 WAL 文件名稱。 recovery_end_command (string)：用於設置當 recovery 結束時執行的 shell 命令，例如可以用於發送 email 通知：\n1 recovery_end_command = \u0026#39;echo \u0026#34;Recovery complete\u0026#34; | mail -s \u0026#34;Recovery complete\u0026#34; admin@example.com\u0026#39; 小節 Log Shipping 是一種異步且即時性不高的 replication 方式，但是他相應的優勢就是因為是透過 primary 歸檔後的 WAL 進行恢復，因此不會有 Streaming Replicaion 丟失 WAL 導致無法復原的問題。\n雖然不推薦將 Log Shipping 做為主力的 replication 方案，但是可以將其同時和 Streaming Replication 一起運行作為附屬方案，只有當 Streaming Replication 因為某些原因跟不上 Primary 導致對應的 WAL 被刪除時，透過歸檔的 WAL 來進行復原。\nStreaming Replication (流複製 或稱 物理複製) 在 PG 9.0 開始提供了 Steaming Replication，雖然和 Log Shipping 一樣都是透過 WAL 日誌的回放來達到 Primary 和 Standby 的同步，但是 Streaming Replication 只要在 WAL 中一產生變化就會發送給 Standby，而不需要等到 WAL 切換才傳送，也就是說 Streaming Replication 會有更短的 replication delay。\n具體實現方面大體上其實和 MySQL 差不多，只是 MySQL 是透過 binlog 中的邏輯複製，但 PG 的 WAL 比較接近 MySQL redo log 也就是說是根據實際修改 Disk 物理空間的紀錄，也就是說在 PG 中 Master 和 Slave 的底層數據狀態是完全一致的。\n在 Streaming Replication 有以下角色：\nMaster 上的 backend 進程：執行收到的 Query 指令，在修改數據前先寫入 WAL，並在 commit 的時候將 WAL fsync 到 Disk。 Master 上的 WAL sender 進程：將 WAL 發送給 Slave 的 WAL receiver 。 Slave 上的 WAL receiver 進程：接收並持久化儲存 Master WAL sender 發送的 WAL。可以類比為 MySQL 的 IO THREAD。 Slave 上的 startup 進程：Apply WAL receiver 接收到的 WAL。可以類比為 MySQL 的 SQL THREAD。 同步 OR 異步 此外和 MySQL 一樣也分為異步或同步，主要透過以下參數控制：\nsynchronous_commit (enum)：指定 server 在完成多少 WAL 處理後才返回 Clinet 端成功。\n當 synchronous_standby_names 為空時，分為兩種設置：\non：此為默認值且 OFF 以外的設置都視為 ON，當 WAL fsync 到 Disk 才返回成功給 Client 端。 off：不會等待 WAL 的處理，也就是說可能會丟失 Transaction，最多可能會導致丟失 wal_write_delay * 3。 當 synchronous_standby_names 不為空時，分為5種設置：\n總共有以下 5 個值：\nremote_apply：保證 Slave 已經收到該 Transaction 的 WAL 並調用 fsync() disk，確保了該 Transaction 只有 Master、Slave 都發生數據損壞才會丟失 Transaction，並且還完成了 WAL 回放，因此在 Master、Slave 上擁有一致性讀取。 on：也可稱為 remote_flush，保證 Slave 已經收到該 Transaction 的 WAL 並調用 fsync() disk，確保了該 Transaction 只有 Master、Slave 都發生數據損壞才會丟失 Transaction，但因為還沒有回放 WAL，因此 Master、Slave 沒有一致性讀取。 remote_write：保證 Slave 已經收到該 Transaction 的 WAL 並寫入 OS 緩存，但未調用 fsync() disk，也就是說 PG server crash 並不會導致 Transaction 丟失，但是整個 OS 系統 Crash 將可能導致 Transaction 丟失。 local：等同於 synchronous_standby_names 為空時的 ON 設置，也就是說只要 Master 的 WAL 有 fsync 即可不必等待 slave，也就是異步複製。 off：不會等待 WAL 的處理，也就是說可能會丟失 Transaction，最多可能會導致丟失 wal_write_delay * 3。 注意：當 synchronous_standby_names 為空時，除了 OFF 以外的設定都會被視為 ON。\nsynchronous_standby_names (string)：指定要求同步 replication 的 slave 列表。\n這邊列出 Slave 在 primary_conninfo 中設置的 application_name (如果沒有則是 cluster_name)。\n可以設置成以下格式：\n1 2 3 [FIRST] num_sync ( standby_name [, ...] ) ANY num_sync ( standby_name [, ...] ) standby_name [, ...] 其中 num_sync 為數字，表示必須至少有多少 Slave 回覆已同步完成的 Ack 訊號，和 FIRST、ANY 組合有以下效果：\n[FIRST] num_sync：必須按照列表中的順序前 num_sync 數量的 slave 回覆已同步完成的 Ack 訊號才可以，之後的 slave 作為同步 slave 的備選只有優先序高的出現問題才會替補。 ANY num_sync：只要列表中的任意 num_sync 數量的 slave 回覆已同步完成的 Ack 訊號即可。 建置範例 檢查 Source 的設定\n1 2 3 4 5 6 listen_addresses = \u0026#39;*\u0026#39; # 以下皆為預設值 hot_standby = ON wal_level = replica max_wal_senders = 10 設置 replication 用的 User\n1 createuser -U postgres --replication repl 確認 Source 中的 pg_hba.conf 是否能接受 Replica 機器的連線\n1 2 # TYPE DATABASE USER ADDRESS METHOD host replication repl 172.17.0.3/16 trust 對 Source 進行 Base backup\n1 pg_basebackup -P -D /var/data/backup/pg_back_$(date +\u0026#34;%F_%T\u0026#34;) -R -U repl -R 選項會在備份檔中有以下不同\n生成 standby.signal\n在 postgresql.auto.conf 中多出 primary_conninfo 的資訊：\n1 primary_conninfo = \u0026#39;user=repl passfile=\u0026#39;\u0026#39;/home/postgres/.pgpass\u0026#39;\u0026#39; channel_binding=prefer port=5432 sslmode=prefer sslcompression=0 sslsni=1 ssl_min_protocol_version=TLSv1.2 gssencmode=disable krbsrvname=postgres target_session_attrs=any\u0026#39; 將 Source 剛剛的 Base backup 還原到 Replica 上\n1 cp -R /root/pg_data/source/backup/pg_back_2023-04-13_07\\:20\\:40/* /root/pg_data/replica/postgres 啟動 replica\n1 pg_ctl -D /var/data/postgres -l logfile start 1 2 3 4 2023-04-13 09:10:54.724 UTC [1136] LOG: consistent recovery state reached at 0/1A000000 2023-04-13 09:10:54.725 UTC [1135] LOG: database system is ready to accept read-only connections 2023-04-13 09:10:54.733 UTC [1140] LOG: started streaming WAL from primary at 0/1A000000 on timeline 1 done 小節 實務上可以結合 log shipping 和 streaming replication 一起使用，當 streaming replicaiton 因為 TCP 異常或是 Primary 丟棄所需的 WAL 時，PG 能夠自動切換回使用 log shipping 透過 restore_command 繼續追趕 Pimary 的進度，直到趕上 Primary 後 Standby 會重新嘗試切回 streaming repliction。\nReplication Slot 功用 - Slave 所需的 WAL 在 Master 上的保留 在 PostgreSQL 9.4 之前是沒有 Replication Slot 的，Slave 因為某些原因暫停 replication 之後，因為在 Master 上需要應用的 WAL 已經被清除，導致 Slave 恢復 replication 後發生以下狀況：requested WAL segment 0000000100000000000000xxx has already been removed，為了避免這個狀況可以透過以下參數的配置：\nwal_keep_size：指定 pg_wal 目錄下至少需保留的 WAL 大小。\n默認值為 0 表示不會額外保留 WAL，也就是說 slave 可用的 WAL segments 數量取決於前一個 checkpoint 和 WAL archiving 狀態。\n備註：在 PG 13 之前是使用 wal_keep_segments 來控制，他們之間的關係是 wal_keep_size = wal_keep_segments * wal_segment_size (一般是 16 MB)。\narchive_command：設置 WAL archive 的指令。\n將 WAL archive 到其他地方，這樣 Slave 就能從已經 archive 的 WAL 繼續恢復。\n不過以上方法會保留較多的 WAL，因此有了 Replication Slot 用來確保 Master 在所有 Slave 收到 WAL segments 之前不會刪除對應的部分。\n但這也帶來了相應的問題：當 Slave 發生異常無法回覆 Master 當前的 lsn 位置，就會導致 Master 不斷保留 WAL 最後導致 Disk 空間用盡而無法提供正常服務。\n在 PostgresSQL 13 之前，只能透過監控 replication 狀態來盡早發現進行處理，例如以下語句可以知道保留的 lsn 到當前最新的 redo_lsn 落後多少：\n1 2 3 4 5 6 postgres=# SELECT redo_lsn, slot_name,restart_lsn, round((redo_lsn-restart_lsn)/1024/1024,2) AS MB_behind FROM pg_control_checkpoint(), pg_replication_slots; redo_lsn | slot_name | restart_lsn | mb_behind -----------+------------+-------------+----------- 0/AAFF2D0 | pgstandby1 | 0/AAFF3B8 | 0.00 (1 row) 在 PostgresSQL 13 時推出了 max_slot_wal_keep_size 這個設置：\nmax_slot_wal_keep_size (integer)：設置 replication slot 在 pg_wal 目錄中保留的最大 wal 大小。\n當一個 slot 的 restart_lsn 落後於 current_lsn 本數值後會停止 stream replication，且該 slot 會被標記為無效，同時之前的 WAL 將被刪除。\n預設值為 -1 表示不限制。\n以上參數極大避免了在發生 Master 被 WAL 撐爆的問題，並且在 pg_replication_slots 也增加了 wal_status 和 safe_wal_size 字段方便監控：\n1 2 3 4 5 postgres=# select wal_status,safe_wal_size from pg_replication_slots; wal_status | safe_wal_size ------------+--------------- reserved | 1078987728 (1 row) wal_status：表示該 Slot 所需的 WAL 狀態 reserved：在 max_wal_size 之內。 extended：超出了 max_wal_size，但仍在 wal_keep_size 或 max_slot_wal_keep_size 的保護範圍內。 unreserved：表示 WAL 已經不在保護範圍內，這是一個臨時狀態，隨後可能變成 extended 或 lost。 lost：代表 WAL 已被刪除。 safe_wal_size：只有設置 max_slot_wal_keep_size 才會出現，表示還能寫入多少 WAL 大小才不會超過 max_slot_wal_keep_size 。當此值 ≤ 0 時，一旦觸發 checkpoint 就會發生 wal_status = lost 的狀況。 功用 - 改善 Master 的 vacuum 過早清除 Slave 所需的紀錄 當在 Master 使用 vacuum 指令或者觸發 auto vacuum 時，如果此操作在 Slave 回放時恰巧正在進行相關表的查詢時，會檢測出 vacuum 要清理的元組 (tuple) 仍被使用中，因此不能在 Slave 中立刻清除會在等待 max_standby_streaming_delay (默認為 30 秒) 之後終止該查詢操作，並返回以下錯誤後進行 vacuum：\n1 2 ERROR: canceling statement due to conflict with recovery Detail: User query might have needed to see row versions that must be removed 在沒有使用 Replication Slot 時，可以透過以下 2 個參數調整：\n在 Master 上設置 vacuum_defer_cleanup_age (integer)：指定 vacuum 和 Hot updates 將延遲多少 transaction 之前的 dead tuple 將不進行刪除。\n默認值為 0，表示可以盡快刪除 dead tuple。\n問題：調大此值雖然可以多保留 N 個 Transaction 之前的 dead tuple，但這是根據 Master 上的 Transaction 狀況決定，實際上很難預測 sLAVE 需要多少額外的寬限時間，因此不太實用。\n在 Slave 上設置 hot_standby_feedback (boolean)：當設置為 ON，表示 Slave 會通知 Master 自己目前的最小活躍事務id (xmin) 值，這樣 Master 在執行 vacuum 操作時會暫時不清除大於該 xmin 的 dead tuple。\n問題：當沒有 Slot 時，在 Slave 未連結的任何時間段都不提供保護。\n當有 Replication Slot 和 hot_standby_feedback 參數配合時，slot 會保持紀錄最後回傳的 xmin 保護 dead tuple。\n不過理所當然的事情有一體兩面，如果 Slave 上該查詢運行過久，Master 上可能會發生更嚴重的表膨脹問題。\n使用 Physical Replication slot 檢查 Source 的設定\n1 2 3 4 5 6 7 listen_addresses = \u0026#39;*\u0026#39; # 以下皆為預設值 hot_standby = ON wal_level = replica max_wal_senders = 10 max_replication_slots = 10 在 Sourrce 上建立 replication slot\n1 2 3 4 5 6 7 8 9 10 postgres=# SELECT * FROM pg_create_physical_replication_slot(\u0026#39;node_a_slot\u0026#39;); slot_name | lsn -------------+----- node_a_slot | postgres=# SELECT slot_name, slot_type, active FROM pg_replication_slots; slot_name | slot_type | active -------------+-----------+-------- node_a_slot | physical | f (1 row) 修改 Replica 上的設定\n1 2 primary_conninfo = \u0026#39;user=repl port=5432 host=172.17.0.2 application_name=replica\u0026#39; primary_slot_name = \u0026#39;node_a_slot\u0026#39; 小節 我認為應該使用 replication slot\nLogical Replication (邏輯複製) PG 15(14) 限制 僅會同步 table (包含 partitioned table)，不支持 views, materialized views, or foreign tables。 不會複製 schema 及 DDL 命令。 不複製 sequence data 不支持 Large objects。 建置範例 調整 Master、Slave 的設定，其中 wal_level 必須調整為 logical\n1 wal_level = logical 在 Master 建立一個用於 Logical Replication 的 role：\n1 2 3 4 5 create user logic_repl with replication; # 還必須提供 usage schema、select table 的權限 grant usage on SCHEMA test_schema to logic_repl; grant select on test_schema.test_table to logic_repl 設置 Master pg_hba.conf，注意這邊和物理複製不一樣，database 必須提供相應的 table：\n1 2 # TYPE DATABASE USER ADDRESS METHOD host test logic_repl 172.17.0.3/16 trust 在 Master 上建立 PUBLICATION：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [postgres @ test] [local]:5432] 07:57:41 \u0026gt; \\dRp List of publications Name | Owner | All tables | Inserts | Updates | Deletes | Truncates | Via root ------+-------+------------+---------+---------+---------+-----------+---------- (0 rows) [postgres @ test] [local]:5432] 07:57:59 \u0026gt; CREATE PUBLICATION repltest FOR TABLE test_schema.test_table; [postgres @ test] [local]:5432] 08:00:43 \u0026gt; \\dRp List of publications Name | Owner | All tables | Inserts | Updates | Deletes | Truncates | Via root --------+----------+------------+---------+---------+---------+-----------+---------- mytest | postgres | f | t | t | t | t | f (1 row) 在 Slave 上建立 SUBSCRIPTION\n1 2 3 4 5 6 7 8 9 10 11 12 13 [postgres @ test] [local]:5432] 08:00:22 \u0026gt; \\dRs List of subscriptions Name | Owner | Enabled | Publication ------+-------+---------+------------- (0 rows) [postgres @ test] [local]:5432] 08:02:30 \u0026gt; CREATE SUBSCRIPTION mysub CONNECTION \u0026#39;dbname=test host=172.17.0.2 user=logic_repl\u0026#39; PUBLICATION repltest WITH (copy_data = false); [postgres @ test] [local]:5432] 08:45:07 \u0026gt; \\dRs List of subscriptions Name | Owner | Enabled | Publication -------+----------+---------+------------- mysub | postgres | t | {mytest} 參考 PostgreSQL: Documentation: 15: Chapter 27. High Availability, Load Balancing, and Replication\nPostgreSQL: Documentation: 15: Chapter 31. Logical Replication\nPostgreSQL: Documentation: 15: 20.6. Replication\nPgSQL · 特性分析 · PG主备流复制机制 (taobao.org)\nPgSQL · 内核解析 · 同步流复制实现分析 (taobao.org)\nPostgreSQL 9.6 同步多副本 与 remote_apply事务同步级别\n一文彻底弄懂PostgreSQL流复制(全网最详细)_pg流复制_foucus、的博客-CSDN博客\nPgSQL · 特性分析· Replication Slot (taobao.org)\npostgresql-14流复制部署手册_HistSpeed的博客-CSDN博客\nSetup PostgreSQL 14 Streaming Replication | Girders: the blog of Allen Fair\n我是一个插槽，今天我做掉了数据库 - 知乎 (zhihu.com)\nPG复制状态监控_wal_status reserved_三思呐三思的博客-CSDN博客\nIt’s All About Replication Lag in PostgreSQL (percona.com)\n","date":"2020-02-19T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/postgre-replication/","title":"PostgreSQL Replication"},{"content":"pg_hba.conf hba 表示 host-based authentication，該設定檔用來\nTYPE：連線方式 local：使用 unix domain socket 連線。 host：使用 TCP/IP 連線，不論是否有 SSL 加密。 hostssl：僅限於使用 SSL 加密的 TCP/IP 連線。 hostnossl：僅限於不使用 SSL 加密的 TCP/IP 連線。 DATABASE：指定連線的 DATABASE 名稱，多個名稱可用 , 分隔。 all：表示所有 database。 sameuser：表示 database 名稱和 user 名稱相同。 samerole：表示 database 名稱和 user 所在的 role 相同。 replication：表示為請求 physical replication。 USER：表示此設定針對的 USER 名稱，多個名稱可用 , 分隔。 all：表示所有 user 都適用。 ADDRESS：表示 client 端機器 address。 METHOD：表示驗證方式。 trust：無條件允許，不需要任何驗證。 reject：無條件拒絕。 scram-sha-256：使用 scram-sha-256 身分驗證，此為目前提供最安全的密碼驗證方法。 md5：使用 scram-sha-256 或 MD5 身分驗證，MD5 並不安全。 password：要求 client 端提供未加密的密碼進行身分驗證，除非使用 SSL 加密連線否則這樣是不安全的。 gss：使用 GSSAPI 來身分驗證，僅支援 TCP/IP 連線方式。 sspi：使用 SSPI 來身分驗證，僅支援 windows。 1 2 3 4 5 6 7 8 # TYPE DATABASE USER ADDRESS METHOD local database user auth-method [auth-options] host database user address auth-method [auth-options] hostssl database user address auth-method [auth-options] hostnossl database user address auth-method [auth-options] host database user IP-address IP-mask auth-method [auth-options] hostssl database user IP-address IP-mask auth-method [auth-options] hostnossl database user IP-address IP-mask auth-method [auth-options] 參考 【赵渝强老师】史上最详细的PostgreSQL体系架构介绍 - 知乎 (zhihu.com)\nPostgreSQL数据目录结构 - 简书 (jianshu.com)\n","date":"2020-02-17T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/postgre-file-storage/","title":"PostgreSQL 實體檔案儲存"},{"content":"發現 PG 中有一個 SCHEMA 的層級這在 MySQL 中是沒有的。\n與 MySQL 類比 在 MySQL 中分為三個層級 Instance → DATABASE → TABLE，在 MySQL 中同一個 Instance 底下的任意 Database 可以存取其他 database 的 table。\n在 PG 中分為四個層級 Instance → DATABASE → SCHEMA → TABLE，在 PG 中不同 Database 之間是不能存取對方 Table 的，也就是說是獨立的。\n以此類比的情況下，PG 的 SCHEMA 會比較接近 MySQL 的 Database，而 PG 的 Database 會比較接近 Instance 的隔離層級。\n細說 每一個 Database 建立後會有以下 3 個 schema：\npg_catalog：用於儲存 pg 系統自帶的各種 metadata。 information_schema：用於儲存提供查詢 metadata 的查詢 view，主要是為了符合 SQL 標準。此 schema 可以單獨刪除 (但不建議)。 public：用於儲存使用者創建的 table，但一般基於安全性、管理性不建議使用。 參考 postgresql - cross-database references are not implemented: - Stack Overflow\ndatabase - What is the MySQL equivalent of a PostgreSQL \u0026lsquo;schema\u0026rsquo;? - Stack Overflow\n在数据库中，schema、catalog分别指的是什么？ - 知乎 (zhihu.com)\npostgresql的database和schema的理解_Chsavvy的博客-CSDN博客\nPostgreSQL教程\u0026ndash;逻辑结构：实例、数据库、schema、表之间的关系_postgre逻辑结构_java编程艺术的博客-CSDN博客\npostgresql - Difference between information_schema.tables and pg_tables - Stack Overflow\n","date":"2020-02-13T12:00:00+08:00","permalink":"https://FuweaY.github.io/p/postgre-schema/","title":"PostgreSQL schema"}]